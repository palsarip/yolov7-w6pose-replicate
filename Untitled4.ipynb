{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff66b90-829f-4f2f-b0fc-f84b839bd237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EPSILON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 241\u001b[0m\n\u001b[0;32m    238\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 220\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(video_path, output_path, rotation)\u001b[0m\n\u001b[0;32m    217\u001b[0m         plot_skeleton_kpts(display_img, keypoints, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;66;03m# Fall detection logic\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfall_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_fall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    221\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(display_img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFALL DETECTED!\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m80\u001b[39m), \n\u001b[0;32m    222\u001b[0m                        cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Resize back to original dimensions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 130\u001b[0m, in \u001b[0;36mFallDetector.detect_fall\u001b[1;34m(self, keypoints)\u001b[0m\n\u001b[0;32m    127\u001b[0m dimension_condition \u001b[38;5;241m=\u001b[39m (body_height \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (body_height \u001b[38;5;241m<\u001b[39m body_width \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.2\u001b[39m)\n\u001b[0;32m    129\u001b[0m velocity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_velocity(shoulder_center)\n\u001b[1;32m--> 130\u001b[0m angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_torso_leg_angle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m is_fall \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m height_condition \u001b[38;5;129;01mand\u001b[39;00m dimension_condition:\n",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m, in \u001b[0;36mFallDetector.calculate_torso_leg_angle\u001b[1;34m(self, keypoints)\u001b[0m\n\u001b[0;32m     86\u001b[0m torso_vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([lh[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m ls[\u001b[38;5;241m0\u001b[39m], lh[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m ls[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m     87\u001b[0m leg_vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([la[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m lh[\u001b[38;5;241m0\u001b[39m], la[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m lh[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(torso_vec) \u001b[38;5;241m<\u001b[39m \u001b[43mEPSILON\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(leg_vec) \u001b[38;5;241m<\u001b[39m EPSILON:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m unit_torso \u001b[38;5;241m=\u001b[39m torso_vec \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(torso_vec)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EPSILON' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device)\n",
    "model = weights['model'].float().eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "class FallDetector:\n",
    "    def __init__(self, fps=30):\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, \n",
    "            'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11,\n",
    "            'RIGHT_HIP': 12,\n",
    "            'LEFT_ANKLE': 13,\n",
    "            'RIGHT_ANKLE': 14\n",
    "        }\n",
    "        \n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.4,\n",
    "            'ANGLE': 120,\n",
    "            'VELOCITY': 0.5,\n",
    "            'CONFIRMATION_FRAMES': 10\n",
    "        }\n",
    "        \n",
    "        self.previous_positions = deque(maxlen=5)\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "\n",
    "    def get_valid_keypoints(self, keypoints):\n",
    "        \"\"\"Filter and validate keypoints with proper confidence\"\"\"\n",
    "        MIN_CONFIDENCE = 0.5\n",
    "        SAFE_COORD_THRESH = 1e6\n",
    "        kps = []\n",
    "        for i in range(0, len(keypoints), 3):\n",
    "            x, y, conf = keypoints[i:i+3]\n",
    "            if conf > MIN_CONFIDENCE and abs(x) < SAFE_COORD_THRESH and abs(y) < SAFE_COORD_THRESH:\n",
    "                kps.extend([x, y, conf])\n",
    "            else:\n",
    "                kps.extend([0.0, 0.0, 0.0])\n",
    "        return np.array(kps)\n",
    "\n",
    "    def calculate_length_factor(self, shoulder, hip):\n",
    "        EPSILON = 1e-6\n",
    "        return np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2 + EPSILON)\n",
    "\n",
    "    def calculate_body_dimensions(self, keypoints):\n",
    "        MIN_CONFIDENCE = 0.5\n",
    "        EPSILON = 1e-6\n",
    "        ls = keypoints[self.KEYPOINT_IDS['LEFT_SHOULDER']*3:(self.KEYPOINT_IDS['LEFT_SHOULDER']+1)*3]\n",
    "        rs = keypoints[self.KEYPOINT_IDS['RIGHT_SHOULDER']*3:(self.KEYPOINT_IDS['RIGHT_SHOULDER']+1)*3]\n",
    "        la = keypoints[self.KEYPOINT_IDS['LEFT_ANKLE']*3:(self.KEYPOINT_IDS['LEFT_ANKLE']+1)*3]\n",
    "        \n",
    "        if all(kp[2] > MIN_CONFIDENCE for kp in [ls, rs, la]):\n",
    "            body_height = abs(((ls[1] + rs[1])/2) - la[1])\n",
    "            body_width = abs(ls[0] - rs[0])\n",
    "            return max(body_height, EPSILON), max(body_width, EPSILON)\n",
    "        return None, None\n",
    "    def calculate_velocity(self, current_pos):\n",
    "        if len(self.previous_positions) >= 2:\n",
    "            prev_pos = self.previous_positions[-1]\n",
    "            dx = current_pos[0] - prev_pos[0]\n",
    "            dy = current_pos[1] - prev_pos[1]\n",
    "            distance = np.sqrt(dx**2 + dy**2 + EPSILON)\n",
    "            return distance * self.fps  # pixels/second\n",
    "        return 0\n",
    "\n",
    "    def calculate_torso_leg_angle(self, keypoints):\n",
    "        MIN_CONFIDENCE = 0.5\n",
    "        ls = keypoints[self.KEYPOINT_IDS['LEFT_SHOULDER']*3:(self.KEYPOINT_IDS['LEFT_SHOULDER']+1)*3]\n",
    "        lh = keypoints[self.KEYPOINT_IDS['LEFT_HIP']*3:(self.KEYPOINT_IDS['LEFT_HIP']+1)*3]\n",
    "        la = keypoints[self.KEYPOINT_IDS['LEFT_ANKLE']*3:(self.KEYPOINT_IDS['LEFT_ANKLE']+1)*3]\n",
    "        \n",
    "        if all(kp[2] > MIN_CONFIDENCE for kp in [ls, lh, la]):\n",
    "            torso_vec = np.array([lh[0] - ls[0], lh[1] - ls[1]])\n",
    "            leg_vec = np.array([la[0] - lh[0], la[1] - lh[1]])\n",
    "            \n",
    "            if np.linalg.norm(torso_vec) < EPSILON or np.linalg.norm(leg_vec) < EPSILON:\n",
    "                return None\n",
    "                \n",
    "            unit_torso = torso_vec / np.linalg.norm(torso_vec)\n",
    "            unit_leg = leg_vec / np.linalg.norm(leg_vec)\n",
    "            angle = np.degrees(np.arccos(np.clip(np.dot(unit_torso, unit_leg), -1.0, 1.0)))\n",
    "            return angle\n",
    "        return None\n",
    "\n",
    "    def detect_fall(self, keypoints):\n",
    "        MIN_CONFIDENCE = 0.5\n",
    "        \n",
    "        keypoints = self.get_valid_keypoints(keypoints)\n",
    "        \n",
    "        # Get required keypoints with validation\n",
    "        required_kps = [\n",
    "            keypoints[self.KEYPOINT_IDS[k]*3:(self.KEYPOINT_IDS[k]+1)*3] \n",
    "            for k in ['LEFT_SHOULDER', 'RIGHT_SHOULDER', \n",
    "                    'LEFT_HIP', 'RIGHT_HIP',\n",
    "                    'LEFT_ANKLE', 'RIGHT_ANKLE']\n",
    "        ]\n",
    "        \n",
    "        if any(kp[2] < MIN_CONFIDENCE for kp in required_kps):\n",
    "            self.fall_frames = max(0, self.fall_frames - 1)\n",
    "            return False\n",
    "        \n",
    "        ls, rs, lh, rh, la, ra = required_kps\n",
    "        shoulder_center = ((ls[0] + rs[0])/2, (ls[1] + rs[1])/2)\n",
    "        self.previous_positions.append(shoulder_center)\n",
    "        \n",
    "        length_factor = self.calculate_length_factor(ls, lh)\n",
    "        body_height, body_width = self.calculate_body_dimensions(keypoints)\n",
    "        \n",
    "        vertical_diff_left = abs(ls[1] - la[1])\n",
    "        vertical_diff_right = abs(rs[1] - ra[1])\n",
    "        height_condition = (vertical_diff_left > self.THRESHOLDS['ALPHA'] * length_factor) or \\\n",
    "                          (vertical_diff_right > self.THRESHOLDS['ALPHA'] * length_factor)\n",
    "        \n",
    "        dimension_condition = (body_height is not None) and (body_height < body_width * 1.2)\n",
    "        \n",
    "        velocity = self.calculate_velocity(shoulder_center)\n",
    "        angle = self.calculate_torso_leg_angle(keypoints)\n",
    "        \n",
    "        is_fall = False\n",
    "        if height_condition and dimension_condition:\n",
    "            angle_condition = (angle is not None) and (angle < self.THRESHOLDS['ANGLE'])\n",
    "            velocity_condition = velocity > self.THRESHOLDS['VELOCITY']\n",
    "            is_fall = angle_condition or velocity_condition\n",
    "        \n",
    "        if is_fall:\n",
    "            self.fall_frames += 1\n",
    "            if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                self.is_fallen = True\n",
    "                return True\n",
    "        else:\n",
    "            self.fall_frames = max(0, self.fall_frames - 2)\n",
    "            if self.fall_frames == 0:\n",
    "                self.is_fallen = False\n",
    "        \n",
    "        return self.is_fallen\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Rotation handling\n",
    "    if rotation in [90, 270]:\n",
    "        width, height = original_height, original_width\n",
    "    else:\n",
    "        width, height = original_width, original_height\n",
    "    \n",
    "    # Video writer setup\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    fall_detector = FallDetector(fps=fps)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "        \n",
    "        # Rotate frame if needed\n",
    "        if rotation == 90:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 180:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif rotation == 270:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess frame (same as photo example)\n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(\n",
    "                output, \n",
    "                0.25, 0.65, \n",
    "                nc=model.yaml['nc'], \n",
    "                nkpt=model.yaml['nkpt'], \n",
    "                kpt_label=True\n",
    "            )\n",
    "            output = output_to_keypoint(output)\n",
    "        \n",
    "        # Prepare display image (same as photo example)\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Process detections\n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                \n",
    "                # Plot skeleton directly on processed image\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                # Fall detection logic\n",
    "                if fall_detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        # Resize back to original dimensions\n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        \n",
    "        # Show and save results\n",
    "        cv2.imshow(\"Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902f17d-c4e6-414b-8d7a-a66ae27227ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = attempt_load('yolov7-w6-pose.pt', map_location=device)  # Load model\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)  # Convert model to half precision if using CUDA\n",
    "\n",
    "class FallDetector:\n",
    "    def __init__(self, fps=30):\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.4, 'ANGLE': 120,\n",
    "            'VELOCITY': 0.5, 'CONFIRMATION_FRAMES': 10\n",
    "        }\n",
    "        self.previous_positions = deque(maxlen=5)\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            left_shoulder = keypoints[self.KEYPOINT_IDS['LEFT_SHOULDER']*3:(self.KEYPOINT_IDS['LEFT_SHOULDER']+1)*3]\n",
    "            right_shoulder = keypoints[self.KEYPOINT_IDS['RIGHT_SHOULDER']*3:(self.KEYPOINT_IDS['RIGHT_SHOULDER']+1)*3]\n",
    "            left_ankle = keypoints[self.KEYPOINT_IDS['LEFT_ANKLE']*3:(self.KEYPOINT_IDS['LEFT_ANKLE']+1)*3]\n",
    "            right_ankle = keypoints[self.KEYPOINT_IDS['RIGHT_ANKLE']*3:(self.KEYPOINT_IDS['RIGHT_ANKLE']+1)*3]\n",
    "            \n",
    "            if left_shoulder[2] < 0.5 or right_shoulder[2] < 0.5:\n",
    "                return False\n",
    "            \n",
    "            shoulder_center = ((left_shoulder[0] + right_shoulder[0]) / 2, \n",
    "                               (left_shoulder[1] + right_shoulder[1]) / 2)\n",
    "            self.previous_positions.append(shoulder_center)\n",
    "            \n",
    "            if len(self.previous_positions) < 2:\n",
    "                return False\n",
    "            \n",
    "            dx = self.previous_positions[-1][0] - self.previous_positions[0][0]\n",
    "            dy = self.previous_positions[-1][1] - self.previous_positions[0][1]\n",
    "            velocity = np.sqrt(dx**2 + dy**2) * self.fps\n",
    "            \n",
    "            height_diff = abs(left_shoulder[1] - left_ankle[1])\n",
    "            is_fall = height_diff < self.THRESHOLDS['ALPHA'] * 200 or velocity > self.THRESHOLDS['VELOCITY']\n",
    "            \n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 1)\n",
    "                if self.fall_frames == 0:\n",
    "                    self.is_fallen = False\n",
    "            return self.is_fallen\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    fall_detector = FallDetector(fps=fps)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if rotation == 90:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 180:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif rotation == 270:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                             nc=model.yaml['nc'], \n",
    "                                             nkpt=model.yaml['nkpt'], \n",
    "                                             kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                if fall_detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1e705-ef5e-4b31-92a9-eba262861607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "# Initialize model with GPU optimizations\n",
    "def setup_device():\n",
    "    # Set up the best available device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # Enable cuDNN benchmark for optimal performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # Print GPU information\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"CuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"Using CPU - performance will be limited\")\n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "\n",
    "# Load model with optimizations\n",
    "@torch.no_grad()\n",
    "def load_model(weights_path):\n",
    "    model = attempt_load(weights_path, map_location=device)  # Load model\n",
    "    model.eval()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # Convert model to half precision (FP16) if using CUDA\n",
    "        model.half().to(device)\n",
    "        # Warm up GPU\n",
    "        img = torch.zeros((1, 3, 640, 640), device=device, dtype=torch.half)\n",
    "        model(img)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_model('yolov7-w6-pose.pt')\n",
    "\n",
    "class FallDetector:\n",
    "    def __init__(self, fps=30):\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.4, 'ANGLE': 120,\n",
    "            'VELOCITY': 0.5, 'CONFIRMATION_FRAMES': 10\n",
    "        }\n",
    "        self.previous_positions = deque(maxlen=5)\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            left_shoulder = keypoints[self.KEYPOINT_IDS['LEFT_SHOULDER']*3:(self.KEYPOINT_IDS['LEFT_SHOULDER']+1)*3]\n",
    "            right_shoulder = keypoints[self.KEYPOINT_IDS['RIGHT_SHOULDER']*3:(self.KEYPOINT_IDS['RIGHT_SHOULDER']+1)*3]\n",
    "            left_ankle = keypoints[self.KEYPOINT_IDS['LEFT_ANKLE']*3:(self.KEYPOINT_IDS['LEFT_ANKLE']+1)*3]\n",
    "            right_ankle = keypoints[self.KEYPOINT_IDS['RIGHT_ANKLE']*3:(self.KEYPOINT_IDS['RIGHT_ANKLE']+1)*3]\n",
    "            \n",
    "            if left_shoulder[2] < 0.5 or right_shoulder[2] < 0.5:\n",
    "                return False\n",
    "            \n",
    "            shoulder_center = ((left_shoulder[0] + right_shoulder[0]) / 2, \n",
    "                               (left_shoulder[1] + right_shoulder[1]) / 2)\n",
    "            self.previous_positions.append(shoulder_center)\n",
    "            \n",
    "            if len(self.previous_positions) < 2:\n",
    "                return False\n",
    "            \n",
    "            dx = self.previous_positions[-1][0] - self.previous_positions[0][0]\n",
    "            dy = self.previous_positions[-1][1] - self.previous_positions[0][1]\n",
    "            velocity = np.sqrt(dx**2 + dy**2) * self.fps\n",
    "            \n",
    "            height_diff = abs(left_shoulder[1] - left_ankle[1])\n",
    "            is_fall = height_diff < self.THRESHOLDS['ALPHA'] * 200 or velocity > self.THRESHOLDS['VELOCITY']\n",
    "            \n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 1)\n",
    "                if self.fall_frames == 0:\n",
    "                    self.is_fallen = False\n",
    "            return self.is_fallen\n",
    "        except Exception as e:\n",
    "            print(f\"Error in fall detection: {e}\")\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    fall_detector = FallDetector(fps=fps)\n",
    "    \n",
    "    # Pre-allocate memory for frame processing\n",
    "    frame_count = 0\n",
    "    start_time = cv2.getTickCount()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Handle rotation if needed\n",
    "        # if rotation == 90:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        # elif rotation == 180:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        # elif rotation == 270:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess frame\n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0)\n",
    "        \n",
    "        # Move tensor to GPU and convert to half precision\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        else:\n",
    "            img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Inference with torch.no_grad() for better performance\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                             nc=model.yaml['nc'], \n",
    "                                             nkpt=model.yaml['nkpt'], \n",
    "                                             kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        # Post-process and display\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                if fall_detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        # Calculate and display FPS periodically\n",
    "        if frame_count % 10 == 0:\n",
    "            elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
    "            fps = frame_count / elapsed_time\n",
    "            print(f\"Processing FPS: {fps:.2f}\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43655869-38e0-4bc7-a8c1-8d0ee926bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "# Initialize model with GPU optimizations\n",
    "def setup_device():\n",
    "    # Set up the best available device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # Enable cuDNN benchmark for optimal performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        # Print GPU information\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"CuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"Using CPU - performance will be limited\")\n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "\n",
    "# Load model with optimizations\n",
    "@torch.no_grad()\n",
    "def load_model(weights_path):\n",
    "    model = attempt_load(weights_path, map_location=device)  # Load model\n",
    "    model.eval()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # Convert model to half precision (FP16) if using CUDA\n",
    "        model.half().to(device)\n",
    "        # Warm up GPU\n",
    "        img = torch.zeros((1, 3, 640, 640), device=device, dtype=torch.half)\n",
    "        model(img)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_model('yolov7-w6-pose.pt')\n",
    "\n",
    "class FallDetector:\n",
    "    def __init__(self, fps=25):\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_KNEE': 13, 'RIGHT_KNEE': 14,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        self.THRESHOLDS = {\n",
    "            'MIN_SHOULDER_CONFIDENCE': 0.7,  # Higher confidence threshold\n",
    "            'HEIGHT_RATIO': 0.35,  # More conservative ratio\n",
    "            'VELOCITY_THRESHOLD': 0.8,  # Higher velocity threshold\n",
    "            'ANGLE_THRESHOLD': 130,  # More tolerant angle\n",
    "            'CONFIRMATION_FRAMES': 15,  # Longer confirmation period\n",
    "            'MAX_GROUND_DISTANCE': 0.2  # Max normalized distance from ground\n",
    "        }\n",
    "        self.position_history = deque(maxlen=10)  # Longer history\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "        self.ground_level = None  # Dynamic ground level estimation\n",
    "    \n",
    "    def calculate_torso_angle(self, shoulder_center, hip_center, knee_center):\n",
    "        \"\"\"Calculate torso angle to detect leaning/bending\"\"\"\n",
    "        vec1 = np.array(hip_center) - np.array(shoulder_center)\n",
    "        vec2 = np.array(knee_center) - np.array(hip_center)\n",
    "        cosine_angle = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        angle = np.degrees(np.arccos(cosine_angle))\n",
    "        return angle\n",
    "    \n",
    "    def estimate_ground_level(self, ankles):\n",
    "        \"\"\"Dynamically estimate ground level based on ankle positions\"\"\"\n",
    "        if len(self.position_history) > 5:\n",
    "            ankle_positions = [pos[2] for pos in self.position_history]\n",
    "            self.ground_level = max(ankle_positions)  # Ground is at max ankle y-position\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Get keypoints with confidence checks\n",
    "            left_shoulder = keypoints[self.KEYPOINT_IDS['LEFT_SHOULDER']*3:(self.KEYPOINT_IDS['LEFT_SHOULDER']+1)*3]\n",
    "            right_shoulder = keypoints[self.KEYPOINT_IDS['RIGHT_SHOULDER']*3:(self.KEYPOINT_IDS['RIGHT_SHOULDER']+1)*3]\n",
    "            left_hip = keypoints[self.KEYPOINT_IDS['LEFT_HIP']*3:(self.KEYPOINT_IDS['LEFT_HIP']+1)*3]\n",
    "            right_hip = keypoints[self.KEYPOINT_IDS['RIGHT_HIP']*3:(self.KEYPOINT_IDS['RIGHT_HIP']+1)*3]\n",
    "            left_knee = keypoints[self.KEYPOINT_IDS['LEFT_KNEE']*3:(self.KEYPOINT_IDS['LEFT_KNEE']+1)*3]\n",
    "            right_knee = keypoints[self.KEYPOINT_IDS['RIGHT_KNEE']*3:(self.KEYPOINT_IDS['RIGHT_KNEE']+1)*3]\n",
    "            left_ankle = keypoints[self.KEYPOINT_IDS['LEFT_ANKLE']*3:(self.KEYPOINT_IDS['LEFT_ANKLE']+1)*3]\n",
    "            right_ankle = keypoints[self.KEYPOINT_IDS['RIGHT_ANKLE']*3:(self.KEYPOINT_IDS['RIGHT_ANKLE']+1)*3]\n",
    "            \n",
    "            # Check keypoint confidence\n",
    "            if (left_shoulder[2] < self.THRESHOLDS['MIN_SHOULDER_CONFIDENCE'] or \n",
    "                right_shoulder[2] < self.THRESHOLDS['MIN_SHOULDER_CONFIDENCE'] or\n",
    "                left_ankle[2] < 0.5 or right_ankle[2] < 0.5):\n",
    "                return False\n",
    "            \n",
    "            # Calculate centers\n",
    "            shoulder_center = ((left_shoulder[0] + right_shoulder[0]) / 2, \n",
    "                              (left_shoulder[1] + right_shoulder[1]) / 2)\n",
    "            hip_center = ((left_hip[0] + right_hip[0]) / 2,\n",
    "                         (left_hip[1] + right_hip[1]) / 2)\n",
    "            knee_center = ((left_knee[0] + right_knee[0]) / 2,\n",
    "                          (left_knee[1] + right_knee[1]) / 2)\n",
    "            ankle_center = ((left_ankle[0] + right_ankle[0]) / 2,\n",
    "                           (left_ankle[1] + right_ankle[1]) / 2)\n",
    "            \n",
    "            # Update position history and ground level\n",
    "            self.position_history.append((shoulder_center, hip_center, knee_center, ankle_center))\n",
    "            self.estimate_ground_level([left_ankle, right_ankle])\n",
    "            \n",
    "            if len(self.position_history) < 5:  # Need more frames for reliable detection\n",
    "                return False\n",
    "            \n",
    "            # Calculate torso angle\n",
    "            torso_angle = self.calculate_torso_angle(shoulder_center, hip_center, knee_center)\n",
    "            \n",
    "            # Calculate velocity\n",
    "            dx = shoulder_center[0] - self.position_history[0][0][0]\n",
    "            dy = shoulder_center[1] - self.position_history[0][0][1]\n",
    "            velocity = np.sqrt(dx**2 + dy**2) * self.fps\n",
    "            \n",
    "            # Calculate height ratio (shoulder to ankle)\n",
    "            height_diff = abs(shoulder_center[1] - ankle_center[1])\n",
    "            frame_height = abs(ankle_center[1] - shoulder_center[1])  # Approximate person height\n",
    "            \n",
    "            # Normalized distance from ground\n",
    "            if self.ground_level is not None:\n",
    "                ground_distance = abs(shoulder_center[1] - self.ground_level) / frame_height\n",
    "            \n",
    "            # Combined fall detection conditions\n",
    "            is_fall = (\n",
    "                (height_diff < self.THRESHOLDS['HEIGHT_RATIO'] * frame_height) or  # Height condition\n",
    "                (velocity > self.THRESHOLDS['VELOCITY_THRESHOLD'] and  # Velocity condition\n",
    "                 torso_angle > self.THRESHOLDS['ANGLE_THRESHOLD']) or  # Angle condition\n",
    "                (self.ground_level is not None and  # Ground proximity\n",
    "                 ground_distance < self.THRESHOLDS['MAX_GROUND_DISTANCE'])\n",
    "            )\n",
    "            \n",
    "            # Temporal consistency check\n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 2)  # Decrease faster\n",
    "                if self.fall_frames <= 2:\n",
    "                    self.is_fallen = False\n",
    "            return self.is_fallen\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fall detection: {e}\")\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    fall_detector = FallDetector(fps=fps)\n",
    "    \n",
    "    # Pre-allocate memory for frame processing\n",
    "    frame_count = 0\n",
    "    start_time = cv2.getTickCount()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Handle rotation if needed\n",
    "        # if rotation == 90:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        # elif rotation == 180:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        # elif rotation == 270:\n",
    "        #     frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess frame\n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0)\n",
    "        \n",
    "        # Move tensor to GPU and convert to half precision\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        else:\n",
    "            img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Inference with torch.no_grad() for better performance\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                             nc=model.yaml['nc'], \n",
    "                                             nkpt=model.yaml['nkpt'], \n",
    "                                             kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        # Post-process and display\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                if fall_detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        # Calculate and display FPS periodically\n",
    "        if frame_count % 10 == 0:\n",
    "            elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
    "            fps = frame_count / elapsed_time\n",
    "            print(f\"Processing FPS: {fps:.2f}\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dd634-4186-4c90-90b1-d4df2e3360db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "class ScientificFallDetector:\n",
    "    def __init__(self, fps=25):\n",
    "        # Keypoint indices based on YOLOv7 pose estimation model\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_KNEE': 13, 'RIGHT_KNEE': 14,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        \n",
    "        # Thresholds from the scientific paper with adjustments\n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.25,                  # Height adjustment factor (α)\n",
    "            'MIN_CONFIDENCE': 0.7,          # Minimum keypoint confidence\n",
    "            'VELOCITY_THRESHOLD': 0.6,      # Normalized velocity threshold\n",
    "            'ANGLE_THRESHOLD': 45,          # Torso-leg angle threshold (degrees)\n",
    "            'CONFIRMATION_FRAMES': 10,      # Frames needed to confirm fall\n",
    "            'GROUND_PROXIMITY': 0.15        # Normalized ground proximity\n",
    "        }\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.position_history = deque(maxlen=15)  # For velocity calculation\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "        self.ground_level = None\n",
    "        \n",
    "    def calculate_length_factor(self, shoulder, hip):\n",
    "        \"\"\"Calculate the normalization factor (L_factor) from equation (1)\"\"\"\n",
    "        return np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "    \n",
    "    def calculate_velocity(self, current_pos, previous_pos):\n",
    "        \"\"\"Calculate normalized velocity between positions\"\"\"\n",
    "        dx = current_pos[0] - previous_pos[0]\n",
    "        dy = current_pos[1] - previous_pos[1]\n",
    "        return np.sqrt(dx**2 + dy**2) * self.fps\n",
    "    \n",
    "    def calculate_torso_leg_angle(self, shoulder, hip, knee):\n",
    "        \"\"\"Calculate angle between torso and legs (degrees)\"\"\"\n",
    "        vec1 = np.array([hip[0] - shoulder[0], hip[1] - shoulder[1]])\n",
    "        vec2 = np.array([knee[0] - hip[0], knee[1] - hip[1]])\n",
    "        cosine_angle = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        return np.degrees(np.arccos(cosine_angle))\n",
    "    \n",
    "    def update_ground_level(self, ankle_positions):\n",
    "        \"\"\"Dynamically estimate ground level based on ankle positions\"\"\"\n",
    "        if ankle_positions:\n",
    "            self.ground_level = max(pos[1] for pos in ankle_positions if pos[2] > 0.5)\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Extract keypoints with confidence check\n",
    "            kps = {}\n",
    "            for name, idx in self.KEYPOINT_IDS.items():\n",
    "                x, y, conf = keypoints[idx*3:(idx+1)*3]\n",
    "                if conf < self.THRESHOLDS['MIN_CONFIDENCE']:\n",
    "                    return False  # Insufficient confidence\n",
    "                kps[name] = (x, y, conf)\n",
    "            \n",
    "            # Calculate centers\n",
    "            shoulder_center = (\n",
    "                (kps['LEFT_SHOULDER'][0] + kps['RIGHT_SHOULDER'][0]) / 2,\n",
    "                (kps['LEFT_SHOULDER'][1] + kps['RIGHT_SHOULDER'][1]) / 2\n",
    "            )\n",
    "            hip_center = (\n",
    "                (kps['LEFT_HIP'][0] + kps['RIGHT_HIP'][0]) / 2,\n",
    "                (kps['LEFT_HIP'][1] + kps['RIGHT_HIP'][1]) / 2\n",
    "            )\n",
    "            ankle_center = (\n",
    "                (kps['LEFT_ANKLE'][0] + kps['RIGHT_ANKLE'][0]) / 2,\n",
    "                (kps['LEFT_ANKLE'][1] + kps['RIGHT_ANKLE'][1]) / 2\n",
    "            )\n",
    "            \n",
    "            # Calculate length factor (L_factor) from equation (1)\n",
    "            L_factor = self.calculate_length_factor(shoulder_center, hip_center)\n",
    "            \n",
    "            # 1. Height condition (equation 2)\n",
    "            height_condition = shoulder_center[1] <= ankle_center[1] + self.THRESHOLDS['ALPHA'] * L_factor\n",
    "            \n",
    "            # 2. Body dimension condition (equations 3-5)\n",
    "            body_height = abs(shoulder_center[1] - ankle_center[1])\n",
    "            body_width = abs(kps['LEFT_SHOULDER'][0] - kps['RIGHT_SHOULDER'][0])\n",
    "            dimension_condition = body_height < body_width\n",
    "            \n",
    "            # 3. Velocity condition (from movement analysis)\n",
    "            velocity = 0\n",
    "            if len(self.position_history) > 0:\n",
    "                velocity = self.calculate_velocity(shoulder_center, self.position_history[-1][0])\n",
    "            velocity_condition = velocity > self.THRESHOLDS['VELOCITY_THRESHOLD']\n",
    "            \n",
    "            # 4. Angle condition (torso-leg angle)\n",
    "            torso_leg_angle = self.calculate_torso_leg_angle(\n",
    "                shoulder_center, hip_center, \n",
    "                (kps['LEFT_KNEE'][0], kps['LEFT_KNEE'][1])\n",
    "            )\n",
    "            angle_condition = torso_leg_angle < self.THRESHOLDS['ANGLE_THRESHOLD']\n",
    "            \n",
    "            # 5. Ground proximity condition\n",
    "            ground_condition = False\n",
    "            if self.ground_level is not None:\n",
    "                ground_distance = abs(shoulder_center[1] - self.ground_level) / body_height\n",
    "                ground_condition = ground_distance < self.THRESHOLDS['GROUND_PROXIMITY']\n",
    "            \n",
    "            # Update position history and ground level\n",
    "            self.position_history.append((shoulder_center, hip_center, ankle_center))\n",
    "            self.update_ground_level([kps['LEFT_ANKLE'], kps['RIGHT_ANKLE']])\n",
    "            \n",
    "            # Combined fall detection (all conditions from paper)\n",
    "            is_fall = (\n",
    "                (height_condition and dimension_condition) or  # Basic geometric conditions\n",
    "                (velocity_condition and angle_condition) or    # Dynamic movement conditions\n",
    "                ground_condition                              # Proximity to ground\n",
    "            )\n",
    "            \n",
    "            # Temporal consistency check\n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 2)\n",
    "                if self.fall_frames == 0:\n",
    "                    self.is_fallen = False\n",
    "            \n",
    "            return self.is_fallen\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fall detection: {e}\")\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    # Initialize device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = attempt_load('yolov7-w6-pose.pt', map_location=device)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.half().to(device)\n",
    "    \n",
    "    # Video setup\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    detector = ScientificFallDetector(fps=fps)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Handle rotation if needed\n",
    "        if rotation == 90:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 180:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif rotation == 270:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess frame\n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        else:\n",
    "            img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                           nc=model.yaml['nc'], \n",
    "                                           nkpt=model.yaml['nkpt'], \n",
    "                                           kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        # Display\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                if detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Scientific Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (3).avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc908a1-ca79-4e8a-a518-f2765f146542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "class ScientificFallDetector:\n",
    "    def __init__(self, fps=25):\n",
    "        # Keypoint indices based on YOLOv7 pose estimation model\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        \n",
    "        # Thresholds from the journal with exact values mentioned\n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.25,                  # Height adjustment factor (α) from equation\n",
    "            'MIN_CONFIDENCE': 0.7,          # Minimum keypoint confidence\n",
    "            'VELOCITY_THRESHOLD': 0.8,      # Normalized velocity threshold for fall vs lying down\n",
    "            'ANGLE_THRESHOLD': 45,          # Torso-leg angle threshold (degrees) from journal\n",
    "            'CONFIRMATION_FRAMES': 10,      # Frames needed to confirm fall\n",
    "            'HEIGHT_RATIO': 1.0             # Height/width ratio threshold from equation (5)\n",
    "        }\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.position_history = deque(maxlen=10)  # For velocity calculation (10 frames ~ 0.4s at 25fps)\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "        \n",
    "    def calculate_length_factor(self, shoulder, hip):\n",
    "        \"\"\"Calculate the normalization factor (L_factor) from equation (1) in journal\"\"\"\n",
    "        return np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "    \n",
    "    def calculate_velocity(self, current_pos, previous_pos):\n",
    "        \"\"\"Calculate normalized velocity between positions as described in journal\"\"\"\n",
    "        dx = current_pos[0] - previous_pos[0]\n",
    "        dy = current_pos[1] - previous_pos[1]\n",
    "        return np.sqrt(dx**2 + dy**2) * self.fps  # pixels/second\n",
    "    \n",
    "    def calculate_torso_leg_angle(self, shoulder, hip, ankle):\n",
    "        \"\"\"Calculate angle between torso and legs (degrees) as described in journal\"\"\"\n",
    "        torso_vec = np.array([hip[0] - shoulder[0], hip[1] - shoulder[1]])\n",
    "        leg_vec = np.array([ankle[0] - hip[0], ankle[1] - hip[1]])\n",
    "        \n",
    "        # Handle zero vectors\n",
    "        if np.linalg.norm(torso_vec) == 0 or np.linalg.norm(leg_vec) == 0:\n",
    "            return 90  # Neutral angle if vectors can't be computed\n",
    "        \n",
    "        cosine_angle = np.dot(torso_vec, leg_vec) / (np.linalg.norm(torso_vec) * np.linalg.norm(leg_vec))\n",
    "        cosine_angle = np.clip(cosine_angle, -1, 1)  # Ensure valid range for arccos\n",
    "        return np.degrees(np.arccos(cosine_angle))\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        \"\"\"Implement the exact fall detection algorithm from the journal\"\"\"\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Extract keypoints with confidence check (exactly as described in journal)\n",
    "            kps = {}\n",
    "            for name, idx in self.KEYPOINT_IDS.items():\n",
    "                x, y, conf = keypoints[idx*3:(idx+1)*3]\n",
    "                if conf < self.THRESHOLDS['MIN_CONFIDENCE']:\n",
    "                    return False  # Insufficient confidence as per journal\n",
    "                kps[name] = (x, y, conf)\n",
    "            \n",
    "            # Calculate centers exactly as described in journal\n",
    "            shoulder_center = (\n",
    "                (kps['LEFT_SHOULDER'][0] + kps['RIGHT_SHOULDER'][0]) / 2,\n",
    "                (kps['LEFT_SHOULDER'][1] + kps['RIGHT_SHOULDER'][1]) / 2\n",
    "            )\n",
    "            hip_center = (\n",
    "                (kps['LEFT_HIP'][0] + kps['RIGHT_HIP'][0]) / 2,\n",
    "                (kps['LEFT_HIP'][1] + kps['RIGHT_HIP'][1]) / 2\n",
    "            )\n",
    "            ankle_center = (\n",
    "                (kps['LEFT_ANKLE'][0] + kps['RIGHT_ANKLE'][0]) / 2,\n",
    "                (kps['LEFT_ANKLE'][1] + kps['RIGHT_ANKLE'][1]) / 2\n",
    "            )\n",
    "            \n",
    "            # 1. Calculate length factor (L_factor) from equation (1) in journal\n",
    "            L_factor = self.calculate_length_factor(shoulder_center, hip_center)\n",
    "            \n",
    "            # 2. Height condition (equation 2 in journal)\n",
    "            height_condition = shoulder_center[1] <= ankle_center[1] + self.THRESHOLDS['ALPHA'] * L_factor\n",
    "            \n",
    "            # 3. Body dimension conditions (equations 3-5 in journal)\n",
    "            body_height = abs(shoulder_center[1] - ankle_center[1])  # Equation (3)\n",
    "            body_width = abs(kps['LEFT_SHOULDER'][0] - kps['RIGHT_SHOULDER'][0])  # Equation (4)\n",
    "            dimension_condition = body_height < body_width  # Equation (5)\n",
    "            \n",
    "            # 4. Velocity condition (for fall vs lying down differentiation)\n",
    "            velocity = 0\n",
    "            if len(self.position_history) > 0:\n",
    "                velocity = self.calculate_velocity(shoulder_center, self.position_history[-1][0])\n",
    "            velocity_condition = velocity > self.THRESHOLDS['VELOCITY_THRESHOLD']\n",
    "            \n",
    "            # 5. Angle condition (torso-leg angle from journal)\n",
    "            torso_leg_angle_left = self.calculate_torso_leg_angle(\n",
    "                shoulder_center, hip_center, \n",
    "                (kps['LEFT_ANKLE'][0], kps['LEFT_ANKLE'][1])\n",
    "            )\n",
    "            torso_leg_angle_right = self.calculate_torso_leg_angle(\n",
    "                shoulder_center, hip_center, \n",
    "                (kps['RIGHT_ANKLE'][0], kps['RIGHT_ANKLE'][1])\n",
    "            )\n",
    "            torso_leg_angle = min(torso_leg_angle_left, torso_leg_angle_right)\n",
    "            angle_condition = torso_leg_angle < self.THRESHOLDS['ANGLE_THRESHOLD']\n",
    "            \n",
    "            # Update position history\n",
    "            self.position_history.append((shoulder_center, hip_center, ankle_center))\n",
    "            \n",
    "            # Combined fall detection exactly as described in journal\n",
    "            # Primary conditions (height and dimension)\n",
    "            primary_conditions = height_condition and dimension_condition\n",
    "            \n",
    "            # Secondary conditions (velocity or angle) for fall vs lying down differentiation\n",
    "            secondary_conditions = velocity_condition or angle_condition\n",
    "            \n",
    "            # Final fall decision as per journal\n",
    "            is_fall = primary_conditions and secondary_conditions\n",
    "            \n",
    "            # Temporal consistency check\n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 2)\n",
    "                if self.fall_frames == 0:\n",
    "                    self.is_fallen = False\n",
    "            \n",
    "            return self.is_fallen\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fall detection: {e}\")\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    # Initialize device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = attempt_load('yolov7-w6-pose.pt', map_location=device)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.half().to(device)\n",
    "    \n",
    "    # Video setup\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    detector = ScientificFallDetector(fps=fps)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Handle rotation if needed\n",
    "        if rotation == 90:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 180:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif rotation == 270:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess frame\n",
    "        img = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        else:\n",
    "            img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                           nc=model.yaml['nc'], \n",
    "                                           nkpt=model.yaml['nkpt'], \n",
    "                                           kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        # Display\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                if detector.detect_fall(keypoints):\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (50, 80), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Scientific Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c96a0e-c932-4948-af8b-077aaf83c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "class ScientificFallDetector:\n",
    "    def __init__(self, fps=25):\n",
    "        # Keypoint indices\n",
    "        self.KEYPOINT_IDS = {\n",
    "            'LEFT_SHOULDER': 5, 'RIGHT_SHOULDER': 6,\n",
    "            'LEFT_HIP': 11, 'RIGHT_HIP': 12,\n",
    "            'LEFT_ANKLE': 15, 'RIGHT_ANKLE': 16\n",
    "        }\n",
    "        \n",
    "        # Optimized thresholds\n",
    "        self.THRESHOLDS = {\n",
    "            'ALPHA': 0.3,                    # Height adjustment factor\n",
    "            'MIN_CONFIDENCE': 0.6,           # Keypoint confidence threshold\n",
    "            'VELOCITY_THRESHOLD': 0.8,       # Movement speed threshold\n",
    "            'ANGLE_THRESHOLD': 40,           # Torso-leg angle threshold\n",
    "            'CONFIRMATION_FRAMES': 10,       # Frames to confirm fall\n",
    "            'MIN_HEIGHT_DIFF': 0.1           # Minimum shoulder-ankle difference\n",
    "        }\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.position_history = deque(maxlen=15)\n",
    "        self.fall_frames = 0\n",
    "        self.is_fallen = False\n",
    "        self.fps = fps\n",
    "        self.debug_info = {}\n",
    "        self.max_shoulder_height = 0\n",
    "\n",
    "    def calculate_length_factor(self, shoulder, hip):\n",
    "        \"\"\"Calculate normalization factor (L_factor)\"\"\"\n",
    "        return np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "    \n",
    "    def calculate_velocity(self, current_pos, previous_pos):\n",
    "        \"\"\"Calculate movement velocity\"\"\"\n",
    "        dx = current_pos[0] - previous_pos[0]\n",
    "        dy = current_pos[1] - previous_pos[1]\n",
    "        return np.sqrt(dx**2 + dy**2) * self.fps\n",
    "    \n",
    "    def calculate_torso_leg_angle(self, shoulder, hip, ankle):\n",
    "        \"\"\"Calculate angle between torso and legs\"\"\"\n",
    "        torso_vec = np.array([hip[0] - shoulder[0], hip[1] - shoulder[1]])\n",
    "        leg_vec = np.array([ankle[0] - hip[0], ankle[1] - hip[1]])\n",
    "        \n",
    "        if np.linalg.norm(torso_vec) == 0 or np.linalg.norm(leg_vec) == 0:\n",
    "            return 90\n",
    "            \n",
    "        cosine_angle = np.dot(torso_vec, leg_vec) / (np.linalg.norm(torso_vec) * np.linalg.norm(leg_vec))\n",
    "        cosine_angle = np.clip(cosine_angle, -1, 1)\n",
    "        return np.degrees(np.arccos(cosine_angle))\n",
    "    \n",
    "    def detect_fall(self, keypoints):\n",
    "        self.debug_info = {}\n",
    "        if keypoints is None or len(keypoints) == 0:\n",
    "            self.debug_info['error'] = \"No keypoints\"\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Extract keypoints with confidence check\n",
    "            kps = {}\n",
    "            for name, idx in self.KEYPOINT_IDS.items():\n",
    "                x, y, conf = keypoints[idx*3:(idx+1)*3]\n",
    "                if conf < self.THRESHOLDS['MIN_CONFIDENCE']:\n",
    "                    self.debug_info['error'] = f\"Low confidence: {name}\"\n",
    "                    return False\n",
    "                kps[name] = (x, y, conf)\n",
    "            \n",
    "            # Calculate centers\n",
    "            shoulder_center = (\n",
    "                (kps['LEFT_SHOULDER'][0] + kps['RIGHT_SHOULDER'][0]) / 2,\n",
    "                (kps['LEFT_SHOULDER'][1] + kps['RIGHT_SHOULDER'][1]) / 2\n",
    "            )\n",
    "            hip_center = (\n",
    "                (kps['LEFT_HIP'][0] + kps['RIGHT_HIP'][0]) / 2,\n",
    "                (kps['LEFT_HIP'][1] + kps['RIGHT_HIP'][1]) / 2\n",
    "            )\n",
    "            ankle_center = (\n",
    "                (kps['LEFT_ANKLE'][0] + kps['RIGHT_ANKLE'][0]) / 2,\n",
    "                (kps['LEFT_ANKLE'][1] + kps['RIGHT_ANKLE'][1]) / 2\n",
    "            )\n",
    "            \n",
    "            # Store positions for debug\n",
    "            self.debug_info['shoulder'] = shoulder_center\n",
    "            self.debug_info['ankle'] = ankle_center\n",
    "            \n",
    "            # Calculate length factor\n",
    "            L_factor = self.calculate_length_factor(shoulder_center, hip_center)\n",
    "            self.debug_info['L_factor'] = L_factor\n",
    "            \n",
    "            # 1. Shoulder-ankle relationship (CRITICAL FIX)\n",
    "            shoulder_above_ankle = shoulder_center[1] < ankle_center[1]\n",
    "            height_diff = ankle_center[1] - shoulder_center[1] if shoulder_above_ankle else shoulder_center[1] - ankle_center[1]\n",
    "            \n",
    "            # 2. Height condition (only when shoulders are BELOW ankles)\n",
    "            height_condition = False\n",
    "            if not shoulder_above_ankle:\n",
    "                height_condition = (height_diff >= self.THRESHOLDS['MIN_HEIGHT_DIFF'] * L_factor and \n",
    "                                  height_diff <= self.THRESHOLDS['ALPHA'] * L_factor)\n",
    "            \n",
    "            self.debug_info['shoulder_above_ankle'] = shoulder_above_ankle\n",
    "            self.debug_info['height_diff'] = height_diff\n",
    "            self.debug_info['height_condition'] = height_condition\n",
    "            \n",
    "            # 3. Body dimension conditions\n",
    "            body_height = abs(shoulder_center[1] - ankle_center[1])\n",
    "            body_width = abs(kps['LEFT_SHOULDER'][0] - kps['RIGHT_SHOULDER'][0])\n",
    "            dimension_condition = body_height < body_width\n",
    "            self.debug_info['body_height'] = body_height\n",
    "            self.debug_info['body_width'] = body_width\n",
    "            self.debug_info['dimension_condition'] = dimension_condition\n",
    "            \n",
    "            # 4. Velocity calculation\n",
    "            velocity = 0\n",
    "            if len(self.position_history) > 0:\n",
    "                velocity = self.calculate_velocity(shoulder_center, self.position_history[-1][0])\n",
    "            velocity_condition = velocity > self.THRESHOLDS['VELOCITY_THRESHOLD']\n",
    "            self.debug_info['velocity'] = velocity\n",
    "            self.debug_info['velocity_condition'] = velocity_condition\n",
    "            \n",
    "            # 5. Angle calculation\n",
    "            torso_leg_angle = self.calculate_torso_leg_angle(\n",
    "                shoulder_center, hip_center, ankle_center)\n",
    "            angle_condition = torso_leg_angle < self.THRESHOLDS['ANGLE_THRESHOLD']\n",
    "            self.debug_info['torso_leg_angle'] = torso_leg_angle\n",
    "            self.debug_info['angle_condition'] = angle_condition\n",
    "            \n",
    "            # Update position history\n",
    "            self.position_history.append((shoulder_center, hip_center, ankle_center))\n",
    "            \n",
    "            # Update max shoulder height\n",
    "            self.max_shoulder_height = max(self.max_shoulder_height, shoulder_center[1])\n",
    "            \n",
    "            # Fall detection logic (REVISED)\n",
    "            is_fall = False\n",
    "            if not shoulder_above_ankle:  # Only check if shoulders are below ankles\n",
    "                is_fall = (\n",
    "                    height_condition and\n",
    "                    dimension_condition and\n",
    "                    velocity_condition and\n",
    "                    angle_condition and\n",
    "                    (self.max_shoulder_height - shoulder_center[1]) > 0.2 * L_factor\n",
    "                )\n",
    "            \n",
    "            # Reset max height when standing\n",
    "            if shoulder_above_ankle and height_diff > 0.5 * L_factor:\n",
    "                self.max_shoulder_height = shoulder_center[1]\n",
    "            \n",
    "            # Temporal consistency\n",
    "            if is_fall:\n",
    "                self.fall_frames += 1\n",
    "                if self.fall_frames >= self.THRESHOLDS['CONFIRMATION_FRAMES']:\n",
    "                    self.is_fallen = True\n",
    "                    return True\n",
    "            else:\n",
    "                self.fall_frames = max(0, self.fall_frames - 1)\n",
    "                if self.fall_frames == 0:\n",
    "                    self.is_fallen = False\n",
    "            \n",
    "            return self.is_fallen\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.debug_info['error'] = str(e)\n",
    "            print(f\"Error in fall detection: {e}\")\n",
    "            return False\n",
    "\n",
    "def process_video(video_path, output_path=None, rotation=0):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = attempt_load('yolov7-w6-pose.pt', map_location=device)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.half().to(device)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    detector = ScientificFallDetector(fps=fps)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Handle rotation\n",
    "        if rotation == 90:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif rotation == 180:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif rotation == 270:\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        # Preprocess\n",
    "        img = letterbox(frame, 960, stride=64, auto=True)[0]\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            img_tensor = img_tensor.half().to(device)\n",
    "        else:\n",
    "            img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(img_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, \n",
    "                                           nc=model.yaml['nc'], \n",
    "                                           nkpt=model.yaml['nkpt'], \n",
    "                                           kpt_label=True)\n",
    "            output = output_to_keypoint(output) if output is not None else None\n",
    "        \n",
    "        # Prepare display\n",
    "        display_img = img_tensor[0].permute(1, 2, 0).cpu().numpy()\n",
    "        display_img = (display_img * 255).astype(np.uint8)\n",
    "        display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if output is not None and len(output) > 0:\n",
    "            for idx in range(output.shape[0]):\n",
    "                keypoints = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(display_img, keypoints, 3)\n",
    "                \n",
    "                fall_detected = detector.detect_fall(keypoints)\n",
    "                \n",
    "                # Visual debug information\n",
    "                debug_text = [\n",
    "                    f\"Shoulder Y: {detector.debug_info.get('shoulder', (0,0))[1]:.1f}\",\n",
    "                    f\"Ankle Y: {detector.debug_info.get('ankle', (0,0))[1]:.1f}\",\n",
    "                    f\"Shoulder Above: {detector.debug_info.get('shoulder_above_ankle', False)}\",\n",
    "                    f\"Height Diff: {detector.debug_info.get('height_diff', 0):.1f}\",\n",
    "                    f\"Height Cond: {detector.debug_info.get('height_condition', False)}\",\n",
    "                    f\"Dimension Cond: {detector.debug_info.get('dimension_condition', False)}\",\n",
    "                    f\"Velocity: {detector.debug_info.get('velocity', 0):.1f}\",\n",
    "                    f\"Angle: {detector.debug_info.get('torso_leg_angle', 0):.1f}°\"\n",
    "                ]\n",
    "                \n",
    "                for i, text in enumerate(debug_text):\n",
    "                    cv2.putText(display_img, text, (10, 30 + i*25), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)\n",
    "                \n",
    "                # Visual markers\n",
    "                if 'shoulder' in detector.debug_info and 'ankle' in detector.debug_info:\n",
    "                    shoulder = detector.debug_info['shoulder']\n",
    "                    ankle = detector.debug_info['ankle']\n",
    "                    cv2.line(display_img, \n",
    "                            (int(shoulder[0]), int(shoulder[1])),\n",
    "                            (int(ankle[0]), int(ankle[1])),\n",
    "                            (0, 255, 0) if detector.debug_info.get('shoulder_above_ankle', True) else (0, 0, 255), 2)\n",
    "                \n",
    "                if fall_detected:\n",
    "                    cv2.putText(display_img, \"FALL DETECTED!\", (width//2 - 200, 50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "        \n",
    "        display_img = cv2.resize(display_img, (width, height))\n",
    "        cv2.imshow(\"Fall Detection\", display_img)\n",
    "        if output_path:\n",
    "            out.write(display_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video('C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51550168-100c-4230-8aa1-eb6e9bc02652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
