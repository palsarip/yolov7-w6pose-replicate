{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2339af9-6541-4c27-b2ff-0e22c6861042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\yolov7\\models\\experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(w, map_location=map_location)  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Processing video (1).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (1).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (10).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (10).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (11).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (11).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (12).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (12).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (13).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (13).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (14).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (14).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (15).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (15).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (16).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (16).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (17).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (17).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (18).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Coffee_room_01\\Annotation_files\\video (18).txt: Expected 1 fields in line 4, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (1).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Home_01\\Annotation_files\\video (1).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Processing video (31).avi...\n",
      "Error parsing C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Home_02\\Annotation_files\\video (31).txt: Expected 1 fields in line 3, saw 6. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Confusion Matrix:\n",
      " [[34  0]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "from utils.datasets import letterbox\n",
    "from utils.plots import plot_skeleton_kpts\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load model YOLOv7-W6 Pose\n",
    "def load_model(weights_path):\n",
    "    model = attempt_load(weights_path, map_location=torch.device('cpu'))\n",
    "    return model\n",
    "\n",
    "# Hitung sudut antara 3 titik (kepala, pinggang, kaki)\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return np.degrees(np.arccos(cosine_angle))\n",
    "\n",
    "# Baca ground truth dari file anotasi\n",
    "def read_ground_truth(annotation_file):\n",
    "    if os.path.exists(annotation_file):\n",
    "        try:\n",
    "            df = pd.read_csv(annotation_file, header=None, sep=r'\\s+|,', engine='python')\n",
    "            print(df.head())  # Cek apakah data terbaca dengan benar\n",
    "            return set(df.iloc[:, 0].astype(int).values)  # Ambil kolom pertama\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error parsing {annotation_file}: {e}\")\n",
    "            return set()\n",
    "    return set()\n",
    "\n",
    "# Deteksi pose dan fall detection\n",
    "def detect_pose(model, image, img_size=640, fall_threshold=60):\n",
    "    img = letterbox(image, img_size, stride=64, auto=True)[0]\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).float() / 255.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(img)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "    \n",
    "    fall_detected = False\n",
    "    for det in pred:\n",
    "        if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], image.shape).round()\n",
    "            for *xyxy, conf, cls, kpts in det:\n",
    "                if kpts.dim() == 2 and kpts.shape[1] == 3:\n",
    "                    head, waist, left_foot = kpts[0].cpu().numpy(), kpts[11].cpu().numpy(), kpts[15].cpu().numpy()\n",
    "                    angle = calculate_angle(head[:2], waist[:2], left_foot[:2])\n",
    "                    if angle < fall_threshold:\n",
    "                        fall_detected = True\n",
    "                        cv2.putText(image, \"FALL DETECTED\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    plot_skeleton_kpts(image, kpts, steps=3)\n",
    "    return image, fall_detected\n",
    "\n",
    "# Buffer untuk menyimpan riwayat posisi hip\n",
    "hip_positions = []\n",
    "\n",
    "def detect_fall_video(keypoints, threshold=0.5, frame_window=5, fall_threshold=20):\n",
    "    \"\"\"\n",
    "    Mendeteksi jatuh berdasarkan pergerakan hip dalam video.\n",
    "    \n",
    "    Args:\n",
    "        keypoints (list): Array dari keypoints (17 keypoints, masing-masing x, y, confidence).\n",
    "        threshold (float): Confidence minimal agar keypoints valid.\n",
    "        frame_window (int): Jumlah frame yang disimpan untuk mendeteksi pergerakan.\n",
    "        fall_threshold (int): Seberapa besar perubahan hip_y dianggap jatuh.\n",
    "\n",
    "    Returns:\n",
    "        bool: True jika terdeteksi jatuh, False jika tidak.\n",
    "    \"\"\"\n",
    "\n",
    "    # Indeks keypoints (COCO format)\n",
    "    LEFT_HIP = 11\n",
    "    RIGHT_HIP = 12\n",
    "\n",
    "    # Ambil koordinat hip\n",
    "    left_hip = keypoints[LEFT_HIP * 3: (LEFT_HIP + 1) * 3]\n",
    "    right_hip = keypoints[RIGHT_HIP * 3: (RIGHT_HIP + 1) * 3]\n",
    "\n",
    "    # Pastikan confidence cukup tinggi\n",
    "    if left_hip[2] < threshold or right_hip[2] < threshold:\n",
    "        return False\n",
    "\n",
    "    # Hitung posisi rata-rata hip\n",
    "    hip_y = (left_hip[1] + right_hip[1]) / 2\n",
    "\n",
    "    # Simpan posisi hip di buffer\n",
    "    hip_positions.append(hip_y)\n",
    "\n",
    "    # Batasi buffer hanya menyimpan `frame_window` terakhir\n",
    "    if len(hip_positions) > frame_window:\n",
    "        hip_positions.pop(0)\n",
    "\n",
    "    # Jika buffer belum penuh, belum bisa deteksi fall\n",
    "    if len(hip_positions) < frame_window:\n",
    "        return False\n",
    "\n",
    "    # Hitung perubahan posisi hip\n",
    "    delta_hip = hip_positions[0] - hip_positions[-1]  # Perbedaan antara awal dan akhir\n",
    "\n",
    "    # Jika hip turun drastis, deteksi jatuh\n",
    "    return delta_hip > fall_threshold\n",
    "    \n",
    "# Evaluasi dengan Confusion Matrix\n",
    "def evaluate_model(predictions, ground_truths):\n",
    "    y_pred, y_true = np.array(predictions), np.array(ground_truths)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Proses video dengan anotasi\n",
    "def process_video(video_path, annotation_file, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count, predictions, ground_truths = 0, [], []\n",
    "    fall_frames = read_ground_truth(annotation_file)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        result_frame, fall_detected = detect_pose(model, frame)\n",
    "        predictions.append(int(fall_detected))\n",
    "        ground_truths.append(1 if frame_count in fall_frames else 0)\n",
    "        \n",
    "        cv2.imshow(\"Result\", result_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return predictions, ground_truths\n",
    "\n",
    "# Main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    weights_path = \"yolov7-w6-pose.pt\"\n",
    "    dataset_path = r\"C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\"\n",
    "    model = load_model(weights_path)\n",
    "    \n",
    "    video_count, all_predictions, all_ground_truths = 0, [], []\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        video_folder = os.path.join(dataset_path, folder, \"Videos\")\n",
    "        annotation_folder = os.path.join(dataset_path, folder, \"Annotation_files\")\n",
    "        if os.path.exists(video_folder) and os.path.exists(annotation_folder):\n",
    "            for video_file in sorted(os.listdir(video_folder))[:10]:  # Ambil 10 video pertama\n",
    "                if video_file.endswith(\".avi\"):\n",
    "                    video_path = os.path.join(video_folder, video_file)\n",
    "                    annotation_file = os.path.join(annotation_folder, video_file.replace(\".avi\", \".txt\"))\n",
    "                    \n",
    "                    print(f\"Processing {video_file}...\")\n",
    "                    predictions, ground_truths = process_video(video_path, annotation_file, model)\n",
    "                    \n",
    "                    all_predictions.extend(predictions)\n",
    "                    all_ground_truths.extend(ground_truths)\n",
    "                    video_count += 1\n",
    "                    if video_count >= 10:\n",
    "                        break\n",
    "    evaluate_model(all_predictions, all_ground_truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e4b4a-747b-4d34-8e9b-d32cb28e5e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
