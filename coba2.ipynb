{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8300cb8-b7eb-4e6e-872b-5cd0aacac488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.92\n",
      "Recall: 0.73\n",
      "F1-score: 0.81\n",
      "Accuracy: 0.80\n",
      "Specificity: 0.90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint\n",
    "from models.yolo import Model\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# SARAN AI TAPI MALAH TURUN\n",
    "def augment_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    brightness_factor = random.uniform(0.8, 1.2)\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "    \n",
    "    contrast_factor = random.uniform(0.8, 1.2)\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "    \n",
    "    image = np.array(image)\n",
    "    mean = 0\n",
    "    var = random.uniform(0, 0.005)\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean, sigma, image.shape).reshape(image.shape)\n",
    "    image = image + gaussian * 255\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def retinex_deillumination(image):\n",
    "    \n",
    "    # Apply Retinex deillumination to the image.\n",
    "    #  image: Input image (numpy array in BGR format).\n",
    "    # return: Image with Retinex deillumination applied (numpy array in BGR format).\n",
    "    \n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply Gaussian blur to the L channel\n",
    "    l_blur = cv2.GaussianBlur(l, (0, 0), 3)\n",
    "    \n",
    "    # Subtract the blurred L channel from the original L channel\n",
    "    l_deilluminated = cv2.subtract(l, l_blur)\n",
    "    \n",
    "    # Merge the channels back and convert to BGR\n",
    "    lab_deilluminated = cv2.merge((l_deilluminated, a, b))\n",
    "    return cv2.cvtColor(lab_deilluminated, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def preprocess_image(image, apply_augmentation=True, apply_clahe_flag=True, apply_retinex_flag=True):\n",
    "    \n",
    "    # Preprocess the image with augmentation, CLAHE, Retinex deillumination, and resizing.\n",
    "    #  image: Input image (numpy array in BGR format).\n",
    "\n",
    "    if apply_augmentation:\n",
    "        image = augment_image(image)\n",
    "\n",
    "    if apply_clahe_flag:\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    if apply_retinex_flag:\n",
    "        image = retinex_deillumination(image)\n",
    "\n",
    "    # Resize image to 640x480\n",
    "    image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_ground_truth(label_path):\n",
    "    \n",
    "    # return: Integer ground truth value (0 for 'adl', 1 for 'fall').\n",
    "    \n",
    "    with open(label_path, 'r') as file:\n",
    "        line = file.readline().strip()  # Baca baris pertama dan hapus whitespace\n",
    "\n",
    "        if not line:  # Cek jika kosong\n",
    "            return 0  # Default: asumsikan 'adl' jika tidak ada data\n",
    "\n",
    "        values = line.split()\n",
    "        if len(values) == 0:  # Jika tetap kosong setelah split\n",
    "            return 0  # Default: tidak ada deteksi jatuh\n",
    "\n",
    "        first_value = values[0]\n",
    "\n",
    "        return int(first_value)  # Konversi ke integer\n",
    "\n",
    "        \n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    \n",
    "    # Detect fall based on keypoints.\n",
    "    # keypoints: Array of keypoints (17 keypoints, each with x, y, confidence).\n",
    "    # threshold: Confidence threshold for keypoints.\n",
    "    # return: True if fall is detected, False otherwise.\n",
    "    \n",
    "    # Indices for keypoints (COCO format)\n",
    "    LEFT_SHOULDER = 5\n",
    "    RIGHT_SHOULDER = 6\n",
    "    LEFT_HIP = 11\n",
    "    RIGHT_HIP = 12\n",
    "    LEFT_KNEE = 13\n",
    "    RIGHT_KNEE = 14\n",
    "\n",
    "    # Get keypoints and confidence scores (IKUT RUMUS DARI MAIN JURNAL)\n",
    "    left_shoulder = keypoints[LEFT_SHOULDER * 3: (LEFT_SHOULDER + 1) * 3]\n",
    "    right_shoulder = keypoints[RIGHT_SHOULDER * 3: (RIGHT_SHOULDER + 1) * 3]\n",
    "    left_hip = keypoints[LEFT_HIP * 3: (LEFT_HIP + 1) * 3]\n",
    "    right_hip = keypoints[RIGHT_HIP * 3: (RIGHT_HIP + 1) * 3]\n",
    "    left_knee = keypoints[LEFT_KNEE * 3: (LEFT_KNEE + 1) * 3]\n",
    "    right_knee = keypoints[RIGHT_KNEE * 3: (RIGHT_KNEE + 1) * 3]\n",
    "\n",
    "    # Check confidence scores (IKUT RUMUS DARI MAIN JURNAL)\n",
    "    if (left_shoulder[2] < threshold or right_shoulder[2] < threshold or\n",
    "        left_hip[2] < threshold or right_hip[2] < threshold or\n",
    "        left_knee[2] < threshold or right_knee[2] < threshold):\n",
    "        return False  # Skip if any keypoint is not confident\n",
    "\n",
    "    # Calculate average y positions (IKUT RUMUS DARI MAIN JURNAL)\n",
    "    shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    hip_y = (left_hip[1] + right_hip[1]) / 2\n",
    "    knee_y = (left_knee[1] + right_knee[1]) / 2\n",
    "\n",
    "    # Check if hip and knee are below shoulders (fall condition)\n",
    "    return hip_y > shoulder_y and knee_y > shoulder_y\n",
    "\n",
    "\n",
    "ground_truth_list = []\n",
    "predictions_list = []\n",
    "\n",
    "test_images_path = \"test/images\"\n",
    "test_labels_path = \"test/labels\"\n",
    "\n",
    "for filename in os.listdir(test_images_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(test_images_path, filename)\n",
    "        label_path = os.path.join(test_labels_path, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = preprocess_image(image, apply_augmentation=False, apply_clahe_flag=True, apply_retinex_flag=True)\n",
    "        \n",
    "        image_resized = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "        image_tensor = transforms.ToTensor()(image_resized)\n",
    "        image_tensor = torch.tensor(np.array([image_tensor.numpy()]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image_tensor = image_tensor.half().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(image_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "            output = output_to_keypoint(output)\n",
    "        \n",
    "        fall_detected = 0\n",
    "        for idx in range(output.shape[0]):\n",
    "            keypoints = output[idx, 7:].T\n",
    "            if detect_fall(keypoints):\n",
    "                fall_detected = 1\n",
    "                break\n",
    "\n",
    "        \n",
    "        predictions_list.append(fall_detected)\n",
    "        ground_truth_list.append(load_ground_truth(label_path))\n",
    "\n",
    "#Calculate Metrix\n",
    "precision = precision_score(ground_truth_list, predictions_list)\n",
    "recall = recall_score(ground_truth_list, predictions_list)\n",
    "f1 = f1_score(ground_truth_list, predictions_list)\n",
    "accuracy = accuracy_score(ground_truth_list, predictions_list)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = confusion_matrix(ground_truth_list, predictions_list).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5c8bf-2227-4c3a-a04a-14414854b9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
