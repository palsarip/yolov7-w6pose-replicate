{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf16fc-460e-4c8d-bcea-e2deeadcd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model'].float().eval().to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.half()\n",
    "\n",
    "# Dataset paths (sesuaikan dengan struktur folder Anda)\n",
    "BASE_PATH = r\"C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Datasets sudah Grouping\\A Gelap\"\n",
    "PATHS = {\n",
    "    'train': {'video': os.path.join(BASE_PATH, 'video', 'train'), \n",
    "              'label': os.path.join(BASE_PATH, 'labels', 'train')},\n",
    "    'valid': {'video': os.path.join(BASE_PATH, 'video', 'valid'),\n",
    "              'label': os.path.join(BASE_PATH, 'labels', 'valid')},\n",
    "    'test': {'video': os.path.join(BASE_PATH, 'video', 'test'),\n",
    "             'label': os.path.join(BASE_PATH, 'labels', 'test')}\n",
    "}\n",
    "\n",
    "# ================== Enhanced Fall Detection ==================\n",
    "def detect_fall(keypoints, threshold=0.3):\n",
    "    # Keypoint indices\n",
    "    NOSE = 0\n",
    "    L_SHOULDER, R_SHOULDER = 5, 6\n",
    "    L_HIP, R_HIP = 11, 12\n",
    "    L_ANKLE, R_ANKLE = 15, 16\n",
    "    \n",
    "    try:\n",
    "        # Extract keypoints with lower confidence threshold\n",
    "        kp = {\n",
    "            'nose': keypoints[NOSE*3:(NOSE+1)*3],\n",
    "            'l_shoulder': keypoints[L_SHOULDER*3:(L_SHOULDER+1)*3],\n",
    "            'r_shoulder': keypoints[R_SHOULDER*3:(R_SHOULDER+1)*3],\n",
    "            'l_hip': keypoints[L_HIP*3:(L_HIP+1)*3],\n",
    "            'r_hip': keypoints[R_HIP*3:(R_HIP+1)*3],\n",
    "            'l_ankle': keypoints[L_ANKLE*3:(L_ANKLE+1)*3],\n",
    "            'r_ankle': keypoints[R_ANKLE*3:(R_ANKLE+1)*3]\n",
    "        }\n",
    "        \n",
    "        # Check if keypoints are detected\n",
    "        for k, v in kp.items():\n",
    "            if v[2] < threshold:\n",
    "                return False, \"low_confidence\", [\"Keypoint low confidence\"]\n",
    "        \n",
    "        # Calculate body parameters\n",
    "        shoulder_y = (kp['l_shoulder'][1] + kp['r_shoulder'][1]) / 2\n",
    "        feet_y = (kp['l_ankle'][1] + kp['r_ankle'][1]) / 2\n",
    "        torso_length = np.sqrt((kp['l_shoulder'][0]-kp['l_hip'][0])**2 + \n",
    "                         (kp['l_shoulder'][1]-kp['l_hip'][1])**2)\n",
    "        \n",
    "        # Enhanced conditions for dark environments\n",
    "        conditions = []\n",
    "        \n",
    "        # 1. Shoulder position relative to feet (adjusted for dark)\n",
    "        if shoulder_y > feet_y - 0.5 * torso_length:  # More tolerant threshold\n",
    "            conditions.append(\"shoulder_near_feet\")\n",
    "        \n",
    "        # 2. Body orientation\n",
    "        body_width = abs(kp['l_shoulder'][0] - kp['r_shoulder'][0])\n",
    "        body_height = abs(kp['nose'][1] - feet_y)\n",
    "        if body_width / (body_height + 1e-5) > 0.8:  # Reduced threshold\n",
    "            conditions.append(\"horizontal_pose\")\n",
    "        \n",
    "        # 3. Motion detection (fall speed)\n",
    "        global prev_shoulder_y, prev_frame_time\n",
    "        if prev_shoulder_y is not None and prev_frame_time is not None:\n",
    "            time_elapsed = time.time() - prev_frame_time\n",
    "            if time_elapsed > 0:\n",
    "                speed = (shoulder_y - prev_shoulder_y) / time_elapsed\n",
    "                if speed > 0.6:  # More sensitive to fast movements\n",
    "                    conditions.append(f\"high_speed_{speed:.1f}px\")\n",
    "        \n",
    "        # Update tracking variables\n",
    "        prev_shoulder_y = shoulder_y\n",
    "        prev_frame_time = time.time()\n",
    "        \n",
    "        # Decision making (at least 2 conditions)\n",
    "        if len(conditions) >= 2:\n",
    "            return True, \"fallen\", conditions\n",
    "        return False, \"normal\", conditions\n",
    "    \n",
    "    except Exception as e:\n",
    "        return False, \"error\", [f\"Error: {str(e)}\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize metrics for each phase\n",
    "    metrics = {\n",
    "        'train': FallDetectionMetrics(),\n",
    "        'valid': FallDetectionMetrics(),\n",
    "        'test': FallDetectionMetrics()\n",
    "    }\n",
    "    \n",
    "    # Process all phases\n",
    "    for phase in ['train', 'valid', 'test']:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing {phase} set (Video: {len(os.listdir(PATHS[phase]['video']))} videos)\")\n",
    "        \n",
    "        # Load annotations\n",
    "        annotations = load_annotations(PATHS[phase]['label'])\n",
    "        \n",
    "        # Process videos\n",
    "        for video_file in os.listdir(PATHS[phase]['video']):\n",
    "            if video_file.endswith(\".avi\"):\n",
    "                video_path = os.path.join(PATHS[phase]['video'], video_file)\n",
    "                process_video(video_path, annotations, metrics[phase])\n",
    "        \n",
    "        # Save results\n",
    "        metrics[phase].save_results(f\"results_{phase}\")\n",
    "        print(f\"{phase} metrics saved to results_{phase}/\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    for phase in ['train', 'valid', 'test']:\n",
    "        res = metrics[phase].calculate_metrics()\n",
    "        print(f\"\\n{phase.upper():<6} Precision: {res['precision']:.3f} | Recall: {res['recall']:.3f} | F1: {res['f1_score']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
