{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a958600-39d3-4dc2-bfeb-aa1b9bfa11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration\n",
    "input_dir = \"runs/detect/exp/labels\"  # Folder containing YOLO detection .txt files\n",
    "output_file = \"converted_annotations.txt\"  # Output file in your desired format\n",
    "total_frames = 157  # Total number of frames in your video\n",
    "\n",
    "def convert_yolo_to_abs(yolo_coords, img_width=640, img_height=480):\n",
    "    \"\"\"Convert YOLO format [class, x_center, y_center, width, height] to absolute coordinates\"\"\"\n",
    "    class_id = int(yolo_coords[0])\n",
    "    x_center = float(yolo_coords[1]) * img_width\n",
    "    y_center = float(yolo_coords[2]) * img_height\n",
    "    width = float(yolo_coords[3]) * img_width\n",
    "    height = float(yolo_coords[4]) * img_height\n",
    "    return class_id, width, height, x_center, y_center\n",
    "\n",
    "# Get all detection files and sort them numerically\n",
    "detection_files = sorted(glob.glob(os.path.join(input_dir, \"*.txt\")), \n",
    "                       key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    # Write total frames count (as in your example)\n",
    "    out_f.write(f\"{total_frames}\\n\")\n",
    "    \n",
    "    # Process each frame\n",
    "    for frame_num in range(1, total_frames + 1):\n",
    "        frame_file = os.path.join(input_dir, f\"{frame_num}.txt\")\n",
    "        \n",
    "        # Default values when no detection\n",
    "        class_id = 1\n",
    "        width = height = x_center = y_center = 0\n",
    "        \n",
    "        # If detection exists for this frame\n",
    "        if os.path.exists(frame_file):\n",
    "            with open(frame_file, \"r\") as in_f:\n",
    "                lines = in_f.readlines()\n",
    "                if lines:  # Take first detection only (modify if you need multiple)\n",
    "                    yolo_coords = lines[0].strip().split()\n",
    "                    class_id, width, height, x_center, y_center = convert_yolo_to_abs(yolo_coords)\n",
    "        \n",
    "        # Write in your desired format: frame_num,class_id,width,height,x_center,y_center\n",
    "        out_f.write(f\"{frame_num},{class_id},{int(width)},{int(height)},{int(x_center)},{int(y_center)}\\n\")\n",
    "\n",
    "print(f\"Conversion complete. Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0cdf07-1dd6-4505-b9ad-1e6908a5c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person detections saved to person_annotations.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration\n",
    "input_dir = \"runs/detect/exp/labels\"  # YOLO output folder\n",
    "output_file = \"person_annotations.txt\"  # Output file\n",
    "video_width = 640  # Adjust to your video dimensions\n",
    "video_height = 480  # Adjust to your video dimensions\n",
    "total_frames = 285  # Total frames in your video\n",
    "\n",
    "def convert_yolo_to_abs(yolo_coords):\n",
    "    \"\"\"Convert YOLO format to absolute coordinates for persons only\"\"\"\n",
    "    class_id = int(yolo_coords[0])\n",
    "    # Only process person detections (class 0)\n",
    "    if class_id != 0:\n",
    "        return None\n",
    "    \n",
    "    x_center = float(yolo_coords[1]) * video_width\n",
    "    y_center = float(yolo_coords[2]) * video_height\n",
    "    width = float(yolo_coords[3]) * video_width\n",
    "    height = float(yolo_coords[4]) * video_height\n",
    "    confidence = float(yolo_coords[5]) if len(yolo_coords) > 5 else 1.0\n",
    "    \n",
    "    # Return only if confidence > 0.5 (adjust as needed)\n",
    "    if confidence > 0.5:\n",
    "        return width, height, x_center, y_center\n",
    "    return None\n",
    "\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    # Write total frames count\n",
    "    out_f.write(f\"{total_frames}\\n\")\n",
    "    \n",
    "    for frame_num in range(1, total_frames + 1):\n",
    "        txt_file = os.path.join(input_dir, f\"{frame_num}.txt\")\n",
    "        width = height = x_center = y_center = 0\n",
    "        class_id = 1  # Default class if no detection\n",
    "        \n",
    "        if os.path.exists(txt_file):\n",
    "            with open(txt_file, \"r\") as in_f:\n",
    "                for line in in_f:\n",
    "                    coords = line.strip().split()\n",
    "                    result = convert_yolo_to_abs(coords)\n",
    "                    if result:\n",
    "                        width, height, x_center, y_center = result\n",
    "                        class_id = 1  # Your desired class ID for persons\n",
    "                        break  # Take first confident person detection\n",
    "        \n",
    "        # Write in your format\n",
    "        out_f.write(f\"{frame_num},{class_id},{int(width)},{int(height)},{int(x_center)},{int(y_center)}\\n\")\n",
    "\n",
    "print(f\"Person detections saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b886bbb-6282-4eb1-9b14-541775f3dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation file telah dibuat: annotations.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Path ke video\n",
    "video_path = r\"C:\\Users\\LENOVO\\Documents\\A Skripsi\\datasets\\FallDataset\\Dataset\\Lecture room\\Videos\\video (1).avi\"\n",
    "\n",
    "# Buka video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Periksa apakah video berhasil dibuka\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Tidak dapat membuka video.\")\n",
    "    exit()\n",
    "\n",
    "# Simpan hasil annotation\n",
    "annotations = []\n",
    "\n",
    "frame_id = 1\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Hentikan jika video selesai\n",
    "    \n",
    "    # Placeholder untuk deteksi objek menggunakan YOLOv7-W6-Pose\n",
    "    # Misalnya, kita mendapatkan kelas, x_min, y_min, x_max, y_max\n",
    "    class_id = 1  # Sesuaikan dengan hasil deteksi\n",
    "    x_min, y_min, x_max, y_max = 0, 0, 0, 0  # Sesuaikan dengan hasil deteksi\n",
    "    \n",
    "    # Simpan hasil dalam format yang diminta\n",
    "    annotations.append([frame_id, class_id, x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    frame_id += 1\n",
    "\n",
    "# Simpan ke file CSV\n",
    "annotation_df = pd.DataFrame(annotations, columns=[\"Frame\", \"Class\", \"X_min\", \"Y_min\", \"X_max\", \"Y_max\"])\n",
    "annotation_df.to_csv(\"annotations.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Annotation file telah dibuat: annotations.csv\")\n",
    "\n",
    "# Tutup video\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff40f44-22d8-4a02-8358-0704ddd7cef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e1fb7-a705-4f81-b522-f42f9e12e4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
