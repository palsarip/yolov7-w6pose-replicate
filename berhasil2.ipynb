{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df9a488-2c44-4b10-b31e-ce40afa809e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3638.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to the image (brightness, contrast, noise, etc.).\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :return: Augmented image (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    # Convert to PIL Image for easier augmentation (PIL uses RGB format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Random brightness adjustment\n",
    "    brightness_factor = random.uniform(0.8, 1.2)  # Adjust brightness randomly\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "\n",
    "    # Random contrast adjustment\n",
    "    contrast_factor = random.uniform(0.8, 1.2)  # Adjust contrast randomly\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "\n",
    "    # Convert back to numpy array (RGB format)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    mean = 0\n",
    "    var = random.uniform(0, 0.005)  # Random noise variance (reduced to avoid extreme changes)\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean, sigma, image.shape).reshape(image.shape)\n",
    "    image = image + gaussian * 255\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Convert back to BGR format for OpenCV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    \"\"\"\n",
    "    Apply CLAHE to the image to enhance contrast.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :return: Image with CLAHE applied (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "\n",
    "    # Merge the channels back\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    image_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return image_clahe\n",
    "\n",
    "def preprocess_image(image, apply_augmentation=True, apply_clahe_flag=True):\n",
    "    \"\"\"\n",
    "    Preprocess the image with augmentation and CLAHE.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :param apply_augmentation: Whether to apply augmentation.\n",
    "    :param apply_clahe_flag: Whether to apply CLAHE.\n",
    "    :return: Preprocessed image (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    if apply_augmentation:\n",
    "        image = augment_image(image)\n",
    "\n",
    "    if apply_clahe_flag:\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect fall based on keypoints.\n",
    "    :param keypoints: Array of keypoints (17 keypoints, each with x, y, confidence).\n",
    "    :param threshold: Confidence threshold for keypoints.\n",
    "    :return: True if fall is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    # Indices for keypoints (COCO format)\n",
    "    LEFT_SHOULDER = 5\n",
    "    RIGHT_SHOULDER = 6\n",
    "    LEFT_HIP = 11\n",
    "    RIGHT_HIP = 12\n",
    "    LEFT_KNEE = 13\n",
    "    RIGHT_KNEE = 14\n",
    "\n",
    "    # Get keypoints and confidence scores\n",
    "    left_shoulder = keypoints[LEFT_SHOULDER * 3: (LEFT_SHOULDER + 1) * 3]\n",
    "    right_shoulder = keypoints[RIGHT_SHOULDER * 3: (RIGHT_SHOULDER + 1) * 3]\n",
    "    left_hip = keypoints[LEFT_HIP * 3: (LEFT_HIP + 1) * 3]\n",
    "    right_hip = keypoints[RIGHT_HIP * 3: (RIGHT_HIP + 1) * 3]\n",
    "    left_knee = keypoints[LEFT_KNEE * 3: (LEFT_KNEE + 1) * 3]\n",
    "    right_knee = keypoints[RIGHT_KNEE * 3: (RIGHT_KNEE + 1) * 3]\n",
    "\n",
    "    # Check confidence scores\n",
    "    if (left_shoulder[2] < threshold or right_shoulder[2] < threshold or\n",
    "        left_hip[2] < threshold or right_hip[2] < threshold or\n",
    "        left_knee[2] < threshold or right_knee[2] < threshold):\n",
    "        return False  # Skip if any keypoint is not confident\n",
    "\n",
    "    # Calculate average y positions\n",
    "    shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    hip_y = (left_hip[1] + right_hip[1]) / 2\n",
    "    knee_y = (left_knee[1] + right_knee[1]) / 2\n",
    "\n",
    "    # Check if hip and knee are below shoulders (fall condition)\n",
    "    if hip_y > shoulder_y and knee_y > shoulder_y:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Real-time fall detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    preprocessed_frame = preprocess_image(frame, apply_augmentation=True, apply_clahe_flag=True)\n",
    "\n",
    "    # Resize and normalize the frame for YOLOv7-pose\n",
    "    image = letterbox(preprocessed_frame, 960, stride=64, auto=True)[0]\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "\n",
    "        # Detect fall\n",
    "        if detect_fall(keypoints):\n",
    "            cv2.putText(nimg, \"Fall Detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "\n",
    "    # Break if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Clear GPU cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f066379-5ec1-4421-b739-2258f92a6b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "545d5e58-569b-45f3-92bb-9e8e06731512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "import math\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# Constants from the journal\n",
    "ALPHA = 0.5  # Adjustment factor for height threshold\n",
    "SPEED_THRESHOLD = 0.5  # Vertical speed threshold for fall detection (pixels/frame)\n",
    "ANGLE_THRESHOLD = 45  # Degrees threshold between torso and legs\n",
    "\n",
    "# Previous frame data for speed calculation\n",
    "prev_shoulder_y = None\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between points a, b, c in degrees\"\"\"\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    global prev_shoulder_y, frame_count\n",
    "    \n",
    "    LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_KNEE, RIGHT_KNEE, LEFT_ANKLE, RIGHT_ANKLE = 5, 6, 11, 12, 13, 14, 15, 16\n",
    "    \n",
    "    keypoints_conf = [keypoints[i * 3: (i + 1) * 3] for i in [LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_KNEE, RIGHT_KNEE, LEFT_ANKLE, RIGHT_ANKLE]]\n",
    "    \n",
    "    # Check if keypoints are detected with sufficient confidence\n",
    "    if any(kp[2] < threshold for kp in keypoints_conf[:4] + keypoints_conf[6:8]):\n",
    "        return False\n",
    "    \n",
    "    # Current shoulder y position (average of left and right)\n",
    "    current_shoulder_y = (keypoints_conf[0][1] + keypoints_conf[1][1]) / 2\n",
    "    \n",
    "    # Calculate vertical speed if we have previous data\n",
    "    vertical_speed = 0\n",
    "    if prev_shoulder_y is not None and frame_count > 0:\n",
    "        vertical_speed = abs(current_shoulder_y - prev_shoulder_y) / frame_count\n",
    "    \n",
    "    prev_shoulder_y = current_shoulder_y\n",
    "    frame_count = 0  # Reset counter after speed calculation\n",
    "    \n",
    "    # Calculate length factor (from shoulder to hip)\n",
    "    length_factor = calculate_length_factor(keypoints_conf[0][:2], keypoints_conf[2][:2])\n",
    "    \n",
    "    # Check shoulder height relative to feet (with length factor adjustment)\n",
    "    shoulder_low = (keypoints_conf[0][1] <= keypoints_conf[6][1] + ALPHA * length_factor and\n",
    "                    keypoints_conf[1][1] <= keypoints_conf[7][1] + ALPHA * length_factor)\n",
    "    \n",
    "    # Calculate body dimensions\n",
    "    body_height = abs(keypoints_conf[0][1] - keypoints_conf[6][1])\n",
    "    body_width = abs(keypoints_conf[0][0] - keypoints_conf[1][0])\n",
    "    horizontal_position = body_height < body_width\n",
    "    \n",
    "    # Calculate angle between hip, knee and ankle (for left and right legs)\n",
    "    left_leg_angle = calculate_angle(keypoints_conf[2][:2], keypoints_conf[4][:2], keypoints_conf[6][:2])\n",
    "    right_leg_angle = calculate_angle(keypoints_conf[3][:2], keypoints_conf[5][:2], keypoints_conf[7][:2])\n",
    "    leg_angle = min(left_leg_angle, right_leg_angle)\n",
    "    \n",
    "    # Fall conditions from journal:\n",
    "    # 1. Shoulders low relative to feet\n",
    "    # 2. Body in horizontal position\n",
    "    # 3. Either rapid movement (speed) or acute angle between torso and legs\n",
    "    if shoulder_low and horizontal_position:\n",
    "        if vertical_speed > SPEED_THRESHOLD or leg_angle < ANGLE_THRESHOLD:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Path to video file\n",
    "video_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\A Skripsi\\\\datasets\\\\FallDataset\\\\Dataset\\\\Coffee_room_01\\\\Videos\\\\video (1).avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    \n",
    "    image = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "    image_ = image.copy()\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "\n",
    "        if detect_fall(keypoints):\n",
    "            cv2.putText(nimg, \"Fall Detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#IIni yg vid 1 nya worked ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448441c9-83a2-49b7-afb9-2315ffa4f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FPS: 25.0, Processing at 25 FPS, skipping 0 frames between processed frames\n",
      "Processing complete. Actual FPS: 29.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# Constants from the journal\n",
    "ALPHA = 0.5  # Adjustment factor for height threshold\n",
    "SPEED_THRESHOLD = 0.5  # Vertical speed threshold for fall detection (pixels/frame)\n",
    "ANGLE_THRESHOLD = 45  # Degrees threshold between torso and legs\n",
    "TARGET_FPS = 25  # Target frames per second for processing\n",
    "\n",
    "# Previous frame data for speed calculation\n",
    "prev_shoulder_y = None\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between points a, b, c in degrees\"\"\"\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    global prev_shoulder_y, frame_count\n",
    "    \n",
    "    LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_KNEE, RIGHT_KNEE, LEFT_ANKLE, RIGHT_ANKLE = 5, 6, 11, 12, 13, 14, 15, 16\n",
    "    \n",
    "    keypoints_conf = [keypoints[i * 3: (i + 1) * 3] for i in [LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_KNEE, RIGHT_KNEE, LEFT_ANKLE, RIGHT_ANKLE]]\n",
    "    \n",
    "    # Check if keypoints are detected with sufficient confidence\n",
    "    if any(kp[2] < threshold for kp in keypoints_conf[:4] + keypoints_conf[6:8]):\n",
    "        return False\n",
    "    \n",
    "    # Current shoulder y position (average of left and right)\n",
    "    current_shoulder_y = (keypoints_conf[0][1] + keypoints_conf[1][1]) / 2\n",
    "    \n",
    "    # Calculate vertical speed if we have previous data\n",
    "    vertical_speed = 0\n",
    "    if prev_shoulder_y is not None and frame_count > 0:\n",
    "        vertical_speed = abs(current_shoulder_y - prev_shoulder_y) / frame_count\n",
    "    \n",
    "    prev_shoulder_y = current_shoulder_y\n",
    "    frame_count = 0  # Reset counter after speed calculation\n",
    "    \n",
    "    # Calculate length factor (from shoulder to hip)\n",
    "    length_factor = calculate_length_factor(keypoints_conf[0][:2], keypoints_conf[2][:2])\n",
    "    \n",
    "    # Check shoulder height relative to feet (with length factor adjustment)\n",
    "    shoulder_low = (keypoints_conf[0][1] <= keypoints_conf[6][1] + ALPHA * length_factor and\n",
    "                    keypoints_conf[1][1] <= keypoints_conf[7][1] + ALPHA * length_factor)\n",
    "    \n",
    "    # Calculate body dimensions\n",
    "    body_height = abs(keypoints_conf[0][1] - keypoints_conf[6][1])\n",
    "    body_width = abs(keypoints_conf[0][0] - keypoints_conf[1][0])\n",
    "    horizontal_position = body_height < body_width\n",
    "    \n",
    "    # Calculate angle between hip, knee and ankle (for left and right legs)\n",
    "    left_leg_angle = calculate_angle(keypoints_conf[2][:2], keypoints_conf[4][:2], keypoints_conf[6][:2])\n",
    "    right_leg_angle = calculate_angle(keypoints_conf[3][:2], keypoints_conf[5][:2], keypoints_conf[7][:2])\n",
    "    leg_angle = min(left_leg_angle, right_leg_angle)\n",
    "    \n",
    "    # Fall conditions from journal:\n",
    "    # 1. Shoulders low relative to feet\n",
    "    # 2. Body in horizontal position\n",
    "    # 3. Either rapid movement (speed) or acute angle between torso and legs\n",
    "    if shoulder_low and horizontal_position:\n",
    "        if vertical_speed > SPEED_THRESHOLD or leg_angle < ANGLE_THRESHOLD:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Path to video file\n",
    "video_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\A Skripsi\\\\datasets\\\\FallDataset\\\\Dataset\\\\Coffee_room_01\\\\Videos\\\\video (2).avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Calculate skip frames to achieve 25 FPS\n",
    "if original_fps > 0:\n",
    "    skip_frames = max(1, int(round(original_fps / TARGET_FPS)))\n",
    "else:\n",
    "    skip_frames = 1  # Default if FPS info not available\n",
    "\n",
    "print(f\"Original FPS: {original_fps}, Processing at {TARGET_FPS} FPS, skipping {skip_frames-1} frames between processed frames\")\n",
    "\n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    "processed_frames = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_counter += 1\n",
    "    \n",
    "    # Skip frames to achieve target FPS\n",
    "    if frame_counter % skip_frames != 0:\n",
    "        continue\n",
    "    \n",
    "    processed_frames += 1\n",
    "    frame_count += 1\n",
    "    \n",
    "    image = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "    image_ = image.copy()\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "\n",
    "        if detect_fall(keypoints):\n",
    "            cv2.putText(nimg, \"Fall Detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Calculate and display actual processing FPS\n",
    "    elapsed_time = time.time() - start_time\n",
    "    current_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0\n",
    "    cv2.putText(nimg, f\"FPS: {current_fps:.1f}\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Calculate final processing statistics\n",
    "total_time = time.time() - start_time\n",
    "actual_fps = processed_frames / total_time if total_time > 0 else 0\n",
    "print(f\"Processing complete. Actual FPS: {actual_fps:.2f}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca1b740b-4085-4dba-b3b4-e737098930fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_shoulder_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 130\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     vertical_speed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 130\u001b[0m prev_shoulder_y \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_shoulder_y\u001b[49m\n\u001b[0;32m    131\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m current_time\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Preprocess and inference\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'current_shoulder_y' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "import math\n",
    "import time\n",
    "# Update constants\n",
    "SPEED_THRESHOLD = 100  # Pixels per second (contoh: 0.5 pixel/frame * 25 fps = 12.5 pixel/s)\n",
    "\n",
    "# Track time between frames\n",
    "prev_time = None\n",
    "prev_shoulder_y = None\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# Constants from the journal\n",
    "ALPHA = 0.5  # Adjustment factor for height threshold\n",
    "SPEED_THRESHOLD = 0.5  # Vertical speed threshold (pixels/frame)\n",
    "ANGLE_THRESHOLD = 45  # Degrees threshold between torso and legs\n",
    "TARGET_FPS = 25  # Target processing FPS\n",
    "\n",
    "# Previous frame data for speed calculation\n",
    "prev_shoulder_y = None\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between points a, b, c in degrees (b as vertex)\"\"\"\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1, 1))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    global prev_shoulder_y, frame_count\n",
    "    \n",
    "    # Keypoint indices\n",
    "    LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_ANKLE, RIGHT_ANKLE = 5, 6, 11, 12, 15, 16\n",
    "    \n",
    "    keypoints_conf = [keypoints[i * 3: (i + 1) * 3] for i in [LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_ANKLE, RIGHT_ANKLE]]\n",
    "    \n",
    "    # Check keypoint confidence\n",
    "    if any(kp[2] < threshold for kp in keypoints_conf):\n",
    "        return False\n",
    "    \n",
    "    # Calculate vertical speed (shoulder movement)\n",
    "    current_shoulder_y = (keypoints_conf[0][1] + keypoints_conf[1][1]) / 2\n",
    "    vertical_speed = 0\n",
    "    if prev_shoulder_y is not None and frame_count > 0:\n",
    "        vertical_speed = abs(current_shoulder_y - prev_shoulder_y) / frame_count\n",
    "    prev_shoulder_y = current_shoulder_y\n",
    "    frame_count = 0  # Reset counter\n",
    "    \n",
    "    # Length factor (shoulder to hip)\n",
    "    length_factor = calculate_length_factor(keypoints_conf[0][:2], keypoints_conf[2][:2])\n",
    "    \n",
    "    # Shoulder and torso height check (relative to feet)\n",
    "    shoulder_low = (keypoints_conf[0][1] <= keypoints_conf[4][1] + ALPHA * length_factor and\n",
    "                    keypoints_conf[1][1] <= keypoints_conf[5][1] + ALPHA * length_factor)\n",
    "    torso_low = (keypoints_conf[2][1] <= keypoints_conf[4][1] + ALPHA * length_factor and\n",
    "                 keypoints_conf[3][1] <= keypoints_conf[5][1] + ALPHA * length_factor)\n",
    "    \n",
    "    # Body dimensions\n",
    "    body_height = abs(keypoints_conf[0][1] - keypoints_conf[4][1])\n",
    "    body_width = abs(keypoints_conf[0][0] - keypoints_conf[1][0])\n",
    "    horizontal_position = body_height < body_width\n",
    "    \n",
    "    # Torso-leg angle calculation (at hip)\n",
    "    left_angle = calculate_angle(keypoints_conf[0][:2], keypoints_conf[2][:2], keypoints_conf[4][:2])\n",
    "    right_angle = calculate_angle(keypoints_conf[1][:2], keypoints_conf[3][:2], keypoints_conf[5][:2])\n",
    "    torso_leg_angle = min(left_angle, right_angle)\n",
    "\n",
    "    # Gunakan vertical_speed yang sudah dihitung di main loop\n",
    "    if shoulder_low and torso_low and horizontal_position:\n",
    "        if abs(vertical_speed) > SPEED_THRESHOLD or torso_leg_angle < ANGLE_THRESHOLD:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "    # Fall conditions (all must be true)\n",
    "    if shoulder_low and torso_low and horizontal_position:\n",
    "        if vertical_speed > SPEED_THRESHOLD or torso_leg_angle < ANGLE_THRESHOLD:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Video processing with FPS control\n",
    "video_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\A Skripsi\\\\datasets\\\\FallDataset\\\\Dataset\\\\Coffee_room_01\\\\Videos\\\\video (1).avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "skip_frames = max(1, int(original_fps / TARGET_FPS))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % skip_frames != 0:\n",
    "        continue\n",
    "\n",
    "    current_time = time.perf_counter()\n",
    "\n",
    "    # Hitung vertical speed\n",
    "    if prev_shoulder_y is not None and prev_time is not None:\n",
    "        time_diff = current_time - prev_time\n",
    "        vertical_speed = (current_shoulder_y - prev_shoulder_y) / time_diff  # pixel/second\n",
    "    else:\n",
    "        vertical_speed = 0\n",
    "    \n",
    "    prev_shoulder_y = current_shoulder_y\n",
    "    prev_time = current_time\n",
    "\n",
    "    # Preprocess and inference\n",
    "    image = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()]))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "    \n",
    "    # Visualize results\n",
    "    nimg = image[0].permute(1, 2, 0).cpu().numpy() * 255\n",
    "    nimg = cv2.cvtColor(nimg.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "        if detect_fall(keypoints, vertical_speed):\n",
    "            cv2.putText(nimg, \"FALL DETECTED!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1cbae1a-9277-489c-aa70-7c57426a85de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 184\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# Tampilkan kondisi yang gagal\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     y_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cond, met \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    185\u001b[0m         color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m met \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    186\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOK\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmet\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAIL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# Constants from the journal\n",
    "ALPHA = 0.5          # Adjustment factor for height threshold\n",
    "SPEED_THRESHOLD = 100 # Pixels per second (harus dikalibrasi)\n",
    "ANGLE_THRESHOLD = 45 # Degrees threshold between torso and legs\n",
    "TARGET_FPS = 25      # Target processing FPS\n",
    "\n",
    "# Tracking variables\n",
    "prev_shoulder_y = None\n",
    "prev_time = None\n",
    "\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between points a, b, c in degrees (b as vertex)\"\"\"\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1, 1))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def detect_fall(keypoints, vertical_speed, threshold=0.5, debug_image=None):\n",
    "    # Keypoint indices\n",
    "    LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_ANKLE, RIGHT_ANKLE = 5, 6, 11, 12, 15, 16\n",
    "    \n",
    "    keypoints_conf = [keypoints[i * 3: (i + 1) * 3] for i in [LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_HIP, RIGHT_HIP, LEFT_ANKLE, RIGHT_ANKLE]]\n",
    "    \n",
    "    # Debug: Gambar semua keypoint\n",
    "    colors = [(0,255,0), (0,0,255), (255,0,0), (255,255,0), (0,255,255), (255,0,255)]\n",
    "    for i, kp in enumerate(keypoints_conf):\n",
    "        if kp[2] > threshold and debug_image is not None:\n",
    "            x, y = int(kp[0]), int(kp[1])\n",
    "            cv2.circle(debug_image, (x, y), 5, colors[i], -1)\n",
    "    \n",
    "    # Check keypoint confidence\n",
    "    if any(kp[2] < threshold for kp in keypoints_conf):\n",
    "        return False, \"Keypoint confidence low\"\n",
    "    \n",
    "    # Length factor (shoulder to hip)\n",
    "    length_factor = calculate_length_factor(keypoints_conf[0][:2], keypoints_conf[2][:2])\n",
    "    \n",
    "    # Shoulder and torso height check (relative to feet)\n",
    "    shoulder_threshold_left = keypoints_conf[4][1] + ALPHA * length_factor\n",
    "    shoulder_threshold_right = keypoints_conf[5][1] + ALPHA * length_factor\n",
    "    torso_threshold_left = keypoints_conf[4][1] + ALPHA * length_factor\n",
    "    torso_threshold_right = keypoints_conf[5][1] + ALPHA * length_factor\n",
    "    \n",
    "    shoulder_low = (keypoints_conf[0][1] <= shoulder_threshold_left and\n",
    "                    keypoints_conf[1][1] <= shoulder_threshold_right)\n",
    "    torso_low = (keypoints_conf[2][1] <= torso_threshold_left and\n",
    "                 keypoints_conf[3][1] <= torso_threshold_right)\n",
    "    \n",
    "    # Body dimensions\n",
    "    body_height = abs(keypoints_conf[0][1] - keypoints_conf[4][1])\n",
    "    body_width = abs(keypoints_conf[0][0] - keypoints_conf[1][0])\n",
    "    horizontal_position = body_height < body_width\n",
    "    \n",
    "    # Torso-leg angle calculation (at hip)\n",
    "    left_angle = calculate_angle(keypoints_conf[0][:2], keypoints_conf[2][:2], keypoints_conf[4][:2])\n",
    "    right_angle = calculate_angle(keypoints_conf[1][:2], keypoints_conf[3][:2], keypoints_conf[5][:2])\n",
    "    torso_leg_angle = min(left_angle, right_angle)\n",
    "    \n",
    "    # Debug: Gambar garis dan teks\n",
    "    if debug_image is not None:\n",
    "        # Gambar garis tinggi bahu\n",
    "        y_shoulder_threshold = int((shoulder_threshold_left + shoulder_threshold_right)/2)\n",
    "        cv2.line(debug_image, (0, y_shoulder_threshold), (debug_image.shape[1], y_shoulder_threshold), (0,255,0), 2)\n",
    "        \n",
    "        # Gambar sudut\n",
    "        cv2.putText(debug_image, f\"Angle: {torso_leg_angle:.1f}deg\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        cv2.putText(debug_image, f\"Speed: {vertical_speed:.1f}px/s\", (50, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        cv2.putText(debug_image, f\"Body: W{body_width:.1f} > H{body_height:.1f}\", (50, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "    \n",
    "    # Fall conditions\n",
    "    conditions = {\n",
    "        \"Shoulder Low\": shoulder_low,\n",
    "        \"Torso Low\": torso_low,\n",
    "        \"Horizontal Position\": horizontal_position,\n",
    "        \"Speed/Angle\": (abs(vertical_speed) > SPEED_THRESHOLD) or (torso_leg_angle < ANGLE_THRESHOLD)\n",
    "    }\n",
    "    \n",
    "    if all([conditions[\"Shoulder Low\"], conditions[\"Torso Low\"], conditions[\"Horizontal Position\"]]) and conditions[\"Speed/Angle\"]:\n",
    "        return True, \"Fall detected\"\n",
    "    else:\n",
    "        return False, conditions\n",
    "\n",
    "# Video processing\n",
    "video_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\A Skripsi\\\\datasets\\\\FallDataset\\\\Dataset\\\\Coffee_room_01\\\\Videos\\\\video (1).avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Frame skipping logic\n",
    "skip_frames = max(1, int(original_fps / TARGET_FPS)) if original_fps > 0 else 1\n",
    "\n",
    "# Initialize tracking\n",
    "current_shoulder_y = None\n",
    "vertical_speed = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Skip frames for target FPS\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) % skip_frames != 0:\n",
    "        continue\n",
    "    \n",
    "    # Preprocess\n",
    "    image = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "    image_tensor = transforms.ToTensor()(image)\n",
    "    image_tensor = torch.tensor(np.array([image_tensor.numpy()]))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor = image_tensor.half().to(device)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image_tensor)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "    \n",
    "    # Calculate vertical speed\n",
    "    current_time = time.perf_counter()\n",
    "    if output.shape[0] > 0:\n",
    "        keypoints = output[0, 7:].T\n",
    "        left_shoulder_y = keypoints[5*3+1]\n",
    "        right_shoulder_y = keypoints[6*3+1]\n",
    "        current_shoulder_y = (left_shoulder_y + right_shoulder_y) / 2\n",
    "        \n",
    "        if prev_shoulder_y is not None and prev_time is not None:\n",
    "            time_diff = current_time - prev_time\n",
    "            vertical_speed = (current_shoulder_y - prev_shoulder_y) / time_diff  # pixel/second\n",
    "        else:\n",
    "            vertical_speed = 0\n",
    "        \n",
    "        prev_shoulder_y = current_shoulder_y\n",
    "        prev_time = current_time\n",
    "    \n",
    "    # Visualize\n",
    "    nimg = image_tensor[0].permute(1, 2, 0).cpu().numpy() * 255\n",
    "    nimg = cv2.cvtColor(nimg.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "        \n",
    "        fall_detected, status = detect_fall(keypoints, vertical_speed, debug_image=nimg)\n",
    "        \n",
    "        if fall_detected:\n",
    "            cv2.putText(nimg, \"FALL DETECTED!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # Tampilkan kondisi yang gagal\n",
    "            y_offset = 250\n",
    "            for cond, met in status.items():\n",
    "                color = (0, 255, 0) if met else (0, 0, 255)\n",
    "                text = f\"{cond}: {'OK' if met else 'FAIL'}\"\n",
    "                cv2.putText(nimg, text, (50, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                y_offset += 30\n",
    "    \n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "    \n",
    "    # Show FPS\n",
    "    fps = 1.0 / (time.perf_counter() - prev_time) if prev_time else 0\n",
    "    cv2.putText(nimg, f\"Speed: {vertical_speed:.1f} px/s\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9f3d907-1330-463f-a37d-f9b893e6d29c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (823094185.py, line 90)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 90\u001b[1;36m\u001b[0m\n\u001b[1;33m    torso_low = (\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "\n",
    "# Inisialisasi device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model YOLOv7-pose\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "# Parameter dari jurnal\n",
    "ALPHA = 0.5          # Faktor penyesuaian tinggi\n",
    "SPEED_THRESHOLD = 100 # Ambang kecepatan (pixel/detik)\n",
    "ANGLE_THRESHOLD = 45  # Ambang sudut (derajat)\n",
    "TARGET_FPS = 25       # Target FPS pemrosesan\n",
    "KP_CONFIDENCE = 0.5   # Ambang keypoint confidence\n",
    "\n",
    "# Variabel pelacakan\n",
    "prev_shoulder_y = None\n",
    "prev_time = None\n",
    "\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    \"\"\"Menghitung faktor panjang antara bahu dan torso\"\"\"\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Menghitung sudut antara tiga titik (b sebagai vertex)\"\"\"\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1, 1))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def detect_fall(keypoints, vertical_speed, debug_image=None, threshold=0.5):\n",
    "    # Keypoint indices sesuai jurnal\n",
    "    LEFT_SHOULDER, RIGHT_SHOULDER = 5, 6\n",
    "    LEFT_HIP, RIGHT_HIP = 11, 12\n",
    "    LEFT_ANKLE, RIGHT_ANKLE = 15, 16\n",
    "\n",
    "    # Ekstrak keypoint dengan confidence\n",
    "    keypoints_dict = {\n",
    "        'left_shoulder': keypoints[LEFT_SHOULDER*3:(LEFT_SHOULDER+1)*3],\n",
    "        'right_shoulder': keypoints[RIGHT_SHOULDER*3:(RIGHT_SHOULDER+1)*3],\n",
    "        'left_torso': keypoints[LEFT_HIP*3:(LEFT_HIP+1)*3],\n",
    "        'right_torso': keypoints[RIGHT_HIP*3:(RIGHT_HIP+1)*3],\n",
    "        'left_foot': keypoints[LEFT_ANKLE*3:(LEFT_ANKLE+1)*3],\n",
    "        'right_foot': keypoints[RIGHT_ANKLE*3:(RIGHT_ANKLE+1)*3]\n",
    "    }\n",
    "\n",
    "    # Inisialisasi kondisi\n",
    "    conditions = {\n",
    "        'keypoints_valid': False,\n",
    "        'shoulder_low': False,\n",
    "        'torso_low': False,\n",
    "        'horizontal_position': False,\n",
    "        'speed_angle': False\n",
    "    }\n",
    "    message = \"\"\n",
    "\n",
    "    # Cek confidence keypoint\n",
    "    if any(kp[2] < threshold for kp in keypoints_dict.values()):\n",
    "        return False, conditions, \"Keypoint confidence low\"\n",
    "    \n",
    "    conditions['keypoints_valid'] = True\n",
    "\n",
    "    # 1. Hitung length factor\n",
    "    L_factor = calculate_length_factor(\n",
    "        keypoints_dict['left_shoulder'][:2], \n",
    "        keypoints_dict['left_torso'][:2]\n",
    "    )\n",
    "\n",
    "    # 2. Threshold tinggi\n",
    "    shoulder_low = (\n",
    "        (keypoints_dict['left_shoulder'][1] <= keypoints_dict['left_foot'][1] + ALPHA*L_factor) or\n",
    "        (keypoints_dict['right_shoulder'][1] <= keypoints_dict['right_foot'][1] + ALPHA*L_factor)\n",
    "    \n",
    "    torso_low = (\n",
    "        (keypoints_dict['left_torso'][1] <= keypoints_dict['left_foot'][1] + ALPHA*L_factor) or\n",
    "        (keypoints_dict['right_torso'][1] <= keypoints_dict['right_foot'][1] + ALPHA*L_factor)\n",
    "    \n",
    "    conditions.update({\n",
    "        'shoulder_low': shoulder_low,\n",
    "        'torso_low': torso_low\n",
    "    })\n",
    "\n",
    "    # 3. Dimensi tubuh\n",
    "    body_height = abs(\n",
    "        (keypoints_dict['left_shoulder'][1] + keypoints_dict['right_shoulder'][1])/2 - \n",
    "        (keypoints_dict['left_foot'][1] + keypoints_dict['right_foot'][1])/2\n",
    "    )\n",
    "    body_width = abs(keypoints_dict['left_shoulder'][0] - keypoints_dict['right_shoulder'][0])\n",
    "    horizontal_position = body_height < body_width\n",
    "    conditions['horizontal_position'] = horizontal_position\n",
    "\n",
    "    # 4. Sudut torso-kaki\n",
    "    left_angle = calculate_angle(\n",
    "        keypoints_dict['left_shoulder'][:2],\n",
    "        keypoints_dict['left_torso'][:2],\n",
    "        keypoints_dict['left_foot'][:2]\n",
    "    )\n",
    "    right_angle = calculate_angle(\n",
    "        keypoints_dict['right_shoulder'][:2],\n",
    "        keypoints_dict['right_torso'][:2],\n",
    "        keypoints_dict['right_foot'][:2]\n",
    "    )\n",
    "    min_angle = min(left_angle, right_angle)\n",
    "    speed_angle_condition = (abs(vertical_speed) > SPEED_THRESHOLD) or (min_angle < ANGLE_THRESHOLD)\n",
    "    conditions['speed_angle'] = speed_angle_condition\n",
    "\n",
    "    # 5. Keputusan akhir\n",
    "    fall_conditions = [\n",
    "        (shoulder_low or torso_low),\n",
    "        horizontal_position,\n",
    "        speed_angle_condition\n",
    "    ]\n",
    "\n",
    "    # Debug visualization\n",
    "    if debug_image is not None:\n",
    "        y_offset = 250\n",
    "        for cond, met in conditions.items():\n",
    "            color = (0, 255, 0) if met else (0, 0, 255)\n",
    "            text = f\"{cond}: {'OK' if met else 'FAIL'}\"\n",
    "            cv2.putText(debug_image, text, (50, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            y_offset += 30\n",
    "        \n",
    "        cv2.putText(debug_image, f\"Speed: {vertical_speed:.1f} px/s\", (50, y_offset+40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "        cv2.putText(debug_image, f\"Angle: {min_angle:.1f} deg\", (50, y_offset+70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    if all(fall_conditions):\n",
    "        return True, conditions, \"Fall detected\"\n",
    "    return False, conditions, \"Conditions not met\"\n",
    "\n",
    "def process_video(video_path):\n",
    "    global prev_shoulder_y, prev_time\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    skip_frames = max(1, int(original_fps / TARGET_FPS)) if original_fps > 0 else 1\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Skip frames untuk target FPS\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % skip_frames != 0:\n",
    "            continue\n",
    "\n",
    "        # Preprocessing\n",
    "        image = letterbox(frame, 640, stride=64, auto=True)[0]\n",
    "        image_tensor = transforms.ToTensor()(image)\n",
    "        image_tensor = torch.tensor(np.array([image_tensor.numpy()]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image_tensor = image_tensor.half().to(device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(image_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "            output = output_to_keypoint(output)\n",
    "        \n",
    "        # Hitung kecepatan vertikal\n",
    "        vertical_speed = 0\n",
    "        current_time = time.perf_counter()\n",
    "        \n",
    "        if output.shape[0] > 0:\n",
    "            keypoints = output[0, 7:].T\n",
    "            left_shoulder = keypoints[5*3+1]\n",
    "            right_shoulder = keypoints[6*3+1]\n",
    "            current_shoulder_y = (left_shoulder + right_shoulder) / 2\n",
    "            \n",
    "            if prev_shoulder_y is not None and prev_time is not None:\n",
    "                time_diff = current_time - prev_time\n",
    "                vertical_speed = (current_shoulder_y - prev_shoulder_y) / time_diff\n",
    "                \n",
    "            prev_shoulder_y = current_shoulder_y\n",
    "            prev_time = current_time\n",
    "        \n",
    "        # Visualisasi\n",
    "        nimg = image_tensor[0].permute(1, 2, 0).cpu().numpy() * 255\n",
    "        nimg = cv2.cvtColor(nimg.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        for idx in range(output.shape[0]):\n",
    "            keypoints = output[idx, 7:].T\n",
    "            plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "            \n",
    "            # Deteksi jatuh dengan debug\n",
    "            fall_detected, conditions, message = detect_fall(\n",
    "                keypoints, \n",
    "                vertical_speed, \n",
    "                debug_image=nimg\n",
    "            )\n",
    "            \n",
    "            # Tampilkan hasil\n",
    "            if fall_detected:\n",
    "                cv2.putText(nimg, \"FALL DETECTED!\", (50, 50), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(nimg, message, (50, 100), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Fall Detection\", nimg)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Jalankan pemrosesan\n",
    "video_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\A Skripsi\\\\datasets\\\\FallDataset\\\\Dataset\\\\Coffee_room_01\\\\Videos\\\\video (1).avi\"\n",
    "process_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb744e-5030-4f27-be2b-e61f1d996ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
