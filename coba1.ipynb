{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7b0a76-e9df-47f3-8eb0-caa4b200bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.73\n",
      "Recall: 0.82\n",
      "F1-score: 0.77\n",
      "Accuracy: 0.71\n",
      "Specificity: 0.54\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint\n",
    "from models.yolo import Model\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def retinex_deillumination(image):\n",
    "    \"\"\"\n",
    "    Apply Retinex deillumination to the image.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :return: Image with Retinex deillumination applied (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply Gaussian blur to the L channel\n",
    "    l_blur = cv2.GaussianBlur(l, (0, 0), 3)\n",
    "    \n",
    "    # Subtract the blurred L channel from the original L channel\n",
    "    l_deilluminated = cv2.subtract(l, l_blur)\n",
    "    \n",
    "    # Merge the channels back and convert to BGR\n",
    "    lab_deilluminated = cv2.merge((l_deilluminated, a, b))\n",
    "    return cv2.cvtColor(lab_deilluminated, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def preprocess_image(image, apply_augmentation= True, apply_clahe_flag=True, apply_retinex_flag=True):\n",
    "    \"\"\"\n",
    "    Preprocess the image with augmentation, CLAHE, Retinex deillumination, and resizing.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :param apply_augmentation: Whether to apply augmentation.\n",
    "    :param apply_clahe_flag: Whether to apply CLAHE.\n",
    "    :param apply_retinex_flag: Whether to apply Retinex deillumination.\n",
    "    :return: Preprocessed image (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    if apply_augmentation:\n",
    "        image = augment_image(image)\n",
    "\n",
    "    if apply_clahe_flag:\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    if apply_retinex_flag:\n",
    "        image = retinex_deillumination(image)\n",
    "\n",
    "    # Resize image to 640x480\n",
    "    image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_ground_truth(label_path):\n",
    "    \"\"\"\n",
    "    Load ground truth label from a text file.\n",
    "    :param label_path: Path to the label file.\n",
    "    :return: Integer ground truth value (0 for 'adl', 1 for 'fall').\n",
    "    \"\"\"\n",
    "    with open(label_path, 'r') as file:\n",
    "        line = file.readline().strip()  # Baca baris pertama dan hapus whitespace\n",
    "\n",
    "        if not line:  # Cek jika kosong\n",
    "            return 0  # Default: asumsikan 'adl' jika tidak ada data\n",
    "\n",
    "        values = line.split()\n",
    "        if len(values) == 0:  # Jika tetap kosong setelah split\n",
    "            return 0  # Default: tidak ada deteksi jatuh\n",
    "\n",
    "        first_value = values[0]\n",
    "\n",
    "        return int(first_value)  # Konversi ke integer\n",
    "import math\n",
    "\n",
    "def calculate_vertical_speed(prev_keypoints, current_keypoints, time_elapsed):\n",
    "    \"\"\"\n",
    "    Calculate vertical speed based on the movement of shoulders.\n",
    "    :param prev_keypoints: Keypoints from the previous frame.\n",
    "    :param current_keypoints: Keypoints from the current frame.\n",
    "    :param time_elapsed: Time elapsed between frames (in seconds).\n",
    "    :return: Vertical speed (pixels per second).\n",
    "    \"\"\"\n",
    "    if prev_keypoints is None or time_elapsed == 0:\n",
    "        return 0\n",
    "\n",
    "    # Indices for keypoints (COCO format)\n",
    "    LEFT_SHOULDER = 5\n",
    "    RIGHT_SHOULDER = 6\n",
    "\n",
    "    # Get y positions of shoulders\n",
    "    prev_left_shoulder_y = prev_keypoints[LEFT_SHOULDER * 3 + 1]\n",
    "    prev_right_shoulder_y = prev_keypoints[RIGHT_SHOULDER * 3 + 1]\n",
    "    current_left_shoulder_y = current_keypoints[LEFT_SHOULDER * 3 + 1]\n",
    "    current_right_shoulder_y = current_keypoints[RIGHT_SHOULDER * 3 + 1]\n",
    "\n",
    "    # Calculate average y positions\n",
    "    prev_shoulder_y = (prev_left_shoulder_y + prev_right_shoulder_y) / 2\n",
    "    current_shoulder_y = (current_left_shoulder_y + current_right_shoulder_y) / 2\n",
    "\n",
    "    # Calculate vertical displacement\n",
    "    vertical_displacement = abs(current_shoulder_y - prev_shoulder_y)\n",
    "\n",
    "    # Calculate vertical speed\n",
    "    vertical_speed = vertical_displacement / time_elapsed\n",
    "    return vertical_speed\n",
    "\n",
    "def calculate_torso_leg_angle(keypoints):\n",
    "    \"\"\"\n",
    "    Calculate the angle between the torso and legs.\n",
    "    :param keypoints: Array of keypoints (17 keypoints, each with x, y, confidence).\n",
    "    :return: Angle between torso and legs (in degrees).\n",
    "    \"\"\"\n",
    "    # Indices for keypoints (COCO format)\n",
    "    LEFT_SHOULDER = 5\n",
    "    RIGHT_SHOULDER = 6\n",
    "    LEFT_HIP = 11\n",
    "    RIGHT_HIP = 12\n",
    "    LEFT_KNEE = 13\n",
    "    RIGHT_KNEE = 14\n",
    "\n",
    "    # Get keypoints\n",
    "    left_shoulder = keypoints[LEFT_SHOULDER * 3: (LEFT_SHOULDER + 1) * 3]\n",
    "    right_shoulder = keypoints[RIGHT_SHOULDER * 3: (RIGHT_SHOULDER + 1) * 3]\n",
    "    left_hip = keypoints[LEFT_HIP * 3: (LEFT_HIP + 1) * 3]\n",
    "    right_hip = keypoints[RIGHT_HIP * 3: (RIGHT_HIP + 1) * 3]\n",
    "    left_knee = keypoints[LEFT_KNEE * 3: (LEFT_KNEE + 1) * 3]\n",
    "    right_knee = keypoints[RIGHT_KNEE * 3: (RIGHT_KNEE + 1) * 3]\n",
    "\n",
    "    # Calculate midpoints\n",
    "    shoulder_midpoint = ((left_shoulder[0] + right_shoulder[0]) / 2, (left_shoulder[1] + right_shoulder[1]) / 2)\n",
    "    hip_midpoint = ((left_hip[0] + right_hip[0]) / 2, (left_hip[1] + right_hip[1]) / 2)\n",
    "    knee_midpoint = ((left_knee[0] + right_knee[0]) / 2, (left_knee[1] + right_knee[1]) / 2)\n",
    "\n",
    "    # Calculate vectors\n",
    "    torso_vector = (hip_midpoint[0] - shoulder_midpoint[0], hip_midpoint[1] - shoulder_midpoint[1])\n",
    "    leg_vector = (knee_midpoint[0] - hip_midpoint[0], knee_midpoint[1] - hip_midpoint[1])\n",
    "\n",
    "    # Calculate dot product and magnitudes\n",
    "    dot_product = torso_vector[0] * leg_vector[0] + torso_vector[1] * leg_vector[1]\n",
    "    torso_magnitude = math.sqrt(torso_vector[0] ** 2 + torso_vector[1] ** 2)\n",
    "    leg_magnitude = math.sqrt(leg_vector[0] ** 2 + leg_vector[1] ** 2)\n",
    "\n",
    "    # Calculate angle in radians and convert to degrees\n",
    "    angle_radians = math.acos(dot_product / (torso_magnitude * leg_magnitude))\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return angle_degrees\n",
    "\n",
    "def detect_fall(keypoints, prev_keypoints, time_elapsed, speed_threshold=100, angle_threshold=45):\n",
    "    \"\"\"\n",
    "    Detect fall based on keypoints, vertical speed, and torso-leg angle.\n",
    "    :param keypoints: Array of keypoints (17 keypoints, each with x, y, confidence).\n",
    "    :param prev_keypoints: Keypoints from the previous frame.\n",
    "    :param time_elapsed: Time elapsed between frames (in seconds).\n",
    "    :param speed_threshold: Threshold for vertical speed (pixels per second).\n",
    "    :param angle_threshold: Threshold for torso-leg angle (degrees).\n",
    "    :return: True if fall is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check vertical speed\n",
    "    vertical_speed = calculate_vertical_speed(prev_keypoints, keypoints, time_elapsed)\n",
    "    if vertical_speed > speed_threshold:\n",
    "        return True\n",
    "\n",
    "    # Check torso-leg angle\n",
    "    torso_leg_angle = calculate_torso_leg_angle(keypoints)\n",
    "    if torso_leg_angle < angle_threshold:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Inisialisasi variabel untuk menyimpan keypoints dari frame sebelumnya\n",
    "prev_keypoints = None\n",
    "time_elapsed = 1 / 30  # Asumsi frame rate 30 fps\n",
    "\n",
    "for filename in os.listdir(test_images_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(test_images_path, filename)\n",
    "        label_path = os.path.join(test_labels_path, filename.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = preprocess_image(image, apply_augmentation=True, apply_clahe_flag=True, apply_retinex_flag=True)\n",
    "        \n",
    "        image_resized = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "        image_tensor = transforms.ToTensor()(image_resized)\n",
    "        image_tensor = torch.tensor(np.array([image_tensor.numpy()]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image_tensor = image_tensor.half().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(image_tensor)\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "            output = output_to_keypoint(output)\n",
    "        \n",
    "        fall_detected = 0\n",
    "        for idx in range(output.shape[0]):\n",
    "            keypoints = output[idx, 7:].T\n",
    "            if detect_fall(keypoints, prev_keypoints, time_elapsed):\n",
    "                fall_detected = 1\n",
    "                break\n",
    "\n",
    "        # Update previous keypoints\n",
    "        prev_keypoints = keypoints\n",
    "        \n",
    "        predictions_list.append(fall_detected)\n",
    "        ground_truth_list.append(load_ground_truth(label_path))\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(ground_truth_list, predictions_list)\n",
    "recall = recall_score(ground_truth_list, predictions_list)\n",
    "f1 = f1_score(ground_truth_list, predictions_list)\n",
    "accuracy = accuracy_score(ground_truth_list, predictions_list)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = confusion_matrix(ground_truth_list, predictions_list).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf6748-b672-4914-bf74-a800c5482ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
