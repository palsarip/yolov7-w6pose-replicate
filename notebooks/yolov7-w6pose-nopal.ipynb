{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f47659-f100-48c6-aa69-19f581d46b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7531dc7d-695d-4f04-af90-4db52a4916c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists!\n",
      "Model already exists!\n",
      "Model file found! Now you need to fix the import structure.\n",
      "Please make sure you have the complete YOLOv7 repository structure.\n",
      "Your project should include the following files:\n",
      "- models/common.py\n",
      "- models/experimental.py\n",
      "- models/yolo.py\n",
      "Loading YOLOv7-W6-Pose model...\n",
      "Model loaded successfully!\n",
      "\n",
      "========================================\n",
      "Processing train set\n",
      "Looking for videos in: datasets\\FallDataset\\train\\video\n",
      "Found 114 video files\n",
      "Processing video (1).avi (0/114)...\n",
      "Total frames: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naufa\\anaconda3\\envs\\cv_env\\Lib\\site-packages\\torch\\functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\b\\abs_fakvb73nko\\croot\\pytorch-select_1730848725921\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3588.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/157 frames, detected 93 people, 0 falls\n",
      "Completed video: video (1).avi - 157 frames processed, 149 people detected, 0 falls detected\n",
      "Completed: 1/114\n",
      "Processing video (10).avi (1/114)...\n",
      "Total frames: 362\n",
      "Processed 300/362 frames, detected 301 people, 0 falls\n",
      "Completed video: video (10).avi - 362 frames processed, 362 people detected, 0 falls detected\n",
      "Completed: 2/114\n",
      "Processing video (100).avi (2/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (100).avi - 192 frames processed, 191 people detected, 0 falls detected\n",
      "Completed: 3/114\n",
      "Processing video (101).avi (3/114)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 261 people, 0 falls\n",
      "Completed video: video (101).avi - 312 frames processed, 264 people detected, 0 falls detected\n",
      "Completed: 4/114\n",
      "Processing video (102).avi (4/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 98 people, 0 falls\n",
      "Completed video: video (102).avi - 192 frames processed, 189 people detected, 0 falls detected\n",
      "Completed: 5/114\n",
      "Processing video (103).avi (5/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (103).avi - 192 frames processed, 150 people detected, 0 falls detected\n",
      "Completed: 6/114\n",
      "Processing video (104).avi (6/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 194 people, 0 falls\n",
      "Completed video: video (104).avi - 240 frames processed, 232 people detected, 0 falls detected\n",
      "Completed: 7/114\n",
      "Processing video (105).avi (7/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 146 people, 0 falls\n",
      "Completed video: video (105).avi - 216 frames processed, 146 people detected, 0 falls detected\n",
      "Completed: 8/114\n",
      "Processing video (106).avi (8/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 37 people, 0 falls\n",
      "Completed video: video (106).avi - 192 frames processed, 94 people detected, 0 falls detected\n",
      "Completed: 9/114\n",
      "Processing video (107).avi (9/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (107).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 10/114\n",
      "Interim metrics after 10 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (108).avi (10/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (108).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 11/114\n",
      "Processing video (109).avi (11/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (109).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 12/114\n",
      "Processing video (11).avi (12/114)...\n",
      "Total frames: 483\n",
      "Processed 400/483 frames, detected 401 people, 0 falls\n",
      "Completed video: video (11).avi - 483 frames processed, 483 people detected, 0 falls detected\n",
      "Completed: 13/114\n",
      "Processing video (110).avi (13/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (110).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 14/114\n",
      "Processing video (111).avi (14/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (111).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 15/114\n",
      "Processing video (112).avi (15/114)...\n",
      "Total frames: 168\n",
      "Processed 100/168 frames, detected 101 people, 0 falls\n",
      "Completed video: video (112).avi - 168 frames processed, 168 people detected, 0 falls detected\n",
      "Completed: 16/114\n",
      "Processing video (113).avi (16/114)...\n",
      "Total frames: 168\n",
      "Processed 100/168 frames, detected 101 people, 0 falls\n",
      "Completed video: video (113).avi - 168 frames processed, 168 people detected, 0 falls detected\n",
      "Completed: 17/114\n",
      "Processing video (114).avi (17/114)...\n",
      "Total frames: 314\n",
      "Processed 300/314 frames, detected 301 people, 0 falls\n",
      "Completed video: video (114).avi - 314 frames processed, 314 people detected, 0 falls detected\n",
      "Completed: 18/114\n",
      "Processing video (12).avi (18/114)...\n",
      "Total frames: 182\n",
      "Processed 100/182 frames, detected 101 people, 0 falls\n",
      "Completed video: video (12).avi - 182 frames processed, 182 people detected, 0 falls detected\n",
      "Completed: 19/114\n",
      "Processing video (13).avi (19/114)...\n",
      "Total frames: 244\n",
      "Processed 200/244 frames, detected 109 people, 0 falls\n",
      "Completed video: video (13).avi - 244 frames processed, 110 people detected, 0 falls detected\n",
      "Completed: 20/114\n",
      "Interim metrics after 20 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (14).avi (20/114)...\n",
      "Total frames: 176\n",
      "Processed 100/176 frames, detected 101 people, 0 falls\n",
      "Completed video: video (14).avi - 176 frames processed, 176 people detected, 0 falls detected\n",
      "Completed: 21/114\n",
      "Processing video (15).avi (21/114)...\n",
      "Total frames: 140\n",
      "Processed 100/140 frames, detected 101 people, 0 falls\n",
      "Completed video: video (15).avi - 140 frames processed, 140 people detected, 0 falls detected\n",
      "Completed: 22/114\n",
      "Processing video (16).avi (22/114)...\n",
      "Total frames: 177\n",
      "Processed 100/177 frames, detected 101 people, 0 falls\n",
      "Completed video: video (16).avi - 177 frames processed, 177 people detected, 0 falls detected\n",
      "Completed: 23/114\n",
      "Processing video (17).avi (23/114)...\n",
      "Total frames: 158\n",
      "Processed 100/158 frames, detected 101 people, 0 falls\n",
      "Completed video: video (17).avi - 158 frames processed, 158 people detected, 0 falls detected\n",
      "Completed: 24/114\n",
      "Processing video (18).avi (24/114)...\n",
      "Total frames: 269\n",
      "Processed 200/269 frames, detected 201 people, 0 falls\n",
      "Completed video: video (18).avi - 269 frames processed, 269 people detected, 0 falls detected\n",
      "Completed: 25/114\n",
      "Processing video (19).avi (25/114)...\n",
      "Total frames: 213\n",
      "Processed 200/213 frames, detected 201 people, 0 falls\n",
      "Completed video: video (19).avi - 213 frames processed, 213 people detected, 0 falls detected\n",
      "Completed: 26/114\n",
      "Processing video (2).avi (26/114)...\n",
      "Total frames: 306\n",
      "Processed 300/306 frames, detected 301 people, 0 falls\n",
      "Completed video: video (2).avi - 306 frames processed, 306 people detected, 0 falls detected\n",
      "Completed: 27/114\n",
      "Processing video (20).avi (27/114)...\n",
      "Total frames: 444\n",
      "Processed 400/444 frames, detected 401 people, 0 falls\n",
      "Completed video: video (20).avi - 444 frames processed, 444 people detected, 0 falls detected\n",
      "Completed: 28/114\n",
      "Processing video (21).avi (28/114)...\n",
      "Total frames: 182\n",
      "Processed 100/182 frames, detected 100 people, 0 falls\n",
      "Completed video: video (21).avi - 182 frames processed, 181 people detected, 0 falls detected\n",
      "Completed: 29/114\n",
      "Processing video (22).avi (29/114)...\n",
      "Total frames: 229\n",
      "Processed 200/229 frames, detected 201 people, 0 falls\n",
      "Completed video: video (22).avi - 229 frames processed, 229 people detected, 0 falls detected\n",
      "Completed: 30/114\n",
      "Interim metrics after 30 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (23).avi (30/114)...\n",
      "Total frames: 311\n",
      "Processed 300/311 frames, detected 295 people, 0 falls\n",
      "Completed video: video (23).avi - 311 frames processed, 305 people detected, 0 falls detected\n",
      "Completed: 31/114\n",
      "Processing video (24).avi (31/114)...\n",
      "Total frames: 267\n",
      "Processed 200/267 frames, detected 201 people, 0 falls\n",
      "Completed video: video (24).avi - 267 frames processed, 267 people detected, 0 falls detected\n",
      "Completed: 32/114\n",
      "Processing video (25).avi (32/114)...\n",
      "Total frames: 262\n",
      "Processed 200/262 frames, detected 201 people, 0 falls\n",
      "Completed video: video (25).avi - 262 frames processed, 262 people detected, 0 falls detected\n",
      "Completed: 33/114\n",
      "Processing video (26).avi (33/114)...\n",
      "Total frames: 278\n",
      "Processed 200/278 frames, detected 201 people, 0 falls\n",
      "Completed video: video (26).avi - 278 frames processed, 278 people detected, 0 falls detected\n",
      "Completed: 34/114\n",
      "Processing video (27).avi (34/114)...\n",
      "Total frames: 253\n",
      "Processed 200/253 frames, detected 201 people, 0 falls\n",
      "Completed video: video (27).avi - 253 frames processed, 253 people detected, 0 falls detected\n",
      "Completed: 35/114\n",
      "Processing video (28).avi (35/114)...\n",
      "Total frames: 175\n",
      "Processed 100/175 frames, detected 101 people, 0 falls\n",
      "Completed video: video (28).avi - 175 frames processed, 175 people detected, 0 falls detected\n",
      "Completed: 36/114\n",
      "Processing video (29).avi (36/114)...\n",
      "Total frames: 328\n",
      "Processed 300/328 frames, detected 301 people, 0 falls\n",
      "Completed video: video (29).avi - 328 frames processed, 328 people detected, 0 falls detected\n",
      "Completed: 37/114\n",
      "Processing video (3).avi (37/114)...\n",
      "Total frames: 304\n",
      "Processed 300/304 frames, detected 296 people, 0 falls\n",
      "Completed video: video (3).avi - 304 frames processed, 299 people detected, 0 falls detected\n",
      "Completed: 38/114\n",
      "Processing video (30).avi (38/114)...\n",
      "Total frames: 145\n",
      "Processed 100/145 frames, detected 101 people, 0 falls\n",
      "Completed video: video (30).avi - 145 frames processed, 145 people detected, 0 falls detected\n",
      "Completed: 39/114\n",
      "Processing video (31).avi (39/114)...\n",
      "Total frames: 265\n",
      "Processed 200/265 frames, detected 201 people, 0 falls\n",
      "Completed video: video (31).avi - 265 frames processed, 265 people detected, 0 falls detected\n",
      "Completed: 40/114\n",
      "Interim metrics after 40 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (32).avi (40/114)...\n",
      "Total frames: 305\n",
      "Processed 300/305 frames, detected 301 people, 0 falls\n",
      "Completed video: video (32).avi - 305 frames processed, 305 people detected, 0 falls detected\n",
      "Completed: 41/114\n",
      "Processing video (33).avi (41/114)...\n",
      "Total frames: 227\n",
      "Processed 200/227 frames, detected 201 people, 0 falls\n",
      "Completed video: video (33).avi - 227 frames processed, 227 people detected, 0 falls detected\n",
      "Completed: 42/114\n",
      "Processing video (34).avi (42/114)...\n",
      "Total frames: 415\n",
      "Processed 400/415 frames, detected 401 people, 0 falls\n",
      "Completed video: video (34).avi - 415 frames processed, 415 people detected, 0 falls detected\n",
      "Completed: 43/114\n",
      "Processing video (35).avi (43/114)...\n",
      "Total frames: 231\n",
      "Processed 200/231 frames, detected 201 people, 0 falls\n",
      "Completed video: video (35).avi - 231 frames processed, 231 people detected, 0 falls detected\n",
      "Completed: 44/114\n",
      "Processing video (36).avi (44/114)...\n",
      "Total frames: 1203\n",
      "Processed 1200/1203 frames, detected 1201 people, 0 falls\n",
      "Completed video: video (36).avi - 1203 frames processed, 1203 people detected, 0 falls detected\n",
      "Completed: 45/114\n",
      "Processing video (37).avi (45/114)...\n",
      "Total frames: 206\n",
      "Processed 200/206 frames, detected 201 people, 0 falls\n",
      "Completed video: video (37).avi - 206 frames processed, 206 people detected, 0 falls detected\n",
      "Completed: 46/114\n",
      "Processing video (38).avi (46/114)...\n",
      "Total frames: 352\n",
      "Processed 300/352 frames, detected 301 people, 0 falls\n",
      "Completed video: video (38).avi - 352 frames processed, 352 people detected, 0 falls detected\n",
      "Completed: 47/114\n",
      "Processing video (39).avi (47/114)...\n",
      "Total frames: 157\n",
      "Processed 100/157 frames, detected 101 people, 0 falls\n",
      "Completed video: video (39).avi - 157 frames processed, 157 people detected, 0 falls detected\n",
      "Completed: 48/114\n",
      "Processing video (4).avi (48/114)...\n",
      "Total frames: 207\n",
      "Processed 200/207 frames, detected 199 people, 0 falls\n",
      "Completed video: video (4).avi - 207 frames processed, 205 people detected, 0 falls detected\n",
      "Completed: 49/114\n",
      "Processing video (40).avi (49/114)...\n",
      "Total frames: 350\n",
      "Processed 300/350 frames, detected 301 people, 0 falls\n",
      "Completed video: video (40).avi - 350 frames processed, 350 people detected, 0 falls detected\n",
      "Completed: 50/114\n",
      "Interim metrics after 50 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (41).avi (50/114)...\n",
      "Total frames: 382\n",
      "Processed 300/382 frames, detected 301 people, 0 falls\n",
      "Completed video: video (41).avi - 382 frames processed, 382 people detected, 0 falls detected\n",
      "Completed: 51/114\n",
      "Processing video (42).avi (51/114)...\n",
      "Total frames: 159\n",
      "Processed 100/159 frames, detected 101 people, 0 falls\n",
      "Completed video: video (42).avi - 159 frames processed, 159 people detected, 0 falls detected\n",
      "Completed: 52/114\n",
      "Processing video (43).avi (52/114)...\n",
      "Total frames: 718\n",
      "Processed 700/718 frames, detected 701 people, 0 falls\n",
      "Completed video: video (43).avi - 718 frames processed, 718 people detected, 0 falls detected\n",
      "Completed: 53/114\n",
      "Processing video (44).avi (53/114)...\n",
      "Total frames: 133\n",
      "Processed 100/133 frames, detected 101 people, 0 falls\n",
      "Completed video: video (44).avi - 133 frames processed, 133 people detected, 0 falls detected\n",
      "Completed: 54/114\n",
      "Processing video (45).avi (54/114)...\n",
      "Total frames: 215\n",
      "Processed 200/215 frames, detected 201 people, 0 falls\n",
      "Completed video: video (45).avi - 215 frames processed, 215 people detected, 0 falls detected\n",
      "Completed: 55/114\n",
      "Processing video (46).avi (55/114)...\n",
      "Total frames: 292\n",
      "Processed 200/292 frames, detected 201 people, 0 falls\n",
      "Completed video: video (46).avi - 292 frames processed, 292 people detected, 0 falls detected\n",
      "Completed: 56/114\n",
      "Processing video (47).avi (56/114)...\n",
      "Total frames: 729\n",
      "Processed 700/729 frames, detected 698 people, 0 falls\n",
      "Completed video: video (47).avi - 729 frames processed, 726 people detected, 0 falls detected\n",
      "Completed: 57/114\n",
      "Processing video (48).avi (57/114)...\n",
      "Total frames: 779\n",
      "Processed 700/779 frames, detected 701 people, 0 falls\n",
      "Completed video: video (48).avi - 779 frames processed, 779 people detected, 0 falls detected\n",
      "Completed: 58/114\n",
      "Processing video (49).avi (58/114)...\n",
      "Total frames: 492\n",
      "Processed 400/492 frames, detected 401 people, 0 falls\n",
      "Completed video: video (49).avi - 492 frames processed, 492 people detected, 0 falls detected\n",
      "Completed: 59/114\n",
      "Processing video (5).avi (59/114)...\n",
      "Total frames: 181\n",
      "Processed 100/181 frames, detected 101 people, 0 falls\n",
      "Completed video: video (5).avi - 181 frames processed, 181 people detected, 0 falls detected\n",
      "Completed: 60/114\n",
      "Interim metrics after 60 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (50).avi (60/114)...\n",
      "Total frames: 1954\n",
      "Processed 1900/1954 frames, detected 1901 people, 0 falls\n",
      "Completed video: video (50).avi - 1954 frames processed, 1954 people detected, 0 falls detected\n",
      "Completed: 61/114\n",
      "Processing video (51).avi (61/114)...\n",
      "Total frames: 203\n",
      "Processed 200/203 frames, detected 190 people, 0 falls\n",
      "Completed video: video (51).avi - 203 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 62/114\n",
      "Processing video (52).avi (62/114)...\n",
      "Total frames: 215\n",
      "Processed 200/215 frames, detected 201 people, 0 falls\n",
      "Completed video: video (52).avi - 215 frames processed, 215 people detected, 0 falls detected\n",
      "Completed: 63/114\n",
      "Processing video (53).avi (63/114)...\n",
      "Total frames: 383\n",
      "Processed 300/383 frames, detected 275 people, 0 falls\n",
      "Completed video: video (53).avi - 383 frames processed, 357 people detected, 0 falls detected\n",
      "Completed: 64/114\n",
      "Processing video (54).avi (64/114)...\n",
      "Total frames: 251\n",
      "Processed 200/251 frames, detected 158 people, 0 falls\n",
      "Completed video: video (54).avi - 251 frames processed, 158 people detected, 0 falls detected\n",
      "Completed: 65/114\n",
      "Processing video (55).avi (65/114)...\n",
      "Total frames: 323\n",
      "Processed 300/323 frames, detected 301 people, 0 falls\n",
      "Completed video: video (55).avi - 323 frames processed, 323 people detected, 0 falls detected\n",
      "Completed: 66/114\n",
      "Processing video (56).avi (66/114)...\n",
      "Total frames: 431\n",
      "Processed 400/431 frames, detected 401 people, 0 falls\n",
      "Completed video: video (56).avi - 431 frames processed, 431 people detected, 0 falls detected\n",
      "Completed: 67/114\n",
      "Processing video (57).avi (67/114)...\n",
      "Total frames: 563\n",
      "Processed 500/563 frames, detected 501 people, 0 falls\n",
      "Completed video: video (57).avi - 563 frames processed, 563 people detected, 0 falls detected\n",
      "Completed: 68/114\n",
      "Processing video (58).avi (68/114)...\n",
      "Total frames: 311\n",
      "Processed 300/311 frames, detected 301 people, 0 falls\n",
      "Completed video: video (58).avi - 311 frames processed, 311 people detected, 0 falls detected\n",
      "Completed: 69/114\n",
      "Processing video (59).avi (69/114)...\n",
      "Total frames: 251\n",
      "Processed 200/251 frames, detected 201 people, 0 falls\n",
      "Completed video: video (59).avi - 251 frames processed, 251 people detected, 0 falls detected\n",
      "Completed: 70/114\n",
      "Interim metrics after 70 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (6).avi (70/114)...\n",
      "Total frames: 239\n",
      "Processed 200/239 frames, detected 194 people, 0 falls\n",
      "Completed video: video (6).avi - 239 frames processed, 232 people detected, 0 falls detected\n",
      "Completed: 71/114\n",
      "Processing video (60).avi (71/114)...\n",
      "Total frames: 275\n",
      "Processed 200/275 frames, detected 201 people, 0 falls\n",
      "Completed video: video (60).avi - 275 frames processed, 275 people detected, 0 falls detected\n",
      "Completed: 72/114\n",
      "Processing video (61).avi (72/114)...\n",
      "Total frames: 1314\n",
      "Processed 1300/1314 frames, detected 1282 people, 0 falls\n",
      "Completed video: video (61).avi - 1314 frames processed, 1295 people detected, 0 falls detected\n",
      "Completed: 73/114\n",
      "Processing video (62).avi (73/114)...\n",
      "Total frames: 282\n",
      "Processed 200/282 frames, detected 201 people, 0 falls\n",
      "Completed video: video (62).avi - 282 frames processed, 282 people detected, 0 falls detected\n",
      "Completed: 74/114\n",
      "Processing video (63).avi (74/114)...\n",
      "Total frames: 596\n",
      "Processed 500/596 frames, detected 501 people, 0 falls\n",
      "Completed video: video (63).avi - 596 frames processed, 596 people detected, 0 falls detected\n",
      "Completed: 75/114\n",
      "Processing video (64).avi (75/114)...\n",
      "Total frames: 212\n",
      "Processed 200/212 frames, detected 201 people, 0 falls\n",
      "Completed video: video (64).avi - 212 frames processed, 212 people detected, 0 falls detected\n",
      "Completed: 76/114\n",
      "Processing video (65).avi (76/114)...\n",
      "Total frames: 711\n",
      "Processed 700/711 frames, detected 701 people, 0 falls\n",
      "Completed video: video (65).avi - 711 frames processed, 711 people detected, 0 falls detected\n",
      "Completed: 77/114\n",
      "Processing video (66).avi (77/114)...\n",
      "Total frames: 298\n",
      "Processed 200/298 frames, detected 201 people, 0 falls\n",
      "Completed video: video (66).avi - 298 frames processed, 298 people detected, 0 falls detected\n",
      "Completed: 78/114\n",
      "Processing video (67).avi (78/114)...\n",
      "Total frames: 347\n",
      "Processed 300/347 frames, detected 289 people, 0 falls\n",
      "Completed video: video (67).avi - 347 frames processed, 322 people detected, 0 falls detected\n",
      "Completed: 79/114\n",
      "Processing video (68).avi (79/114)...\n",
      "Total frames: 1607\n",
      "Processed 1600/1607 frames, detected 1574 people, 0 falls\n",
      "Completed video: video (68).avi - 1607 frames processed, 1580 people detected, 0 falls detected\n",
      "Completed: 80/114\n",
      "Interim metrics after 80 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (69).avi (80/114)...\n",
      "Total frames: 1283\n",
      "Processed 1200/1283 frames, detected 1201 people, 0 falls\n",
      "Completed video: video (69).avi - 1283 frames processed, 1283 people detected, 0 falls detected\n",
      "Completed: 81/114\n",
      "Processing video (7).avi (81/114)...\n",
      "Total frames: 174\n",
      "Processed 100/174 frames, detected 101 people, 0 falls\n",
      "Completed video: video (7).avi - 174 frames processed, 174 people detected, 0 falls detected\n",
      "Completed: 82/114\n",
      "Processing video (70).avi (82/114)...\n",
      "Total frames: 839\n",
      "Processed 800/839 frames, detected 690 people, 0 falls\n",
      "Completed video: video (70).avi - 839 frames processed, 728 people detected, 0 falls detected\n",
      "Completed: 83/114\n",
      "Processing video (71).avi (83/114)...\n",
      "Total frames: 264\n",
      "Processed 200/264 frames, detected 201 people, 0 falls\n",
      "Completed video: video (71).avi - 264 frames processed, 264 people detected, 0 falls detected\n",
      "Completed: 84/114\n",
      "Processing video (72).avi (84/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (72).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 85/114\n",
      "Processing video (73).avi (85/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (73).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 86/114\n",
      "Processing video (74).avi (86/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (74).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 87/114\n",
      "Processing video (75).avi (87/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (75).avi - 192 frames processed, 134 people detected, 0 falls detected\n",
      "Completed: 88/114\n",
      "Processing video (76).avi (88/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (76).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 89/114\n",
      "Processing video (77).avi (89/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (77).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 90/114\n",
      "Interim metrics after 90 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (78).avi (90/114)...\n",
      "Total frames: 285\n",
      "Processed 200/285 frames, detected 201 people, 0 falls\n",
      "Completed video: video (78).avi - 285 frames processed, 273 people detected, 0 falls detected\n",
      "Completed: 91/114\n",
      "Processing video (79).avi (91/114)...\n",
      "Total frames: 336\n",
      "Processed 300/336 frames, detected 248 people, 0 falls\n",
      "Completed video: video (79).avi - 336 frames processed, 248 people detected, 0 falls detected\n",
      "Completed: 92/114\n",
      "Processing video (8).avi (92/114)...\n",
      "Total frames: 258\n",
      "Processed 200/258 frames, detected 198 people, 0 falls\n",
      "Completed video: video (8).avi - 258 frames processed, 255 people detected, 0 falls detected\n",
      "Completed: 93/114\n",
      "Processing video (80).avi (93/114)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 255 people, 0 falls\n",
      "Completed video: video (80).avi - 312 frames processed, 266 people detected, 0 falls detected\n",
      "Completed: 94/114\n",
      "Processing video (81).avi (94/114)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 228 people, 0 falls\n",
      "Completed video: video (81).avi - 312 frames processed, 236 people detected, 0 falls detected\n",
      "Completed: 95/114\n",
      "Processing video (82).avi (95/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (82).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 96/114\n",
      "Processing video (83).avi (96/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 183 people, 0 falls\n",
      "Completed video: video (83).avi - 240 frames processed, 222 people detected, 0 falls detected\n",
      "Completed: 97/114\n",
      "Processing video (84).avi (97/114)...\n",
      "Total frames: 288\n",
      "Processed 200/288 frames, detected 99 people, 0 falls\n",
      "Completed video: video (84).avi - 288 frames processed, 158 people detected, 0 falls detected\n",
      "Completed: 98/114\n",
      "Processing video (85).avi (98/114)...\n",
      "Total frames: 238\n",
      "Processed 200/238 frames, detected 138 people, 0 falls\n",
      "Completed video: video (85).avi - 238 frames processed, 173 people detected, 0 falls detected\n",
      "Completed: 99/114\n",
      "Processing video (86).avi (99/114)...\n",
      "Total frames: 264\n",
      "Processed 200/264 frames, detected 194 people, 0 falls\n",
      "Completed video: video (86).avi - 264 frames processed, 226 people detected, 0 falls detected\n",
      "Completed: 100/114\n",
      "Interim metrics after 100 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (87).avi (100/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 197 people, 0 falls\n",
      "Completed video: video (87).avi - 240 frames processed, 236 people detected, 0 falls detected\n",
      "Completed: 101/114\n",
      "Processing video (88).avi (101/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 195 people, 0 falls\n",
      "Completed video: video (88).avi - 216 frames processed, 210 people detected, 0 falls detected\n",
      "Completed: 102/114\n",
      "Processing video (89).avi (102/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (89).avi - 192 frames processed, 191 people detected, 0 falls detected\n",
      "Completed: 103/114\n",
      "Processing video (9).avi (103/114)...\n",
      "Total frames: 206\n",
      "Processed 200/206 frames, detected 200 people, 0 falls\n",
      "Completed video: video (9).avi - 206 frames processed, 205 people detected, 0 falls detected\n",
      "Completed: 104/114\n",
      "Processing video (90).avi (104/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (90).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 105/114\n",
      "Processing video (91).avi (105/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (91).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 106/114\n",
      "Processing video (92).avi (106/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 189 people, 0 falls\n",
      "Completed video: video (92).avi - 240 frames processed, 228 people detected, 0 falls detected\n",
      "Completed: 107/114\n",
      "Processing video (93).avi (107/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 195 people, 0 falls\n",
      "Completed video: video (93).avi - 240 frames processed, 234 people detected, 0 falls detected\n",
      "Completed: 108/114\n",
      "Processing video (94).avi (108/114)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (94).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 109/114\n",
      "Processing video (95).avi (109/114)...\n",
      "Total frames: 213\n",
      "Processed 200/213 frames, detected 201 people, 0 falls\n",
      "Completed video: video (95).avi - 213 frames processed, 213 people detected, 0 falls detected\n",
      "Completed: 110/114\n",
      "Interim metrics after 110 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (96).avi (110/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (96).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 111/114\n",
      "Processing video (97).avi (111/114)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (97).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 112/114\n",
      "Processing video (98).avi (112/114)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (98).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 113/114\n",
      "Processing video (99).avi (113/114)...\n",
      "Total frames: 271\n",
      "Processed 200/271 frames, detected 197 people, 0 falls\n",
      "Completed video: video (99).avi - 271 frames processed, 267 people detected, 0 falls detected\n",
      "Completed: 114/114\n",
      "train metrics saved to results\\train\n",
      "\n",
      "========================================\n",
      "Processing valid set\n",
      "Looking for videos in: datasets\\FallDataset\\valid\\video\n",
      "Found 38 video files\n",
      "Processing video (1).avi (0/38)...\n",
      "Total frames: 157\n",
      "Processed 100/157 frames, detected 93 people, 0 falls\n",
      "Completed video: video (1).avi - 157 frames processed, 149 people detected, 0 falls detected\n",
      "Completed: 1/38\n",
      "Processing video (10).avi (1/38)...\n",
      "Total frames: 362\n",
      "Processed 300/362 frames, detected 301 people, 0 falls\n",
      "Completed video: video (10).avi - 362 frames processed, 362 people detected, 0 falls detected\n",
      "Completed: 2/38\n",
      "Processing video (11).avi (2/38)...\n",
      "Total frames: 483\n",
      "Processed 400/483 frames, detected 401 people, 0 falls\n",
      "Completed video: video (11).avi - 483 frames processed, 483 people detected, 0 falls detected\n",
      "Completed: 3/38\n",
      "Processing video (12).avi (3/38)...\n",
      "Total frames: 182\n",
      "Processed 100/182 frames, detected 101 people, 0 falls\n",
      "Completed video: video (12).avi - 182 frames processed, 182 people detected, 0 falls detected\n",
      "Completed: 4/38\n",
      "Processing video (13).avi (4/38)...\n",
      "Total frames: 244\n",
      "Processed 200/244 frames, detected 109 people, 0 falls\n",
      "Completed video: video (13).avi - 244 frames processed, 110 people detected, 0 falls detected\n",
      "Completed: 5/38\n",
      "Processing video (14).avi (5/38)...\n",
      "Total frames: 176\n",
      "Processed 100/176 frames, detected 101 people, 0 falls\n",
      "Completed video: video (14).avi - 176 frames processed, 176 people detected, 0 falls detected\n",
      "Completed: 6/38\n",
      "Processing video (15).avi (6/38)...\n",
      "Total frames: 140\n",
      "Processed 100/140 frames, detected 101 people, 0 falls\n",
      "Completed video: video (15).avi - 140 frames processed, 140 people detected, 0 falls detected\n",
      "Completed: 7/38\n",
      "Processing video (16).avi (7/38)...\n",
      "Total frames: 177\n",
      "Processed 100/177 frames, detected 101 people, 0 falls\n",
      "Completed video: video (16).avi - 177 frames processed, 177 people detected, 0 falls detected\n",
      "Completed: 8/38\n",
      "Processing video (17).avi (8/38)...\n",
      "Total frames: 158\n",
      "Processed 100/158 frames, detected 101 people, 0 falls\n",
      "Completed video: video (17).avi - 158 frames processed, 158 people detected, 0 falls detected\n",
      "Completed: 9/38\n",
      "Processing video (18).avi (9/38)...\n",
      "Total frames: 269\n",
      "Processed 200/269 frames, detected 201 people, 0 falls\n",
      "Completed video: video (18).avi - 269 frames processed, 269 people detected, 0 falls detected\n",
      "Completed: 10/38\n",
      "Interim metrics after 10 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (19).avi (10/38)...\n",
      "Total frames: 213\n",
      "Processed 200/213 frames, detected 201 people, 0 falls\n",
      "Completed video: video (19).avi - 213 frames processed, 213 people detected, 0 falls detected\n",
      "Completed: 11/38\n",
      "Processing video (2).avi (11/38)...\n",
      "Total frames: 306\n",
      "Processed 300/306 frames, detected 301 people, 0 falls\n",
      "Completed video: video (2).avi - 306 frames processed, 306 people detected, 0 falls detected\n",
      "Completed: 12/38\n",
      "Processing video (20).avi (12/38)...\n",
      "Total frames: 444\n",
      "Processed 400/444 frames, detected 401 people, 0 falls\n",
      "Completed video: video (20).avi - 444 frames processed, 444 people detected, 0 falls detected\n",
      "Completed: 13/38\n",
      "Processing video (21).avi (13/38)...\n",
      "Total frames: 182\n",
      "Processed 100/182 frames, detected 100 people, 0 falls\n",
      "Completed video: video (21).avi - 182 frames processed, 181 people detected, 0 falls detected\n",
      "Completed: 14/38\n",
      "Processing video (22).avi (14/38)...\n",
      "Total frames: 229\n",
      "Processed 200/229 frames, detected 201 people, 0 falls\n",
      "Completed video: video (22).avi - 229 frames processed, 229 people detected, 0 falls detected\n",
      "Completed: 15/38\n",
      "Processing video (23).avi (15/38)...\n",
      "Total frames: 311\n",
      "Processed 300/311 frames, detected 295 people, 0 falls\n",
      "Completed video: video (23).avi - 311 frames processed, 305 people detected, 0 falls detected\n",
      "Completed: 16/38\n",
      "Processing video (24).avi (16/38)...\n",
      "Total frames: 267\n",
      "Processed 200/267 frames, detected 201 people, 0 falls\n",
      "Completed video: video (24).avi - 267 frames processed, 267 people detected, 0 falls detected\n",
      "Completed: 17/38\n",
      "Processing video (25).avi (17/38)...\n",
      "Total frames: 262\n",
      "Processed 200/262 frames, detected 201 people, 0 falls\n",
      "Completed video: video (25).avi - 262 frames processed, 262 people detected, 0 falls detected\n",
      "Completed: 18/38\n",
      "Processing video (26).avi (18/38)...\n",
      "Total frames: 278\n",
      "Processed 200/278 frames, detected 201 people, 0 falls\n",
      "Completed video: video (26).avi - 278 frames processed, 278 people detected, 0 falls detected\n",
      "Completed: 19/38\n",
      "Processing video (27).avi (19/38)...\n",
      "Total frames: 253\n",
      "Processed 200/253 frames, detected 201 people, 0 falls\n",
      "Completed video: video (27).avi - 253 frames processed, 253 people detected, 0 falls detected\n",
      "Completed: 20/38\n",
      "Interim metrics after 20 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (28).avi (20/38)...\n",
      "Total frames: 175\n",
      "Processed 100/175 frames, detected 101 people, 0 falls\n",
      "Completed video: video (28).avi - 175 frames processed, 175 people detected, 0 falls detected\n",
      "Completed: 21/38\n",
      "Processing video (29).avi (21/38)...\n",
      "Total frames: 328\n",
      "Processed 300/328 frames, detected 301 people, 0 falls\n",
      "Completed video: video (29).avi - 328 frames processed, 328 people detected, 0 falls detected\n",
      "Completed: 22/38\n",
      "Processing video (3).avi (22/38)...\n",
      "Total frames: 304\n",
      "Processed 300/304 frames, detected 296 people, 0 falls\n",
      "Completed video: video (3).avi - 304 frames processed, 299 people detected, 0 falls detected\n",
      "Completed: 23/38\n",
      "Processing video (30).avi (23/38)...\n",
      "Total frames: 145\n",
      "Processed 100/145 frames, detected 101 people, 0 falls\n",
      "Completed video: video (30).avi - 145 frames processed, 145 people detected, 0 falls detected\n",
      "Completed: 24/38\n",
      "Processing video (31).avi (24/38)...\n",
      "Total frames: 265\n",
      "Processed 200/265 frames, detected 201 people, 0 falls\n",
      "Completed video: video (31).avi - 265 frames processed, 265 people detected, 0 falls detected\n",
      "Completed: 25/38\n",
      "Processing video (32).avi (25/38)...\n",
      "Total frames: 305\n",
      "Processed 300/305 frames, detected 301 people, 0 falls\n",
      "Completed video: video (32).avi - 305 frames processed, 305 people detected, 0 falls detected\n",
      "Completed: 26/38\n",
      "Processing video (33).avi (26/38)...\n",
      "Total frames: 227\n",
      "Processed 200/227 frames, detected 201 people, 0 falls\n",
      "Completed video: video (33).avi - 227 frames processed, 227 people detected, 0 falls detected\n",
      "Completed: 27/38\n",
      "Processing video (34).avi (27/38)...\n",
      "Total frames: 415\n",
      "Processed 400/415 frames, detected 401 people, 0 falls\n",
      "Completed video: video (34).avi - 415 frames processed, 415 people detected, 0 falls detected\n",
      "Completed: 28/38\n",
      "Processing video (35).avi (28/38)...\n",
      "Total frames: 231\n",
      "Processed 200/231 frames, detected 201 people, 0 falls\n",
      "Completed video: video (35).avi - 231 frames processed, 231 people detected, 0 falls detected\n",
      "Completed: 29/38\n",
      "Processing video (36).avi (29/38)...\n",
      "Total frames: 1203\n",
      "Processed 1200/1203 frames, detected 1201 people, 0 falls\n",
      "Completed video: video (36).avi - 1203 frames processed, 1203 people detected, 0 falls detected\n",
      "Completed: 30/38\n",
      "Interim metrics after 30 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (37).avi (30/38)...\n",
      "Total frames: 206\n",
      "Processed 200/206 frames, detected 201 people, 0 falls\n",
      "Completed video: video (37).avi - 206 frames processed, 206 people detected, 0 falls detected\n",
      "Completed: 31/38\n",
      "Processing video (38).avi (31/38)...\n",
      "Total frames: 352\n",
      "Processed 300/352 frames, detected 301 people, 0 falls\n",
      "Completed video: video (38).avi - 352 frames processed, 352 people detected, 0 falls detected\n",
      "Completed: 32/38\n",
      "Processing video (4).avi (32/38)...\n",
      "Total frames: 207\n",
      "Processed 200/207 frames, detected 199 people, 0 falls\n",
      "Completed video: video (4).avi - 207 frames processed, 205 people detected, 0 falls detected\n",
      "Completed: 33/38\n",
      "Processing video (5).avi (33/38)...\n",
      "Total frames: 181\n",
      "Processed 100/181 frames, detected 101 people, 0 falls\n",
      "Completed video: video (5).avi - 181 frames processed, 181 people detected, 0 falls detected\n",
      "Completed: 34/38\n",
      "Processing video (6).avi (34/38)...\n",
      "Total frames: 239\n",
      "Processed 200/239 frames, detected 194 people, 0 falls\n",
      "Completed video: video (6).avi - 239 frames processed, 232 people detected, 0 falls detected\n",
      "Completed: 35/38\n",
      "Processing video (7).avi (35/38)...\n",
      "Total frames: 174\n",
      "Processed 100/174 frames, detected 101 people, 0 falls\n",
      "Completed video: video (7).avi - 174 frames processed, 174 people detected, 0 falls detected\n",
      "Completed: 36/38\n",
      "Processing video (8).avi (36/38)...\n",
      "Total frames: 258\n",
      "Processed 200/258 frames, detected 198 people, 0 falls\n",
      "Completed video: video (8).avi - 258 frames processed, 255 people detected, 0 falls detected\n",
      "Completed: 37/38\n",
      "Processing video (9).avi (37/38)...\n",
      "Total frames: 206\n",
      "Processed 200/206 frames, detected 200 people, 0 falls\n",
      "Completed video: video (9).avi - 206 frames processed, 205 people detected, 0 falls detected\n",
      "Completed: 38/38\n",
      "valid metrics saved to results\\valid\n",
      "\n",
      "========================================\n",
      "Processing test set\n",
      "Looking for videos in: datasets\\FallDataset\\test\\video\n",
      "Found 38 video files\n",
      "Processing video (100).avi (0/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (100).avi - 192 frames processed, 191 people detected, 0 falls detected\n",
      "Completed: 1/38\n",
      "Processing video (101).avi (1/38)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 261 people, 0 falls\n",
      "Completed video: video (101).avi - 312 frames processed, 264 people detected, 0 falls detected\n",
      "Completed: 2/38\n",
      "Processing video (102).avi (2/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 98 people, 0 falls\n",
      "Completed video: video (102).avi - 192 frames processed, 189 people detected, 0 falls detected\n",
      "Completed: 3/38\n",
      "Processing video (103).avi (3/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (103).avi - 192 frames processed, 150 people detected, 0 falls detected\n",
      "Completed: 4/38\n",
      "Processing video (104).avi (4/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 194 people, 0 falls\n",
      "Completed video: video (104).avi - 240 frames processed, 232 people detected, 0 falls detected\n",
      "Completed: 5/38\n",
      "Processing video (105).avi (5/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 146 people, 0 falls\n",
      "Completed video: video (105).avi - 216 frames processed, 146 people detected, 0 falls detected\n",
      "Completed: 6/38\n",
      "Processing video (106).avi (6/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 37 people, 0 falls\n",
      "Completed video: video (106).avi - 192 frames processed, 94 people detected, 0 falls detected\n",
      "Completed: 7/38\n",
      "Processing video (107).avi (7/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (107).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 8/38\n",
      "Processing video (108).avi (8/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (108).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 9/38\n",
      "Processing video (71).avi (9/38)...\n",
      "Total frames: 264\n",
      "Processed 200/264 frames, detected 201 people, 0 falls\n",
      "Completed video: video (71).avi - 264 frames processed, 264 people detected, 0 falls detected\n",
      "Completed: 10/38\n",
      "Interim metrics after 10 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (72).avi (10/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (72).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 11/38\n",
      "Processing video (73).avi (11/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (73).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 12/38\n",
      "Processing video (74).avi (12/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (74).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 13/38\n",
      "Processing video (75).avi (13/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (75).avi - 192 frames processed, 134 people detected, 0 falls detected\n",
      "Completed: 14/38\n",
      "Processing video (76).avi (14/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (76).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 15/38\n",
      "Processing video (77).avi (15/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (77).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 16/38\n",
      "Processing video (78).avi (16/38)...\n",
      "Total frames: 285\n",
      "Processed 200/285 frames, detected 201 people, 0 falls\n",
      "Completed video: video (78).avi - 285 frames processed, 273 people detected, 0 falls detected\n",
      "Completed: 17/38\n",
      "Processing video (79).avi (17/38)...\n",
      "Total frames: 336\n",
      "Processed 300/336 frames, detected 248 people, 0 falls\n",
      "Completed video: video (79).avi - 336 frames processed, 248 people detected, 0 falls detected\n",
      "Completed: 18/38\n",
      "Processing video (80).avi (18/38)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 255 people, 0 falls\n",
      "Completed video: video (80).avi - 312 frames processed, 266 people detected, 0 falls detected\n",
      "Completed: 19/38\n",
      "Processing video (81).avi (19/38)...\n",
      "Total frames: 312\n",
      "Processed 300/312 frames, detected 228 people, 0 falls\n",
      "Completed video: video (81).avi - 312 frames processed, 236 people detected, 0 falls detected\n",
      "Completed: 20/38\n",
      "Interim metrics after 20 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (82).avi (20/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (82).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 21/38\n",
      "Processing video (83).avi (21/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 183 people, 0 falls\n",
      "Completed video: video (83).avi - 240 frames processed, 222 people detected, 0 falls detected\n",
      "Completed: 22/38\n",
      "Processing video (84).avi (22/38)...\n",
      "Total frames: 288\n",
      "Processed 200/288 frames, detected 99 people, 0 falls\n",
      "Completed video: video (84).avi - 288 frames processed, 158 people detected, 0 falls detected\n",
      "Completed: 23/38\n",
      "Processing video (85).avi (23/38)...\n",
      "Total frames: 238\n",
      "Processed 200/238 frames, detected 138 people, 0 falls\n",
      "Completed video: video (85).avi - 238 frames processed, 173 people detected, 0 falls detected\n",
      "Completed: 24/38\n",
      "Processing video (86).avi (24/38)...\n",
      "Total frames: 264\n",
      "Processed 200/264 frames, detected 194 people, 0 falls\n",
      "Completed video: video (86).avi - 264 frames processed, 226 people detected, 0 falls detected\n",
      "Completed: 25/38\n",
      "Processing video (87).avi (25/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 197 people, 0 falls\n",
      "Completed video: video (87).avi - 240 frames processed, 236 people detected, 0 falls detected\n",
      "Completed: 26/38\n",
      "Processing video (88).avi (26/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 195 people, 0 falls\n",
      "Completed video: video (88).avi - 216 frames processed, 210 people detected, 0 falls detected\n",
      "Completed: 27/38\n",
      "Processing video (89).avi (27/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (89).avi - 192 frames processed, 191 people detected, 0 falls detected\n",
      "Completed: 28/38\n",
      "Processing video (90).avi (28/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (90).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 29/38\n",
      "Processing video (91).avi (29/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (91).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 30/38\n",
      "Interim metrics after 30 videos:\n",
      "Precision: 0.000, Recall: 0.000\n",
      "Processing video (92).avi (30/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 189 people, 0 falls\n",
      "Completed video: video (92).avi - 240 frames processed, 228 people detected, 0 falls detected\n",
      "Completed: 31/38\n",
      "Processing video (93).avi (31/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 195 people, 0 falls\n",
      "Completed video: video (93).avi - 240 frames processed, 234 people detected, 0 falls detected\n",
      "Completed: 32/38\n",
      "Processing video (94).avi (32/38)...\n",
      "Total frames: 192\n",
      "Processed 100/192 frames, detected 101 people, 0 falls\n",
      "Completed video: video (94).avi - 192 frames processed, 192 people detected, 0 falls detected\n",
      "Completed: 33/38\n",
      "Processing video (95).avi (33/38)...\n",
      "Total frames: 213\n",
      "Processed 200/213 frames, detected 201 people, 0 falls\n",
      "Completed video: video (95).avi - 213 frames processed, 213 people detected, 0 falls detected\n",
      "Completed: 34/38\n",
      "Processing video (96).avi (34/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (96).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 35/38\n",
      "Processing video (97).avi (35/38)...\n",
      "Total frames: 240\n",
      "Processed 200/240 frames, detected 201 people, 0 falls\n",
      "Completed video: video (97).avi - 240 frames processed, 240 people detected, 0 falls detected\n",
      "Completed: 36/38\n",
      "Processing video (98).avi (36/38)...\n",
      "Total frames: 216\n",
      "Processed 200/216 frames, detected 201 people, 0 falls\n",
      "Completed video: video (98).avi - 216 frames processed, 216 people detected, 0 falls detected\n",
      "Completed: 37/38\n",
      "Processing video (99).avi (37/38)...\n",
      "Total frames: 271\n",
      "Processed 200/271 frames, detected 197 people, 0 falls\n",
      "Completed video: video (99).avi - 271 frames processed, 267 people detected, 0 falls detected\n",
      "Completed: 38/38\n",
      "test metrics saved to results\\test\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "\n",
      "TRAIN  Precision: 0.000 | Recall: 0.000 | F1: 0.000\n",
      "\n",
      "VALID  Precision: 0.000 | Recall: 0.000 | F1: 0.000\n",
      "\n",
      "TEST   Precision: 0.000 | Recall: 0.000 | F1: 0.000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "# Add the parent directory to the path so Python can find your modules\n",
    "sys.path.insert(0, os.path.abspath('.'))  # Add current directory first\n",
    "sys.path.append(os.getcwd())  # Also add current directory\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Global variables for tracking motion between frames\n",
    "prev_keypoints = None\n",
    "prev_frame_time = None\n",
    "fall_history = []\n",
    "alert_timestamp = None\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Enhanced fall detection algorithm based on YOLOv7-W6-Pose keypoints\n",
    "    as described in the journal paper \"Enhanced Fall Detection Using YOLOv7-W6-Pose for Real-Time Elderly Monitoring\"\n",
    "    \n",
    "    Args:\n",
    "        keypoints: Array of keypoints from YOLOv7-W6-Pose (shape: 17*3, where each keypoint has x, y, conf)\n",
    "        threshold: Confidence threshold for keypoint detection\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (is_fall, status, conditions)\n",
    "            - is_fall: Boolean indicating whether a fall is detected\n",
    "            - status: String description of the current state\n",
    "            - conditions: List of conditions that led to the fall detection\n",
    "    \"\"\"\n",
    "    global prev_keypoints, prev_frame_time, fall_history, alert_timestamp\n",
    "    \n",
    "    # Keypoint indices as defined in YOLOv7-pose\n",
    "    NOSE = 0\n",
    "    L_EYE, R_EYE = 1, 2\n",
    "    L_EAR, R_EAR = 3, 4\n",
    "    L_SHOULDER, R_SHOULDER = 5, 6\n",
    "    L_ELBOW, R_ELBOW = 7, 8\n",
    "    L_WRIST, R_WRIST = 9, 10\n",
    "    L_HIP, R_HIP = 11, 12\n",
    "    L_KNEE, R_KNEE = 13, 14\n",
    "    L_ANKLE, R_ANKLE = 15, 16\n",
    "    \n",
    "    try:\n",
    "        # Extract keypoints and organize them for easier access\n",
    "        kp = {\n",
    "            'nose': keypoints[NOSE*3:(NOSE+1)*3],\n",
    "            'l_eye': keypoints[L_EYE*3:(L_EYE+1)*3],\n",
    "            'r_eye': keypoints[R_EYE*3:(R_EYE+1)*3],\n",
    "            'l_ear': keypoints[L_EAR*3:(L_EAR+1)*3],\n",
    "            'r_ear': keypoints[R_EAR*3:(R_EAR+1)*3],\n",
    "            'l_shoulder': keypoints[L_SHOULDER*3:(L_SHOULDER+1)*3],\n",
    "            'r_shoulder': keypoints[R_SHOULDER*3:(R_SHOULDER+1)*3],\n",
    "            'l_elbow': keypoints[L_ELBOW*3:(L_ELBOW+1)*3],\n",
    "            'r_elbow': keypoints[R_ELBOW*3:(R_ELBOW+1)*3],\n",
    "            'l_wrist': keypoints[L_WRIST*3:(L_WRIST+1)*3],\n",
    "            'r_wrist': keypoints[R_WRIST*3:(R_WRIST+1)*3],\n",
    "            'l_hip': keypoints[L_HIP*3:(L_HIP+1)*3],\n",
    "            'r_hip': keypoints[R_HIP*3:(R_HIP+1)*3],\n",
    "            'l_knee': keypoints[L_KNEE*3:(L_KNEE+1)*3],\n",
    "            'r_knee': keypoints[R_KNEE*3:(R_KNEE+1)*3],\n",
    "            'l_ankle': keypoints[L_ANKLE*3:(L_ANKLE+1)*3],\n",
    "            'r_ankle': keypoints[R_ANKLE*3:(R_ANKLE+1)*3]\n",
    "        }\n",
    "        \n",
    "        # Check if keypoints are detected with sufficient confidence\n",
    "        low_confidence_keypoints = []\n",
    "        for k, v in kp.items():\n",
    "            if v[2] < threshold:\n",
    "                low_confidence_keypoints.append(k)\n",
    "        \n",
    "        # If more than 30% of keypoints have low confidence, return early\n",
    "        if len(low_confidence_keypoints) > 0.3 * len(kp):\n",
    "            return False, \"low_confidence\", [f\"Low confidence in keypoints: {', '.join(low_confidence_keypoints)}\"]\n",
    "        \n",
    "        # 1. Calculate the length factor based on torso length to adjust thresholds\n",
    "        # as described in the journal's supplementary materials\n",
    "        shoulder_midpoint = [(kp['l_shoulder'][0] + kp['r_shoulder'][0])/2, \n",
    "                            (kp['l_shoulder'][1] + kp['r_shoulder'][1])/2]\n",
    "        hip_midpoint = [(kp['l_hip'][0] + kp['r_hip'][0])/2, \n",
    "                        (kp['l_hip'][1] + kp['r_hip'][1])/2]\n",
    "        \n",
    "        torso_length = np.sqrt((shoulder_midpoint[0] - hip_midpoint[0])**2 + \n",
    "                              (shoulder_midpoint[1] - hip_midpoint[1])**2)\n",
    "        \n",
    "        # If torso length is near zero (very rare), use a default value\n",
    "        if torso_length < 1e-5:\n",
    "            torso_length = 100  # default average torso length in pixels\n",
    "        \n",
    "        # 2. Calculate body dimensions and ratios\n",
    "        feet_midpoint = [(kp['l_ankle'][0] + kp['r_ankle'][0])/2, \n",
    "                         (kp['l_ankle'][1] + kp['r_ankle'][1])/2]\n",
    "        \n",
    "        # Height of the body (vertical distance from shoulders to ankles)\n",
    "        body_height = abs(shoulder_midpoint[1] - feet_midpoint[1])\n",
    "        \n",
    "        # Width of the body (distance between shoulders)\n",
    "        body_width = abs(kp['l_shoulder'][0] - kp['r_shoulder'][0])\n",
    "        \n",
    "        # The conditions list will store all the criteria that suggest a fall\n",
    "        conditions = []\n",
    "        \n",
    "        # 3. Analyze shoulder position relative to feet\n",
    "        # In a normal standing posture, shoulder_y < feet_y\n",
    "        # In a fall, shoulder_y approaches or exceeds feet_y\n",
    "        shoulder_relative_threshold = feet_midpoint[1] - 0.5 * torso_length\n",
    "        if shoulder_midpoint[1] > shoulder_relative_threshold:\n",
    "            conditions.append(\"shoulder_near_feet\")\n",
    "        \n",
    "        # 4. Analyze body orientation (width vs height ratio)\n",
    "        # In normal standing posture, height > width\n",
    "        # In a fall, especially to the side, width may exceed height\n",
    "        width_height_ratio = body_width / (body_height + 1e-5)  # Adding epsilon to avoid division by zero\n",
    "        if width_height_ratio > 0.8:  # Threshold from the journal\n",
    "            conditions.append(\"horizontal_orientation\")\n",
    "        \n",
    "        # 5. Calculate angle between torso and legs\n",
    "        # As mentioned in the paper - a threshold of 45 degrees is used\n",
    "        try:\n",
    "            # Calculate vectors for torso and legs\n",
    "            torso_vector = [hip_midpoint[0] - shoulder_midpoint[0], \n",
    "                           hip_midpoint[1] - shoulder_midpoint[1]]\n",
    "            \n",
    "            leg_vector = [(kp['l_knee'][0] + kp['r_knee'][0])/2 - hip_midpoint[0],\n",
    "                          (kp['l_knee'][1] + kp['r_knee'][1])/2 - hip_midpoint[1]]\n",
    "            \n",
    "            # Calculate the angle between vectors using dot product\n",
    "            dot_product = torso_vector[0]*leg_vector[0] + torso_vector[1]*leg_vector[1]\n",
    "            torso_magnitude = math.sqrt(torso_vector[0]**2 + torso_vector[1]**2)\n",
    "            leg_magnitude = math.sqrt(leg_vector[0]**2 + leg_vector[1]**2)\n",
    "            \n",
    "            if torso_magnitude > 0 and leg_magnitude > 0:\n",
    "                angle_cos = dot_product / (torso_magnitude * leg_magnitude)\n",
    "                angle_cos = max(-1, min(1, angle_cos))  # Ensure value is in [-1, 1] range\n",
    "                angle_degrees = math.degrees(math.acos(angle_cos))\n",
    "                \n",
    "                # Check if angle is below threshold (45 degrees as mentioned in paper)\n",
    "                if angle_degrees < 45:\n",
    "                    conditions.append(f\"acute_body_angle_{angle_degrees:.1f}\")\n",
    "        except Exception as e:\n",
    "            # Skip angle calculation if there's an error\n",
    "            pass\n",
    "        \n",
    "        # 6. Motion detection (fall speed)\n",
    "        # This is crucial to distinguish between a fall and intentionally lying down\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if prev_keypoints is not None and prev_frame_time is not None:\n",
    "            time_elapsed = current_time - prev_frame_time\n",
    "            \n",
    "            if time_elapsed > 0:\n",
    "                # Calculate vertical movement speed of shoulder\n",
    "                prev_shoulder_y = (prev_keypoints['l_shoulder'][1] + prev_keypoints['r_shoulder'][1]) / 2\n",
    "                shoulder_y = (kp['l_shoulder'][1] + kp['r_shoulder'][1]) / 2\n",
    "                shoulder_speed = (shoulder_y - prev_shoulder_y) / time_elapsed\n",
    "                \n",
    "                # Calculate vertical movement speed of hip\n",
    "                prev_hip_y = (prev_keypoints['l_hip'][1] + prev_keypoints['r_hip'][1]) / 2\n",
    "                hip_y = (kp['l_hip'][1] + kp['r_hip'][1]) / 2\n",
    "                hip_speed = (hip_y - prev_hip_y) / time_elapsed\n",
    "                \n",
    "                # Use the maximum speed between shoulder and hip\n",
    "                # High positive speed indicates downward movement (in image coordinate system)\n",
    "                max_speed = max(shoulder_speed, hip_speed)\n",
    "                \n",
    "                # Threshold adjusted based on the literature (0.6 from your original code)\n",
    "                # scaled by the torso length for body-size independence\n",
    "                speed_threshold = 0.6 * (torso_length / 100)\n",
    "                \n",
    "                if max_speed > speed_threshold:\n",
    "                    conditions.append(f\"high_downward_speed_{max_speed:.1f}\")\n",
    "        \n",
    "        # Store current keypoints and time for next frame comparison\n",
    "        prev_keypoints = kp.copy()\n",
    "        prev_frame_time = current_time\n",
    "        \n",
    "        # 7. Fall decision logic as described in the journal's algorithm\n",
    "        # A fall is detected if:\n",
    "        # - At least 2 conditions are met (as in your original code)\n",
    "        # OR\n",
    "        # - High downward speed AND at least one other condition\n",
    "        is_fall = False\n",
    "        if len(conditions) >= 2:\n",
    "            is_fall = True\n",
    "        elif any(cond.startswith(\"high_downward_speed\") for cond in conditions) and len(conditions) >= 2:\n",
    "            is_fall = True\n",
    "            \n",
    "        # 8. Fall history tracking for more robust detection (reduce false positives)\n",
    "        # Store recent fall detections to make final decision more robust\n",
    "        fall_history.append(is_fall)\n",
    "        # Keep only the last 5 frames\n",
    "        if len(fall_history) > 5:\n",
    "            fall_history.pop(0)\n",
    "            \n",
    "        # Require at least 3 fall detections in last 5 frames for more robust detection\n",
    "        robust_fall = sum(fall_history) >= 3\n",
    "        \n",
    "        # 9. Alert frequency control\n",
    "        # Prevent alert spam by limiting frequency\n",
    "        current_time = time.time()\n",
    "        if robust_fall:\n",
    "            if alert_timestamp is None or (current_time - alert_timestamp > 120):  # 2 minutes between alerts\n",
    "                alert_timestamp = current_time\n",
    "                return True, \"fallen\", conditions\n",
    "            else:\n",
    "                # Fall detected but alert recently sent\n",
    "                return False, \"alert_cooldown\", conditions\n",
    "                \n",
    "        return False, \"normal\", conditions\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Reset tracking variables in case of error\n",
    "        prev_keypoints = None\n",
    "        prev_frame_time = None\n",
    "        fall_history = []\n",
    "        return False, \"error\", [f\"Error: {str(e)}\"]\n",
    "\n",
    "\n",
    "class FallDetectionMetrics:\n",
    "    \"\"\"\n",
    "    Class for tracking fall detection performance metrics\n",
    "    as described in the journal's evaluation methodology.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.true_positives = 0   # Correctly detected falls\n",
    "        self.false_positives = 0  # Incorrectly detected falls\n",
    "        self.true_negatives = 0   # Correctly identified non-falls\n",
    "        self.false_negatives = 0  # Missed falls\n",
    "        self.results = []\n",
    "        \n",
    "    def update(self, is_fall_detected, is_actual_fall):\n",
    "        \"\"\"Update metrics based on detection results\"\"\"\n",
    "        if is_fall_detected and is_actual_fall:\n",
    "            self.true_positives += 1\n",
    "        elif is_fall_detected and not is_actual_fall:\n",
    "            self.false_positives += 1\n",
    "        elif not is_fall_detected and is_actual_fall:\n",
    "            self.false_negatives += 1\n",
    "        else:\n",
    "            self.true_negatives += 1\n",
    "            \n",
    "        self.results.append({\n",
    "            \"detected\": is_fall_detected,\n",
    "            \"actual\": is_actual_fall,\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        \"\"\"Calculate performance metrics from confusion matrix\"\"\"\n",
    "        # Handle division by zero\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives) if (self.true_positives + self.false_positives) > 0 else 0\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives) if (self.true_positives + self.false_negatives) > 0 else 0\n",
    "        specificity = self.true_negatives / (self.true_negatives + self.false_positives) if (self.true_negatives + self.false_positives) > 0 else 0\n",
    "        accuracy = (self.true_positives + self.true_negatives) / (self.true_positives + self.true_negatives + self.false_positives + self.false_negatives) if (self.true_positives + self.true_negatives + self.false_positives + self.false_negatives) > 0 else 0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"specificity\": specificity,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"true_positives\": self.true_positives,\n",
    "            \"false_positives\": self.false_positives,\n",
    "            \"true_negatives\": self.true_negatives,\n",
    "            \"false_negatives\": self.false_negatives\n",
    "        }\n",
    "    \n",
    "    def save_results(self, filename_prefix):\n",
    "        \"\"\"Save detection results and metrics to files\"\"\"\n",
    "        import json\n",
    "        import os\n",
    "        \n",
    "        # Create results directory if it doesn't exist\n",
    "        os.makedirs(filename_prefix, exist_ok=True)\n",
    "        \n",
    "        # Save raw results\n",
    "        with open(os.path.join(filename_prefix, \"results.json\"), \"w\") as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        \n",
    "        # Save metrics\n",
    "        with open(os.path.join(filename_prefix, \"metrics.json\"), \"w\") as f:\n",
    "            json.dump(self.calculate_metrics(), f, indent=2)\n",
    "\n",
    "\n",
    "def load_annotations(label_dir):\n",
    "    \"\"\"\n",
    "    Load ground truth annotations from label files\n",
    "    \n",
    "    Args:\n",
    "        label_dir: Directory containing label files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of annotations by video file\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    annotations = {}\n",
    "    for file in os.listdir(label_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            video_name = file.replace(\".txt\", \".avi\")\n",
    "            with open(os.path.join(label_dir, file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "            # Parse annotations\n",
    "            fall_frames = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 3 and parts[0] == \"fall\":\n",
    "                    start_frame = int(parts[1])\n",
    "                    end_frame = int(parts[2])\n",
    "                    fall_frames.extend(list(range(start_frame, end_frame + 1)))\n",
    "            \n",
    "            annotations[video_name] = set(fall_frames)\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "\n",
    "def process_video(video_path, annotations, metrics, model=None):\n",
    "    \"\"\"\n",
    "    Process a video file for fall detection\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        annotations: Dictionary of ground truth annotations\n",
    "        metrics: FallDetectionMetrics instance for tracking performance\n",
    "        model: Optional pre-loaded YOLOv7 model\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "    from utils.datasets import letterbox\n",
    "    from utils.general import non_max_suppression_kpt\n",
    "    from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "    \n",
    "    # Initialize device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Check if model is provided, otherwise load it\n",
    "    if model is None:\n",
    "        # Ensure models directory exists\n",
    "        os.makedirs('./models', exist_ok=True)\n",
    "        \n",
    "        # Check if model file exists, if not download it\n",
    "        if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "            print(\"Model file not found. Please download yolov7-w6-pose.pt and place it in the models directory.\")\n",
    "            return\n",
    "            \n",
    "        # Load YOLOv7-pose model\n",
    "        weights = torch.load('./models/yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "        model = weights['model'].float().eval().to(device)\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.half()\n",
    "    \n",
    "    # Get video file name\n",
    "    video_file = os.path.basename(video_path)\n",
    "    \n",
    "    # Get ground truth fall frames (if available)\n",
    "    fall_frames = annotations.get(video_file, set())\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return\n",
    "        \n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Process frame for pose estimation\n",
    "            # Resize and preprocess\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "            image = transforms.ToTensor()(image)\n",
    "            image = torch.tensor(np.array([image.numpy()]))\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                image = image.half().to(device)\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                \n",
    "            # Run model inference\n",
    "            with torch.no_grad():\n",
    "                output, _ = model(image)\n",
    "            \n",
    "            # Process output for keypoints\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'])\n",
    "            \n",
    "            # Check if person detected\n",
    "            if len(output) > 0 and len(output[0]) > 0:\n",
    "                # Get keypoints for first person detected\n",
    "                keypoints = output[0][0, 7:].clone().cpu().numpy()\n",
    "                \n",
    "                # Check if keypoints array is valid\n",
    "                if len(keypoints) > 0:\n",
    "                    # Check for fall\n",
    "                    is_fall_detected, status, conditions = detect_fall(keypoints)\n",
    "                    \n",
    "                    # Ground truth - is this frame a fall according to annotations?\n",
    "                    is_actual_fall = frame_count in fall_frames\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    metrics.update(is_fall_detected, is_actual_fall)\n",
    "                    \n",
    "                    # Display results\n",
    "                    if is_fall_detected:\n",
    "                        cv2.putText(frame, f\"FALL DETECTED! {status}\", (10, 30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    \n",
    "                    # Draw skeleton - Add error handling\n",
    "                    try:\n",
    "                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        with_skeleton = plot_skeleton_kpts(frame, keypoints, 3)\n",
    "                        frame = cv2.cvtColor(with_skeleton, cv2.COLOR_RGB2BGR)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error plotting skeleton: {str(e)}\")\n",
    "                        # Continue without drawing skeleton\n",
    "            \n",
    "            # Display frame\n",
    "            cv2.imshow('Fall Detection', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "            frame_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_count}: {str(e)}\")\n",
    "            frame_count += 1\n",
    "            continue\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def run_fall_detection_system(camera_index=0):\n",
    "    \"\"\"\n",
    "    Run real-time fall detection system using webcam\n",
    "    \n",
    "    Args:\n",
    "        camera_index: Index of camera to use\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import torch\n",
    "    import os\n",
    "    from torchvision import transforms\n",
    "    from utils.datasets import letterbox\n",
    "    from utils.general import non_max_suppression_kpt\n",
    "    from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "    \n",
    "    # Initialize device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Ensure models directory exists\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Check if model file exists, if not inform user\n",
    "    if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "        print(\"Model file not found. Please download yolov7-w6-pose.pt and place it in the models directory.\")\n",
    "        return\n",
    "    \n",
    "    # Load YOLOv7-pose model\n",
    "    weights = torch.load('./models/yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "    model = weights['model'].float().eval().to(device)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()\n",
    "    \n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    \n",
    "    print(\"Fall detection system running. Press 'q' to quit.\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process frame for pose estimation\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            image = image.half().to(device)\n",
    "        else:\n",
    "            image = image.to(device)\n",
    "            \n",
    "        # Run model inference\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(image)\n",
    "        \n",
    "        # Process output for keypoints\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'])\n",
    "        \n",
    "        # Check if person detected\n",
    "        if len(output) > 0 and len(output[0]) > 0:\n",
    "            # Get keypoints for first person detected\n",
    "            keypoints = output[0][0, 7:].clone().cpu().numpy()\n",
    "            \n",
    "            # Check for fall\n",
    "            is_fall_detected, status, conditions = detect_fall(keypoints)\n",
    "            \n",
    "            # Display results\n",
    "            if is_fall_detected:\n",
    "                cv2.putText(frame, f\"FALL DETECTED! {status}\", (10, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                print(f\"Fall detected! Conditions: {conditions}\")\n",
    "            else:\n",
    "                cv2.putText(frame, f\"Status: {status}\", (10, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw skeleton\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            with_skeleton = plot_skeleton_kpts(frame, keypoints, 3)\n",
    "            frame = cv2.cvtColor(with_skeleton, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No person detected\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Fall Detection System', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def evaluate_on_dataset(base_path, phase='test'):\n",
    "    \"\"\"\n",
    "    Evaluate fall detection system on a dataset\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base path to dataset\n",
    "        phase: Dataset phase to evaluate (train, valid, test)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import torch\n",
    "    \n",
    "    # Fix path issues - use proper path joining\n",
    "    video_path = os.path.join(base_path, phase, 'video')\n",
    "    label_path = os.path.join(base_path, phase, 'labels')\n",
    "    \n",
    "    # Print the actual paths to help debug\n",
    "    print(f\"Looking for videos in: {os.path.abspath(video_path)}\")\n",
    "    print(f\"Looking for labels in: {os.path.abspath(label_path)}\")\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video directory not found at {video_path}\")\n",
    "        # List parent directory contents to help debugging\n",
    "        parent_dir = os.path.dirname(video_path)\n",
    "        if os.path.exists(parent_dir):\n",
    "            print(f\"Contents of {parent_dir}:\")\n",
    "            for item in os.listdir(parent_dir):\n",
    "                print(f\"  - {item}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"Error: Labels directory not found at {label_path}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = FallDetectionMetrics()\n",
    "    \n",
    "    # Load model once for all videos\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Ensure models directory exists\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Check if model file exists\n",
    "    if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "        print(\"Model file not found. Please download yolov7-w6-pose.pt and place it in the models directory.\")\n",
    "        return\n",
    "    \n",
    "    # Load YOLOv7-pose model\n",
    "    print(f\"Loading YOLOv7-W6-Pose model...\")\n",
    "    weights = torch.load('./models/yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "    model = weights['model'].float().eval().to(device)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    \n",
    "    # Count video files\n",
    "    video_files = [f for f in os.listdir(video_path) if f.endswith(('.avi', '.mp4'))]\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing {phase} set (Videos: {len(video_files)})\")\n",
    "    \n",
    "    # Load annotations\n",
    "    annotations = load_annotations(label_path)\n",
    "    \n",
    "    # Process videos\n",
    "    for video_file in video_files:\n",
    "        video_file_path = os.path.join(video_path, video_file)\n",
    "        print(f\"Processing {video_file}...\")\n",
    "        process_video(video_file_path, annotations, metrics, model)\n",
    "    \n",
    "    # Save results\n",
    "    results_dir = os.path.join('./results', phase)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    metrics.save_results(results_dir)\n",
    "    print(f\"{phase} metrics saved to {results_dir}\")\n",
    "    \n",
    "    # Print results\n",
    "    res = metrics.calculate_metrics()\n",
    "    print(f\"\\n{phase.upper():<6} Results:\")\n",
    "    print(f\"Precision: {res['precision']:.3f}\")\n",
    "    print(f\"Recall: {res['recall']:.3f}\")\n",
    "    print(f\"F1 Score: {res['f1_score']:.3f}\")\n",
    "    print(f\"Accuracy: {res['accuracy']:.3f}\")\n",
    "    print(f\"Specificity: {res['specificity']:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Download the YOLOv7-W6-Pose model\n",
    "def download_model():\n",
    "    \"\"\"\n",
    "    Download the YOLOv7-W6-Pose model if it doesn't exist\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Check if model already exists\n",
    "    if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "        print(\"Downloading YOLOv7-W6-Pose model...\")\n",
    "        try:\n",
    "            # Try wget first\n",
    "            subprocess.run([\"wget\", \"-O\", \"./models/yolov7-w6-pose.pt\", \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt\"], check=True)\n",
    "        except:\n",
    "            # If wget fails, try curl\n",
    "            try:\n",
    "                subprocess.run([\"curl\", \"-L\", \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt\", \"-o\", \"./models/yolov7-w6-pose.pt\"], check=True)\n",
    "            except:\n",
    "                print(\"Failed to download model. Please download manually from:\")\n",
    "                print(\"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt\")\n",
    "                print(\"and place it in the ./models/ directory.\")\n",
    "                return False\n",
    "        \n",
    "        print(\"Download complete!\")\n",
    "    else:\n",
    "        print(\"Model already exists!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def evaluate_all_phases(base_path):\n",
    "    \"\"\"\n",
    "    Evaluate fall detection system on all dataset phases\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base path to dataset\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import torch\n",
    "    \n",
    "    # Initialize metrics for each phase\n",
    "    metrics = {\n",
    "        'train': FallDetectionMetrics(),\n",
    "        'valid': FallDetectionMetrics(),\n",
    "        'test': FallDetectionMetrics()\n",
    "    }\n",
    "    \n",
    "    # Load model once for all videos\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Ensure models directory exists\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    # Check if model file exists - FIXED FILE NAME\n",
    "    if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "        print(\"Model file not found. Please download yolov7-w6-pose.pt and place it in the models directory.\")\n",
    "        return\n",
    "    \n",
    "    # Load YOLOv7-pose model\n",
    "    print(f\"Loading YOLOv7-W6-Pose model...\")\n",
    "    weights = torch.load('./models/yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "    model = weights['model'].float().eval().to(device)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    \n",
    "    # Process all phases\n",
    "    for phase in ['train', 'valid', 'test']:\n",
    "        # Fix path issues - make sure path is normalized\n",
    "        video_path = os.path.normpath(os.path.join(base_path, phase, 'video'))\n",
    "        label_path = os.path.normpath(os.path.join(base_path, phase, 'labels'))\n",
    "        \n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing {phase} set\")\n",
    "        print(f\"Looking for videos in: {video_path}\")\n",
    "        \n",
    "        # Check if directory exists\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Error: Video directory not found at {video_path}\")\n",
    "            # List parent directory to help debugging\n",
    "            parent_dir = os.path.dirname(video_path)\n",
    "            if os.path.exists(parent_dir):\n",
    "                print(f\"Contents of {parent_dir}:\")\n",
    "                for item in os.listdir(parent_dir):\n",
    "                    print(f\"  - {item}\")\n",
    "            continue\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Error: Labels directory not found at {label_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Load annotations\n",
    "        annotations = load_annotations(label_path)\n",
    "        \n",
    "        # Process videos\n",
    "        video_files = [f for f in os.listdir(video_path) if f.endswith(('.avi', '.mp4'))]\n",
    "        print(f\"Found {len(video_files)} video files\")\n",
    "        \n",
    "        # Set up batch processing for videos\n",
    "        total_videos = len(video_files)\n",
    "        processed_videos = 0\n",
    "        \n",
    "        for video_file in video_files:\n",
    "            video_file_path = os.path.join(video_path, video_file)\n",
    "            print(f\"Processing {video_file} ({processed_videos}/{total_videos})...\")\n",
    "            try:\n",
    "                # MODIFIED to process videos in a simpler way\n",
    "                process_video_nonvisual(video_file_path, annotations, metrics[phase], model)\n",
    "                processed_videos += 1\n",
    "                print(f\"Completed: {processed_videos}/{total_videos}\")\n",
    "                \n",
    "                # Print interim metrics every 10 videos\n",
    "                if processed_videos % 10 == 0:\n",
    "                    interim_metrics = metrics[phase].calculate_metrics()\n",
    "                    print(f\"Interim metrics after {processed_videos} videos:\")\n",
    "                    print(f\"Precision: {interim_metrics['precision']:.3f}, Recall: {interim_metrics['recall']:.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Save results\n",
    "        results_dir = os.path.normpath(os.path.join('./results', phase))\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        metrics[phase].save_results(results_dir)\n",
    "        print(f\"{phase} metrics saved to {results_dir}\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    for phase in ['train', 'valid', 'test']:\n",
    "        res = metrics[phase].calculate_metrics()\n",
    "        print(f\"\\n{phase.upper():<6} Precision: {res['precision']:.3f} | Recall: {res['recall']:.3f} | F1: {res['f1_score']:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_video_nonvisual(video_path, annotations, metrics, model=None):\n",
    "    \"\"\"\n",
    "    Process a video file for fall detection without visualization\n",
    "    (much faster for batch processing)\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        annotations: Dictionary of ground truth annotations\n",
    "        metrics: FallDetectionMetrics instance for tracking performance\n",
    "        model: Optional pre-loaded YOLOv7 model\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "    from utils.datasets import letterbox\n",
    "    from utils.general import non_max_suppression_kpt\n",
    "    \n",
    "    # Initialize device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Check if model is provided, otherwise load it\n",
    "    if model is None:\n",
    "        # Ensure models directory exists\n",
    "        os.makedirs('./models', exist_ok=True)\n",
    "        \n",
    "        # Check if model file exists, if not download it\n",
    "        if not os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "            print(\"Model file not found. Please download yolov7-w6-pose.pt and place it in the models directory.\")\n",
    "            return\n",
    "            \n",
    "        # Load YOLOv7-pose model\n",
    "        weights = torch.load('./models/yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "        model = weights['model'].float().eval().to(device)\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.half()\n",
    "    \n",
    "    # Get video file name\n",
    "    video_file = os.path.basename(video_path)\n",
    "    \n",
    "    # Get ground truth fall frames (if available)\n",
    "    fall_frames = annotations.get(video_file, set())\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return\n",
    "        \n",
    "    frame_count = 0\n",
    "    detect_count = 0\n",
    "    fall_detect_count = 0\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Process frame for pose estimation\n",
    "            # Resize and preprocess\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "            image = transforms.ToTensor()(image)\n",
    "            image = torch.tensor(np.array([image.numpy()]))\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                image = image.half().to(device)\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                \n",
    "            # Run model inference\n",
    "            with torch.no_grad():\n",
    "                output, _ = model(image)\n",
    "            \n",
    "            # Process output for keypoints\n",
    "            output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'])\n",
    "            \n",
    "            # Check if person detected\n",
    "            if len(output) > 0 and len(output[0]) > 0:\n",
    "                detect_count += 1\n",
    "                # Get keypoints for first person detected\n",
    "                keypoints = output[0][0, 7:].clone().cpu().numpy()\n",
    "                \n",
    "                # Check if keypoints array is valid and has enough points\n",
    "                if len(keypoints) > 0:\n",
    "                    # Check for fall\n",
    "                    is_fall_detected, status, conditions = detect_fall(keypoints)\n",
    "                    \n",
    "                    # Ground truth - is this frame a fall according to annotations?\n",
    "                    is_actual_fall = frame_count in fall_frames\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    metrics.update(is_fall_detected, is_actual_fall)\n",
    "                    \n",
    "                    if is_fall_detected:\n",
    "                        fall_detect_count += 1\n",
    "            else:\n",
    "                # No person detected - generally count as \"no fall detected\"\n",
    "                # Since annotations typically mark scenes with people falling\n",
    "                is_actual_fall = frame_count in fall_frames\n",
    "                metrics.update(False, is_actual_fall)\n",
    "                \n",
    "            # Progress indicator (show every 100 frames)\n",
    "            if frame_count % 100 == 0:\n",
    "                print(f\"Processed {frame_count}/{total_frames} frames, detected {detect_count} people, {fall_detect_count} falls\", end=\"\\r\")\n",
    "                \n",
    "            frame_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_count}: {str(e)}\")\n",
    "            frame_count += 1\n",
    "            continue\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"\\nCompleted video: {video_file} - {frame_count} frames processed, {detect_count} people detected, {fall_detect_count} falls detected\")\n",
    "\n",
    "# For running in Jupyter notebook\n",
    "# 1. Download the model first\n",
    "download_success = download_model()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# Make sure the paths are correct\n",
    "sys.path.insert(0, os.path.abspath('.'))  # Add current directory first\n",
    "\n",
    "# Now try to download and load the model\n",
    "download_success = download_model()\n",
    "\n",
    "# Check if the model file exists\n",
    "if os.path.exists('./models/yolov7-w6-pose.pt'):\n",
    "    print(\"Model file found! Now you need to fix the import structure.\")\n",
    "    print(\"Please make sure you have the complete YOLOv7 repository structure.\")\n",
    "    print(\"Your project should include the following files:\")\n",
    "    print(\"- models/common.py\")\n",
    "    print(\"- models/experimental.py\")\n",
    "    print(\"- models/yolo.py\")\n",
    "else:\n",
    "    print(\"Model file not found. Please download it first.\")\n",
    "\n",
    "# 2. You can now choose what you want to do:\n",
    "# Uncomment one of these lines to run:\n",
    "\n",
    "# For webcam detection:\n",
    "# run_fall_detection_system(camera_index=0)\n",
    "\n",
    "# For dataset evaluation:\n",
    "# evaluate_on_dataset('./datasets/FallDataset', phase='test')\n",
    "\n",
    "# Evaluate all phases at once\n",
    "metrics = evaluate_all_phases('./datasets/FallDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2f4dc-ca71-420a-9296-d5cc6154d1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
