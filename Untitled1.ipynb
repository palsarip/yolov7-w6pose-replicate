{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933b36a9-e917-41d9-80fa-7c9951100bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from models.yolo import Model\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "# Add the custom class to the safe globals list\n",
    "torch.serialization.add_safe_globals([Model])\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv7-pose model\n",
    "weights = torch.load('yolov7-w6-pose.pt', map_location=device, weights_only=False)\n",
    "model = weights['model']\n",
    "_ = model.float().eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.half().to(device)\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to the image (brightness, contrast, noise, etc.).\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :return: Augmented image (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    # Convert to PIL Image for easier augmentation (PIL uses RGB format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Random brightness adjustment\n",
    "    brightness_factor = random.uniform(0.8, 1.2)  # Adjust brightness randomly\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "\n",
    "    # Random contrast adjustment\n",
    "    contrast_factor = random.uniform(0.8, 1.2)  # Adjust contrast randomly\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "\n",
    "    # Convert back to numpy array (RGB format)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    mean = 0\n",
    "    var = random.uniform(0, 0.005)  # Random noise variance (reduced to avoid extreme changes)\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean, sigma, image.shape).reshape(image.shape)\n",
    "    image = image + gaussian * 255\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Convert back to BGR format for OpenCV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    \"\"\"\n",
    "    Apply CLAHE to the image to enhance contrast.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :return: Image with CLAHE applied (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "\n",
    "    # Merge the channels back\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    image_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return image_clahe\n",
    "\n",
    "def preprocess_image(image, apply_augmentation=True, apply_clahe_flag=True):\n",
    "    \"\"\"\n",
    "    Preprocess the image with augmentation and CLAHE.\n",
    "    :param image: Input image (numpy array in BGR format).\n",
    "    :param apply_augmentation: Whether to apply augmentation.\n",
    "    :param apply_clahe_flag: Whether to apply CLAHE.\n",
    "    :return: Preprocessed image (numpy array in BGR format).\n",
    "    \"\"\"\n",
    "    if apply_augmentation:\n",
    "        image = augment_image(image)\n",
    "\n",
    "    if apply_clahe_flag:\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def detect_fall(keypoints, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect fall based on keypoints.\n",
    "    :param keypoints: Array of keypoints (17 keypoints, each with x, y, confidence).\n",
    "    :param threshold: Confidence threshold for keypoints.\n",
    "    :return: True if fall is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    # Indices for keypoints (COCO format)\n",
    "    LEFT_SHOULDER = 5\n",
    "    RIGHT_SHOULDER = 6\n",
    "    LEFT_HIP = 11\n",
    "    RIGHT_HIP = 12\n",
    "    LEFT_KNEE = 13\n",
    "    RIGHT_KNEE = 14\n",
    "\n",
    "    # Get keypoints and confidence scores\n",
    "    left_shoulder = keypoints[LEFT_SHOULDER * 3: (LEFT_SHOULDER + 1) * 3]\n",
    "    right_shoulder = keypoints[RIGHT_SHOULDER * 3: (RIGHT_SHOULDER + 1) * 3]\n",
    "    left_hip = keypoints[LEFT_HIP * 3: (LEFT_HIP + 1) * 3]\n",
    "    right_hip = keypoints[RIGHT_HIP * 3: (RIGHT_HIP + 1) * 3]\n",
    "    left_knee = keypoints[LEFT_KNEE * 3: (LEFT_KNEE + 1) * 3]\n",
    "    right_knee = keypoints[RIGHT_KNEE * 3: (RIGHT_KNEE + 1) * 3]\n",
    "\n",
    "    # Check confidence scores\n",
    "    if (left_shoulder[2] < threshold or right_shoulder[2] < threshold or\n",
    "        left_hip[2] < threshold or right_hip[2] < threshold or\n",
    "        left_knee[2] < threshold or right_knee[2] < threshold):\n",
    "        return False  # Skip if any keypoint is not confident\n",
    "\n",
    "    # Calculate average y positions\n",
    "    shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    hip_y = (left_hip[1] + right_hip[1]) / 2\n",
    "    knee_y = (left_knee[1] + right_knee[1]) / 2\n",
    "\n",
    "    # Check if hip and knee are below shoulders (fall condition)\n",
    "    if hip_y > shoulder_y and knee_y > shoulder_y:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def calculate_metrics(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, F1-score, and accuracy.\n",
    "    :param ground_truth: List of ground truth labels (1 = Fall, 0 = No Fall).\n",
    "    :param predictions: List of predicted labels (1 = Fall, 0 = No Fall).\n",
    "    :return: Precision, recall, F1-score, and accuracy.\n",
    "    \"\"\"\n",
    "    TP = sum(1 for gt, pred in zip(ground_truth, predictions) if gt == 1 and pred == 1)\n",
    "    FP = sum(1 for gt, pred in zip(ground_truth, predictions) if gt == 0 and pred == 1)\n",
    "    TN = sum(1 for gt, pred in zip(ground_truth, predictions) if gt == 0 and pred == 0)\n",
    "    FN = sum(1 for gt, pred in zip(ground_truth, predictions) if gt == 1 and pred == 0)\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score, accuracy\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "ground_truth_list = []\n",
    "predictions_list = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame (augmentation + CLAHE)\n",
    "    preprocessed_frame = preprocess_image(frame, apply_augmentation=True, apply_clahe_flag=True)\n",
    "\n",
    "    # Resize and normalize the frame for YOLOv7-pose\n",
    "    image = letterbox(preprocessed_frame, 960, stride=64, auto=True)[0]\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()]))\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    fall_detected = False\n",
    "    for idx in range(output.shape[0]):\n",
    "        keypoints = output[idx, 7:].T\n",
    "        plot_skeleton_kpts(nimg, keypoints, 3)\n",
    "\n",
    "        # Detect fall\n",
    "        if detect_fall(keypoints):\n",
    "            fall_detected = True\n",
    "            cv2.putText(nimg, \"Fall Detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Simulate ground truth with some randomness\n",
    "    # Here, we assume the ground truth is correct 80% of the time\n",
    "    if fall_detected:\n",
    "        ground_truth = 1 if random.random() < 0.8 else 0  # 80% chance of correct ground truth\n",
    "    else:\n",
    "        ground_truth = 0 if random.random() < 0.8 else 1  # 80% chance of correct ground truth\n",
    "\n",
    "    ground_truth_list.append(ground_truth)\n",
    "    predictions_list.append(1 if fall_detected else 0)\n",
    "\n",
    "    # Calculate and display metrics in real-time\n",
    "    if len(ground_truth_list) == len(predictions_list) and len(ground_truth_list) > 0:\n",
    "        precision, recall, f1_score, accuracy = calculate_metrics(ground_truth_list, predictions_list)\n",
    "        cv2.putText(nimg, f\"Precision: {precision:.2f}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(nimg, f\"Recall: {recall:.2f}\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(nimg, f\"F1-score: {f1_score:.2f}\", (50, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(nimg, f\"Accuracy: {accuracy:.2f}\", (50, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Fall Detection\", nimg)\n",
    "\n",
    "    # Break if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print final metrics\n",
    "if len(ground_truth_list) == len(predictions_list):\n",
    "    print(\"Final Metrics:\")\n",
    "    precision, recall, f1_score, accuracy = calculate_metrics(ground_truth_list, predictions_list)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1_score:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45a40c-9577-47bc-8bc9-e9964777f502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
