{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bcc876-66ce-4feb-9384-4783aa1f35d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--poseweights POSEWEIGHTS [POSEWEIGHTS ...]] [--source SOURCE] [--device DEVICE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\LENOVO\\AppData\\Roaming\\jupyter\\runtime\\kernel-15f6fddb-f920-45d4-baa2-670819cc9b30.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\yolov7_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import csv\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.torch_utils import select_device\n",
    "from models.experimental import attempt_load\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "# Initialize the CSV file to store the data\n",
    "csv_filename = 'fall_detection_output.csv'\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    headers = ['frame', 'xmin', 'ymin', 'xmax', 'ymax', 'fall_detected']\n",
    "    for i in range(17):  # 17 keypoints\n",
    "        headers.extend([f'kpt_{i}_x', f'kpt_{i}_y', f'kpt_{i}_conf'])\n",
    "    writer.writerow(headers)\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(poseweights='yolov7-w6-pose.pt', source='pose.mp4', device='cpu'):\n",
    "    video_path = source\n",
    "    device = select_device(device)\n",
    "    model = attempt_load(poseweights, map_location=device)  # load FP32 model\n",
    "    model.eval()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print('Error while trying to read video. Please check path again')\n",
    "\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    resize_factor = 1\n",
    "    resized_width = int(original_width * resize_factor)\n",
    "    resized_height = int(original_height * resize_factor)\n",
    "\n",
    "    out_video_name = f\"{video_path.split('/')[-1].split('.')[0]}\"\n",
    "    out = cv2.VideoWriter(f\"{out_video_name}_test.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
    "                          (resized_width, resized_height))\n",
    "\n",
    "    frame_count, total_fps = 0, 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (resized_width, resized_height))\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = letterbox(image, new_shape=resized_width, auto=False)[0]\n",
    "            image = transforms.ToTensor()(image)\n",
    "            image = torch.tensor(np.array([image.numpy()]))\n",
    "            image = image.to(device).float()\n",
    "            start_time = time.time()\n",
    "\n",
    "            output, _ = model(image)\n",
    "            output = non_max_suppression_kpt(output, 0.5, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'],\n",
    "                                             kpt_label=True)\n",
    "            output = output_to_keypoint(output)\n",
    "            img = image[0].permute(1, 2, 0) * 255\n",
    "            img = img.cpu().numpy().astype(np.uint8)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            thre = (resized_height // 2) + 100\n",
    "            for idx in range(output.shape[0]):\n",
    "                kpts = output[idx, 7:].T\n",
    "                plot_skeleton_kpts(img, kpts, 3)\n",
    "                cx, cy, w, h = output[idx, 2], output[idx, 3], output[idx, 4], output[idx, 5]\n",
    "                xmin, ymin = int(cx - w / 2), int(cy - h / 2)\n",
    "                xmax, ymax = int(cx + w / 2), int(cy + h / 2)\n",
    "                dx, dy = xmax - xmin, ymax - ymin\n",
    "                \n",
    "                # Ambil koordinat Y dari keypoint ke-2 (misalnya, pinggul)\n",
    "                keypoint_index = 2\n",
    "                ph = kpts[3 * keypoint_index + 1]  # Y-coordinate of keypoint 2\n",
    "                \n",
    "                difference = dy - dx\n",
    "                fall_detected = ((difference < 0) and (ph > thre)) or (difference < 0)\n",
    "\n",
    "                # Gambar bounding box\n",
    "                cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                text = \"FALL DETECTED\" if fall_detected else \"NORMAL\"\n",
    "                color = (0, 0, 255) if fall_detected else (255, 255, 255)1\n",
    "                cv2.putText(img, text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Simpan data ke CSV\n",
    "                with open(csv_filename, mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    row = [frame_count, xmin, ymin, xmax, ymax, fall_detected]\n",
    "                    for i in range(0, len(kpts), 3):\n",
    "                        kpt_x, kpt_y, kpt_conf = kpts[i], kpts[i+1], kpts[i+2]\n",
    "                        row.extend([kpt_x, kpt_y, kpt_conf])\n",
    "                    writer.writerow(row)\n",
    "            \n",
    "            cv2.imshow(\"Detection\", img)\n",
    "            cv2.waitKey(1)\n",
    "            end_time = time.time()\n",
    "            fps = 1 / (end_time - start_time)\n",
    "            total_fps += fps\n",
    "            frame_count += 1\n",
    "            out.write(img)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    avg_fps = total_fps / frame_count\n",
    "    print(f\"Average FPS: {avg_fps:.3f}\")\n",
    "\n",
    "def parse_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--poseweights', nargs='+', type=str, default='yolov7-w6-pose.pt', help='model path(s)')\n",
    "    parser.add_argument('--source', type=str, default='0', help='source')  # file/folder, 0 for webcam\n",
    "    parser.add_argument('--device', type=str, default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    opt = parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = parse_opt()\n",
    "    run(**vars(opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9212a-da45-4b22-b8b4-f803a1eabc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106022b8-12ed-4b94-b0e3-48147f63732a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m ground_truth_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Annotation_files/video (1).txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Jalankan fungsi proses video\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(video_path, ground_truth_path)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_video\u001b[39m(video_path, ground_truth_path):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Baca ground truth\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     start_frame, end_frame, bbox_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_ground_truth\u001b[49m(ground_truth_path)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Inisialisasi list untuk ground truth dan predictions\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Fungsi untuk menghitung faktor panjang\n",
    "def calculate_length_factor(shoulder, torso):\n",
    "    return np.sqrt((shoulder[0] - torso[0])**2 + (shoulder[1] - torso[1])**2)\n",
    "\n",
    "# Fungsi untuk mendeteksi jatuh\n",
    "def detect_fall(keypoints, length_factor, alpha=0.1):\n",
    "    left_shoulder = keypoints[5]  # Keypoint bahu kiri\n",
    "    right_shoulder = keypoints[6]  # Keypoint bahu kanan\n",
    "    left_hip = keypoints[11]  # Keypoint pinggang kiri\n",
    "    right_hip = keypoints[12]  # Keypoint pinggang kanan\n",
    "    left_foot = keypoints[15]  # Keypoint kaki kiri\n",
    "    right_foot = keypoints[16]  # Keypoint kaki kanan\n",
    "\n",
    "    # Periksa apakah bahu berada di bawah kaki\n",
    "    shoulder_below_foot = left_shoulder[1] <= left_foot[1] + alpha * length_factor\n",
    "\n",
    "    # Hitung tinggi dan lebar tubuh\n",
    "    body_height = abs(left_shoulder[1] - left_foot[1])\n",
    "    body_width = abs(left_shoulder[0] - right_shoulder[0])\n",
    "\n",
    "    # Periksa apakah tinggi tubuh lebih kecil dari lebar tubuh\n",
    "    height_less_than_width = body_height < body_width\n",
    "\n",
    "    # Jika kedua kondisi terpenuhi, deteksi jatuh\n",
    "    if shoulder_below_foot and height_less_than_width:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Fungsi untuk memproses video dan menghitung metrik\n",
    "def process_video(video_path, ground_truth_path):\n",
    "    # Baca ground truth\n",
    "    start_frame, end_frame, bbox_data = read_ground_truth(ground_truth_path)\n",
    "    \n",
    "    # Inisialisasi list untuk ground truth dan predictions\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Buka video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Cek apakah frame termasuk dalam rentang jatuh\n",
    "        if start_frame <= frame_count <= end_frame:\n",
    "            ground_truth.append(1)  # 1 = jatuh\n",
    "        else:\n",
    "            ground_truth.append(0)  # 0 = tidak jatuh\n",
    "        \n",
    "        # Di sini Anda bisa menambahkan kode untuk menjalankan model YOLOv7-w6\n",
    "        # dan mendapatkan keypoints untuk frame saat ini.\n",
    "        # Contoh sederhana: prediksi jatuh jika frame berada dalam rentang tertentu.\n",
    "        keypoints = get_keypoints_from_yolov7(frame)  # Ganti dengan fungsi yang sesuai\n",
    "        \n",
    "        # Hitung faktor panjang\n",
    "        length_factor = calculate_length_factor(keypoints[5], keypoints[11])\n",
    "        \n",
    "        # Deteksi jatuh\n",
    "        if detect_fall(keypoints, length_factor):\n",
    "            predictions.append(1)  # Prediksi jatuh\n",
    "        else:\n",
    "            predictions.append(0)  # Prediksi tidak jatuh\n",
    "        \n",
    "        # Tampilkan frame (opsional)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Hitung metrik\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    f1 = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Path ke video dan file ground truth\n",
    "video_path = \"C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Videos/video (1).avi\"\n",
    "ground_truth_path = \"C:/Users/LENOVO/Documents/A Skripsi/datasets/FallDataset/Dataset/Coffee_room_01/Annotation_files/video (1).txt\"\n",
    "\n",
    "# Jalankan fungsi proses video\n",
    "process_video(video_path, ground_truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c9eb0-738d-4a9a-b411-c806a99d902f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
